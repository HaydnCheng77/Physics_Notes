\documentclass[english,a4paper,12pt]{report}
\usepackage{mypackage}

\title{Maths (Miscellaneous)}

\author{Haydn Cheng}

\date{\today}

\begin{document}
\maketitle
\tableofcontents

\chapter{Functions of Complex Variables}

\section{Complex Numbers}

A complex number is most conveniently thought of as a vector with the \(x\)-axis replaced by the real axis with unit vector \(1\) and the \(y\)-axis replaced by the imaginary axis with unit vector \(i = \sqrt{-1} \). An arbitrary vector can then be represented in polar form or Cartesian form

\begin{equation}
	z = re^{i \theta } = x + iy, 
\end{equation}

where \( r = \abs{z} = \sqrt{x^2 + y^2} \text { and } \theta = \arg (z)\) is the angle between the complex number (vector) and the positive \(x\)-axis, measured counterclockwisely. If the complex number (vector) lies in the first quadrant, then 

\begin{equation}
    \arg (z) = \arctan {\left(y /x \right)} + 2\pi k
\end{equation}

If it is not in the first quadrant then \(\pi /2 \text { or } \pi \) must be added. \(k\) can be any integer value, but usually we use the pricipal value of the argument, the value of \(n\) such that \textit{i.e.,} \(\arg (z) \in (-\pi ,\pi ]\).
 
In particular, if \(r=1\), then it is easy to show that 

\begin{equation}
	e^{i \theta } = \cos \theta + i\sin \theta ,
\end{equation}

since we simply decompose a complex number (vector) into its components. This equation can also be verified using the Taylors' expansion of the exponential, sine and cosine function.

Raising both sides of the above equation to the power \(n\), we have the DeMoivre's formula

\begin{equation}
	(\cos \theta + i \sin \theta )^{n} = e^{i n \theta } = \cos (n \theta ) + i \sin (n \theta ).
\end{equation}

Using the polar form, it is trivial to derive the relations

\begin{equation}
	\abs{z_1 z_2 } = \abs{z_1 }\abs{z_2 } \text { and } \arg (z_1 z_2 ) = \arg (z_1 ) + \arg (z_2 ).
\end{equation}

Hence multiplying two complex numbers (vectors) together can be thought separately as two process. First, the modulus (length) of the new complex number (vector) is the product of the modulus (length) of the two complex numbers (vectors). Second, the argument of the new complex number (vector) is the sum of the arguments of the two complex numbers (vectors).

The complex conjugate of a complex number is defined as 

\begin{equation}
	z^* = x-iy = re^{-i \theta }.
\end{equation}

For complex number with a more complicated form, we simply replace all \(i\) by \(-i\). This follows from the fact that \((z_1 + z_2 )^* = z_1 ^* + z_2 ^*\) and \((z_1 z_2 )^* = z_1 ^* z_2 ^*\).  

Geometrically, we flip the imaginary axis (\(y\)-axis) upside down. Therefore, \(z \text { and } z^*\) are two complex numbers (vectors) reflected about the real axis (\(x\)-axis). Thus we have

\begin{equation}
	z z^* = \abs{z}^2 
\end{equation}

When extend to complex numbers, the natural logarithm is infinitely-multivalued, this is because 

\begin{equation}
    \ln (z) = \ln (\abs{z}e^{i \the\tau _{0}  + 2\pi k}  ) = \ln (\abs{z} ) + i (\theta _{0} +2\pi k),
\end{equation}

where \(\theta _{0} \in (-\pi ,\pi ] \text { and } k \in \mathbb{Z}\). The princpial value is defined as the value when \(k = 0\).  

The \(n^{\text{th}} \) root function is \(n\)-times-multivalued, since 

\begin{equation}
    z^{1/n} = \abs{z}^{1/n} e^{i \theta _{0}/n } e^{2\pi i k /n}      
\end{equation}

can take \(n\) different values for all \(k \in \mathbb{Z}\). 

The hyperbolic trigonometric formulas are largely reminiscent of the ordinary trigonometric formulas, with a few exceptions:

\begin{equation}
    \cosh^2(x) - \sinh^2(x) = 1, \quad 1 - \tanh^2(x) = \sech^2(x) ~\text { and }~  \cosh^2(x) + \sinh^2(x) = \cosh(2x).
\end{equation}

The inverse of trigonometric functions can be written in terms of the natural logorithmic function. For example, we have

\begin{equation}
    z = \tan w = \frac{1}{i} \left( \frac{e^{iw} - e^{-iw} }{e^{iw} + e^{-iw}  }  \right) \implies e^{2iw} = \frac{1+iz}{1-iz}  \implies \tan ^{-1} z = \frac{1}{2i} \ln \left( \frac{1+iz}{1-iz}  \right). \label{tan} 
\end{equation}

\example{Inverse Trigonometric Functions of Complex Variables (1).}
{Express \(\tan ^{-1} {(\sqrt{3}i )} \) in the form \(a+bi\). Hence solve the equation \(\tan z = \sqrt{3} i\).}
{To calculate \(\tan ^{-1} {(\sqrt{3} i)}\) we substitute \(z = \sqrt{3}i \) into \cref{tan} and get

\begin{equation}
    \tan ^{-1} (\sqrt{3} i) = \frac{1}{2i} \ln (\frac{1-\sqrt{3} }{1+\sqrt{3} } ) = \frac{1}{2i} \ln \left( \frac{\sqrt{3}-1 }{\sqrt{3}+1 } e^{i\pi }  \right) = -\frac{i}{2} \ln (2-\sqrt{3} ) + \frac{\pi }{2}.    
\end{equation}

To solve the equation \(\tan z = \sqrt{3} i\), we add \(n\pi \) to \(\tan \sqrt{3}i \) to get 

\begin{equation}
    z = - \frac{i}{2} \ln (2-\sqrt{3} ) + \frac{\pi }{2} (1+ 2n).  
\end{equation}
 } 

\example{Inverse Trigonometric Functions of Complex Variables (2).}
{Express \(\sin ^{-1} (3)\) in the form \(a+bi\). Hence solve the equation \(\sin z = 3\).}
{To calculate \(\sin ^{-1} (3)\) we substitute \(z = 3\) into \cref{sin} and get
 
\begin{equation}
    \sin ^{-1} (3) = \frac{\pi }{2} - i \ln (3+2\sqrt{2} ). 
\end{equation}
 
To solve the equation \(\sin z = 3\) we add \(2\pi n\) to \(\sin ^{-1} (3)\) or we subtract \(\sin ^{-1} (3) \) from \( \pi + 2\pi n\) and get

\begin{equation}
    z = \frac{\pi }{2} - i \ln (3+2\sqrt{2} ) + 2\pi n ~\text { or } ~ \frac{\pi }{2} + i \ln (3+2\sqrt{2} ) + 2\pi n,
\end{equation}

which we may combine compactly as 

\begin{equation}
    z = \frac{\pi }{2} + 2\pi n \pm i \ln (3+2\sqrt{2} ),
\end{equation}

We can also solve the eqaution without using the predetermined formula, but start from

\begin{equation}
    \sin z = \frac{e^{iz}-e^{-iz}  }{2i} = 3 
\end{equation}

to get 

\begin{equation}
    \begin{aligned} 
    z &= -i \ln (i (3+2\sqrt{2} )) = -i \left(i \frac{\pi }{2} + 2\pi in + \ln (3 \pm 2\sqrt{2} ) \right) \\
    &= \frac{\pi }{2} + 2n\pi - i\ln (3+2\sqrt{2} ) ~\text { or } ~ \frac{\pi }{2} + 2n\pi +i\left( \ln (\frac{1}{3-2 \sqrt{2} } ) \right) \\
    &= \frac{\pi }{2} + 2n\pi -i \ln (3+2\sqrt{2} ) ~\text { or } ~ \frac{\pi }{2} + 2n\pi +i \ln (3+2\sqrt{2} )\\
    &=  \frac{\pi }{2} + 2n\pi \pm i \ln (3+2\sqrt{2} ).  
    \end{aligned} 
\end{equation}
~
} 
 

\example{Plot on the Complex Plane (1).}
{Plot the equation \( \arg \left((z-4)/(z-1)\right)=3\pi /2 \) on the complex plane. }
{Writing \(z = x+iy\), we have 

\begin{equation}
    \frac{z-4}{z-1} = \frac{(x-4)(x-1)+y^2}{(x-1)^2+y^2} + i \frac{3y}{(x-1)^2+y^2}.  
\end{equation}

The real part must be zero and the imaginary part must be negative for the argument to be \(3\pi /2\), so we get \((x-4)(x-1)+y^2=0 \implies (x-5/2)^2+y^2 = 0 \text { and } y<0\). Note we cannot use the formula \(\arg (z) =  \arctan {\left(y /x\right) } \), since the complex number does not lie in the first quadrant.   
} 

\example{Plot on the Complex Plane (2).}
{Plot the equation \(\arg (z-3i) = \pi /4\) on the complex plane. }
{Writing \(z = x+iy\), we have

\begin{equation}
    \arg \left( x+i(y-3) \right) =\frac{\pi }{4} \implies y - 3 = x. 
\end{equation}

However, an extra condition \(x > 0\) has to be imposed so that the point \((x,y-3)\) lies in the direction corresponding to an angle of \(\pi /4\).  

} 

To find the cosine or sine of some multiples of angle (\textit{e.g.,} \(\sin (6\theta )\)), the simpliest way is always expand \((\cos \theta +i\sin \theta )^6 = \cos (6\theta ) + i\sin (6\theta )\) and compare the imaginary (or real) part. 

To find some power of cosine or sine of angle (\textit{e.g.,} \(\sin ^{6} \theta \)) in terms of single power of cosine or sine, the sipmliest way is always write \(\sin \theta = (e^{i \theta }-e^{-i \theta })/2i \), and expand. 

The fundamental theorem of algebra states that a \(n^{\text{th}}\) order polynomial equation will have exactly \(n\) roots. For example, the equation \(x^{8} = 16\) has eight roots \(x = \sqrt[8]{16} = (16e^{2\pi k})^{1 /8 } = \sqrt{2}e^{\pi n/4 }\), where \(n = (0,\ldots 7) \text { or } (1,\ldots 8)\).   

The sum and product of roots of the polynomial equation

\begin{equation}
    a_0 + a_1 z + a_2 z ^2 + \cdots + a_{n}z^2 = a_{n}(z - z_1 )(z-z_2 )\cdots (z-z_{n} ) = 0   
\end{equation}

can be extracted to be 

\begin{equation}
    \sum_{i=1}^{n} z_{i} = - \frac{a_{n-1} }{a_{n} } ~\text { and }~ \prod_{i=1}^{n} z_{i} = (-1)^{n} \left(\frac{a_{0} }{a_{n} }\right).     
\end{equation}

\section{Analytic Functions}

\subsection{Definition}

For a complex vector 

\begin{equation}
    z(x,y) = x+iy,
\end{equation}

a complex function \(f(x,y)\) maps a complex vector \(x+iy\) to one or more vectors of \(f(x,y)\),\footnote{In rigorous definition a function should be singled-valued. However, it serves no harm to define a ``multi-valued'' function, and this is a widely accepted terminology. In later sections we will choose one of the many possible \(f(x,y)\) as the principal value, which resolves the ``issue'' of having a function that gives multiple values on a single input.}  and can be represented by

\begin{equation}
    f(x,y) = u(x,y) + iv(x,y).
\end{equation}

In fact, since \((x,y)\) and \((z,\overline{z} )\) are related by 

\begin{equation}
    x = \frac{\overline{z} +z }{2} ~\text { and }~ y = \frac{i(\overline{z} -z)}{2},
\end{equation}

we can rewrite the functions in terms of \(z \text { and } \overline{z} \), \textit{i.e.,} \(f(x,y) = f(z, \overline{z} )\). 

\begin{equation}
    \begin{aligned} 
    f_1 (x,y) &= (x^2-y^2,2xy) = f_1 (z,\overline{z} ) = z^2,\\
    f_2 (x,y) &= (x^2+y^2,0) = f_2 (z,\overline{z} ) = z \overline{z} ,\\
    f_3 (x,y) &= (x^3 +xy,0) = f_3 (z,\overline{z} ) = \frac{1}{8} (z + \overline{z} )^2 - \frac{i}{4}(z^2-\overline{z} ^2). 
    \end{aligned} 
\end{equation}

At first glance, one may think that since \(\overline{z} \) is a ``function'' of \(z\), so \(f(z,\overline{z} )\) is just \(f(z)\). However, we cannot recreate \(x \text { or } y\) from \(z\) alone without using the \(\mathfrak{Re} \text { or } \mathfrak{Im}  \) ``functions''. In other words, there is no elementary way of describing all possibles transformations on the complex plane with \(z\) alone. For example, for \(f(x,y) = x\), indeed we can write the equivalent \(f(z) = \mathfrak{Re} (z) \), but it would be difficult to work in this form as the \(\mathfrak{Re} \) ``function'' is not easy to work with. Instead it is much more convenient to introduce \(\overline{z} \), where we can write the function as \(f(z,\overline{z} ) = (z + \overline{z} ) /2\). 

Therefore, \(f(z)\) is only a subset of all the possible transformations of \(z\), where the general \(f(z,\overline{z} ) = f(z)\) depends on \(z\) alone but not \(\overline{z} \). This type of complex functions will be our main focus due to its usefulness.

For a complex function \(f(z,\overline{z} )\) to be independent of \(\overline{z} \) we must have 

\begin{equation}
    \frac{\partial f}{\partial \overline{z} } = 0. 
\end{equation}

We start from writing the total derivative of \(f(x,y)\) in terms of \(x \text { and } y\)

\begin{equation}
    df = f_{x}  dx + f_{y}  dy.
\end{equation}

Dividing both sides by \(d \overline{z} \) while keeping \(z\) constant we have 

\begin{equation}
    \left( \frac{\partial f}{\partial \overline{z} } \right)_{z} = f_{x} \left( \frac{\partial x}{\partial \overline{z} } \right)_{z} + f_{y} \left( \frac{\partial y}{\partial \overline{z} } \right)_{z} = \frac{1}{2} \left( \frac{\partial }{\partial x} + i \frac{\partial }{\partial y}  \right) (u+iv) = \frac{1}{2} \left( \frac{\partial u}{\partial x} -\frac{\partial v}{\partial y}  \right) + \frac{i}{2} \left( \frac{\partial v}{\partial x} + \frac{\partial u}{\partial y}  \right).
\end{equation}

Enforcing it to be zero we obtain the Cauchy-Riemann conditions

\begin{equation}
    \frac{\partial u}{\partial x} = \frac{\partial v}{\partial y} ~\text { and }~ \frac{\partial u}{\partial y} = -\frac{\partial v}{\partial x}.
\end{equation}

A single-valued function \(f(z)\) is differentiable point \(z\) if the derivative 

\begin{equation}
    \frac{df}{dz} = \lim_{\delta z \to 0} \frac{f(z+\delta z)-f(z)}{\delta z}   
\end{equation}

exists\footnote{The existence of \(df/dz\) is the same as the existence of just \(f(z)\).} and is unique, in that its value does not depend on the direction in the copmlex plane from which \(\delta z\) tends to zero. 

A function \(f(z)\) is said to be holomorhpic at a point \(a\) if it is differentiable at every point within some open disk centered at \(a\), and is said to be analytic at \(a\) if in some open disck centered at \(a\) it can be expanded as a convergent power series 

\begin{equation}
    f(z) = \sum_{n=0}^{\infty} c_{n} (z-a)^{n},   
\end{equation}

which is the Taylor series of \(f(z)\) around the point \(z = a\). It could be shown that in complex analysis holomorhpic functions are analytic and vice versa. In the following we will be mostly using the term analytic except otherwise specified.

Given that the derivative \(df /dz\) exists, consider as \(\delta z\) appraoches zero along the \(x\)- and \(y\)- axes  
\begin{equation}
    \begin{aligned}
        \frac{df}{dz} &= \lim_{\delta x \to 0}  \frac{f(x+\delta x,y)-f(x,y)}{\delta x} = \left( \frac{\partial f}{\partial x} \right)_{y} = \frac{\partial u}{\partial x} + i\frac{\partial v}{\partial x} ,\\
        \frac{df}{dz} &= \lim_{\delta y \to 0}   \frac{f(x,y+\delta y)-f(x,y)}{i \delta y} = \left( \frac{\partial f}{\partial y} \right)_{x} = \frac{1}{i} \frac{\partial u}{\partial y} + \frac{\partial v}{\partial y}.
    \end{aligned}
\end{equation}

For the derivatives to be unique we require the two results to be equal we obtain the Cauchy-Riemann conditions. This shows that a complex function being analytic is the same as saying that the function \(f(z,\overline{z} ) = f(z)\) depends on \(z\) alone but not \(\overline{z} \). 

Their relations can be summarized by 

\begin{equation}
    f(z) \text{ is analytic (given existence)} \longleftrightarrow \text{Cauchy-Riemann Conditions} \longleftrightarrow f(z) = f(z,\overline{z} ).
\end{equation}

A function may be analytic in a domain except at a finite number of points, called the singularities of \(f(z)\) (or an infinite number if the domain is infinite). Functions that are analytic everywhere (excpet, maybe, at \(z = \infty\)) are called entire or integral functions.

\example{\(f\) Being Constant.}
{Prove that if \(f\) is real-valued or if \(\abs{f} \) is constant, then \(f\) is constant given that \(f\) is an analytic function.}
{If \(f\) is real-valued, then \(v(x,y) = 0\). From the Cauhy-Riemann conditions we have \(u_{x} = u_{y} = 0  \), so \(u\) is constant. 

If \(\abs{f} \) is constant, then we have 

\begin{equation}
    u^2+v^2=R^2 \implies \begin{cases}
        u u_{x}+v v_{x} &=0,\\
        u u_{y} + v v_{y} &= 0.
    \end{cases} \implies 
    \begin{cases}
        uv_{y}+v v_{x} &=0,\\
        u(-v_{x} )+v v_{y} &=0 .
    \end{cases}  
\end{equation}

Viewed as a linear system in the unknowns \(v_{x}\text { and } v_{y}  \), the determinant is \(v^2+u^2=R^2 > 0\), hence the only solution is \(v_{x}=v_{y}=u_{x}=u_{y}=0   \), so \(f\) is a constant.   
} 


\subsection{Properties and Examples}

\subsubsection{\(u(x,y) = c_1 \text { and } v(x,y) = c_2 \) being Orthogonal}

Consider the lines on the Argand plane that satisfy 

\begin{equation}
    u(x,y) = c_1 ~\text { and }~ v(x,y) = c_2.
\end{equation}

The normal vectors to these curves are 

\begin{equation}
    \vb{n} _{u} = \grad{u(x,y)} = \left( \frac{\partial u}{\partial x} , \frac{\partial u}{\partial y}  \right) ~\text { and }~ \vb{n} _{v} = \grad{v(x,y)} = \left( \frac{\partial v}{\partial x} , \frac{\partial v}{\partial y}  \right).
\end{equation}

If we now take the dot product between these two vectors we find 

\begin{equation}
    \vb{n} _{u} \cdot \vb{n} _{v} = \frac{\partial u}{\partial x} \frac{\partial v}{\partial x} + \frac{\partial u}{\partial y}  \frac{\partial v}{\partial y} = \frac{\partial v}{\partial y} \frac{\partial v}{\partial x} - \frac{\partial v}{\partial x} \frac{\partial v}{\partial y} =0.  
\end{equation}

In other words, curves of constant \(u \text { and } v\) are orthogonal to each other, wherever the function is analytic.

\subsubsection{Conformality}

Consider two infinitesimal changes to \(z\)  which are at angle \(\theta \)

\begin{equation}
    z_1 = z+ \epsilon e^{i \theta _{1} } ~\text { and }~ z_2 = z+ \epsilon e^{i \theta _{2} } \implies \frac{z_2 -z}{z_1 -z} = e^{i \theta }.    
\end{equation}

We now transform the two points 

\begin{equation}
    w_{1} = f(z_1 ) ~\text { and }~ w_{2} = f(z_2 ).  
\end{equation}

But given that the function is analytic we can also Taylor expand to get 

\begin{equation}
    w+\delta w_1 = f(z) + f'(z)\epsilon e^{i \theta _{1} } ~\text { and }~ w+\delta w_2 = f(z) + f'(z)\epsilon  e^{i \theta _{2} },
\end{equation}

so the angle between the two transformed points is 

\begin{equation}
    \arg \left( \frac{\delta w_2 }{\delta w_1 }  \right) = \arg \left( \frac{f'(z)\epsilon e^{i \theta _{1} } }{f(z)\epsilon e^{i \theta _{2} } }  \right).
\end{equation}

Such angle preserving transformations are also known as conformal transfrmations.

An analytic function is conformal at a point \(z_0 \) when its derivative there is non-zero, \textit{i.e.,} \(f'(z_0 )=0\).  

\subsubsection{Examples}

Examples of analytic functions include 

\begin{equation}
    f(z) = z^{n}, \quad f(z) = e^{z} \equiv \sum_{k=0}^{\infty} \frac{z^{k} }{k!}, \quad f(z) = \cos (z) \equiv \sum_{k=0}^{\infty} \frac{(-1)^{k}z^{2k}  }{(2k)!}.   
\end{equation}

But by for the most commonly used complex functions are the multivalued functions

\begin{equation}
    z^{1 /n } = \abs{z}^{1 /n}  e^{i(\theta + 2\pi k) /n} ~\text { and }~ \ln (z) = \ln \abs{z} + i (\theta + 2\pi k).
\end{equation}

For multivalued functions there is a canonical choice called the principal value, which preserve the injective property of ordinary function. For the examples above, we restrict ourselves to \((\theta +2\pi k) \in (0,2\pi ] \text { or } \in (-\pi ,\pi ]\), depending our the convention adopted. 

If we restrict ourselves to the princpal roots, then the function \(f(z) = z ^{1 /2} \) transforms the complex plane into the upper half plane while the function \(f(z) = z^{1 /4} \) transforms the complex plane into the first quadrant, \textit{etc.} On the other hand, the natural logarithmic function transforms the complex plane into an infinite horizontal strip with boundaries at \(y = 0 \text { and } 2\pi\).   

A less commonly used multivalued function is the complex power

\begin{equation}
    t^{z} = e^{z \ln t} = \sum_{k=0}^{\infty} \frac{z^{k} (\ln \abs{t} + i(\theta +2\pi k) )^{t} }{k!}.
\end{equation}

Note that using this definition \(1^{i} = e^{i \log (1)} = 0 \neq (e^{i(2\pi (1+n)i)} ) = e^{2\pi (1+n)} \). 

One particularly interesting example maps the half plane onto a circle

\begin{equation}
    f(z) = \left( \frac{z-z_0 }{z-\overline{z_0} }  \right) e^{i \theta _{0} },
\end{equation}

where the point \(z_0 \) will be mapped onto the origin while \(-\infty \text { and } + \infty\) will be mapped onto the point \(e^{i \theta _{0} } \).  

Another interesting mapping is the Möbius map

\begin{equation}
    f(z) = \frac{az+b}{cz+d}, \quad ad-bc \neq 0,
\end{equation}

which carries generalized circles, \textit{i.e.,} Euclidean circles or straight lines, into generalized circles. So given any three distinct points \(z_1 ,z_2, z_3 \) on one generalized cirlce and any three distinct images \(f(z_1 ), f(z_2 ), f(z_3 )\) on another generalized circle, there is exactly one Möbius map sending \(z_{i} \mapsto f(z_{i} ) \) for \(i = 1,2,3\).    

\example{Analytic Functions.}
{Given that \(v(x,y)  = (x^2-y^2) + y^2\) and \(f(0)=0\), find \(f(z)\).  }
{We notice that the first part is simply \(\mathfrak{Re} (z^2) \) while the second part is \(\mathfrak{Im} (z) \). We therefore guess that 

\begin{equation}
    f(z) = iz^2+z+c, 
\end{equation}

where \(c = 0\) to satisfy the condition at \(z = 0\).

Alternatively we can use a more ssytematic method and find from the Cauchy-Riemann conditions that 

\begin{equation}
    \frac{\partial u}{\partial x} = \frac{\partial v}{\partial y} = -2y+1 \implies u = -2xy+x+h(y),
\end{equation}

and 

\begin{equation}
    \frac{\partial u}{\partial y} = -\frac{\partial v}{\partial x} = -2x \implies h(y) = c = 0.
\end{equation}
~
} 

\example{Jacobian.}
{Prove that \(\abs{J} = \abs{f'}^2 \). }
{Using the Cauchy-Riemann conditions we see that 

\begin{equation}
    \abs{J} = \abs{\frac{\partial u}{\partial x} \frac{\partial v}{\partial y} - \frac{\partial v}{\partial x} \frac{\partial u}{\partial y} } = \left( \frac{\partial u}{\partial x}  \right)^2 + \left( \frac{\partial u}{\partial y}  \right)^2 = \left( \frac{\partial v}{\partial y}  \right)^2 + \left( \frac{\partial v}{\partial x}  \right)^2.   
\end{equation}

On the other hand we have

\begin{equation}
    \begin{aligned} 
    f'(z) &= \frac{df}{dz} = \frac{1}{2} \left( \frac{\partial }{\partial x} - i \frac{\partial }{\partial y}  \right) (u+iv) \\
    &= \frac{1}{2} \left( \frac{\partial u}{\partial x} - \frac{\partial v}{\partial y}  \right) - \frac{i}{2} \left( \frac{\partial v}{\partial x} + \frac{\partial u}{\partial y}  \right) = \frac{\partial u}{\partial x} - i \frac{\partial u}{\partial y} = \frac{\partial v}{\partial y} + i \frac{\partial v}{\partial x}.
    \end{aligned} 
\end{equation}

Thus the norm-sqaured is 

\begin{equation}
    \abs{f'(z)}^2 = \left( \frac{\partial u}{\partial x}  \right)^2 + \left( \frac{\partial u}{\partial y}  \right)^2 = \left( \frac{\partial v}{\partial x}  \right)^2 + \left( \frac{\partial v}{\partial y}  \right)^2 = \abs{J}^2.  
\end{equation}
~
} 

\example{Conformal Mapping.}
{Consider the function 

\begin{equation}
    f: z  \mapsto w = z+\frac{1}{z} .
\end{equation}

\begin{enumerate}
    \item Give the subset of the complex \(z\)  plane in which \(f\) is holomorhpic.
    \item Determine whether the mapping is conformal in the region of holomorphy.
    \item  Onto which subset of the \(w\) plane does \(f\) map the upper half and lower half of circle \(\abs{z} = 1 \)?
    \item What is the image through \(f\) of a cirlce \(\abs{z} = \rho \) with \(\rho \neq 1\)?  
\end{enumerate}
~
}
{\begin{enumerate}
    \item The function is holomorhpic everywhere except at the pole \(z = 0 \text { and } \infty\).
    \item  The derivative is zero at \(z = \pm 1\), so the function is conformal everywhere except at \(x = 0 \text { and } \pm 1\).
    \item On the unit circle we parametrize 
    \item 
    \begin{equation}
        z = e^{i \theta }, \quad 0 \le \theta <2\pi ,
    \end{equation}

    then

    \begin{equation}
        f(z) = f(e^{i \theta } ) = e^{i \theta } + e^{-i \theta } = 2 \cos \theta.
    \end{equation}
    
    Hence both upper and lower half of the cirlce get mapped to the real segment \([-2,2]\). 

    \item We parametrize the circle by 
    
    \begin{equation}
        z=\rho e^{i \theta }, \quad 0 \le \theta < 2\pi ,
    \end{equation}
    
    then 

    \begin{equation}
        f(z) = f(\rho e^{i \theta } )= \left( \rho +\frac{1}{\rho }  \right)\cos \theta + i \left( \rho - \frac{1}{\rho }  \right) \sin \theta .
    \end{equation}
    
    Defining 

    \begin{equation}
        x \equiv \mathfrak{Re} (f(z)) = \left( \rho +\frac{1}{\rho }  \right) \cos \theta ~\text { and }~ y \equiv \mathfrak{Im} (f(z)) = \left( \rho -\frac{1}{\rho }  \right) \sin \theta ,
    \end{equation}
    
    one sees that \((x,y)\) satisfies the ellipse equation 

    \begin{equation}
        \frac{x^2}{(\rho +1 /\rho )^2} + \frac{y^2}{(\rho -1 /\rho )^2} = 1.  
    \end{equation}
    
    Thus the cirlce \(\abs{z} = \rho  \) is carried to the ellipse centered at the origin with semi-axes
    
    \begin{equation}
        a = \rho + \frac{1}{\rho } ~\text { and }~ b = \abs{\rho +\frac{1}{\rho } }.
    \end{equation}
\end{enumerate}
~
} 




\section{Power Series in a Complex Variable}

If the power series

\begin{equation}
    f(z) = \sum_{n=0}^{\infty} a_{n}z^{n}  = \sum_{n=0}^{\infty} a_{n}r^{n} e^{in\theta }        
\end{equation}

converge then its real (and imaginary) part must be convergent, \textit{i.e.,}  

\begin{equation}
    \sum_{n=0}^{\infty} \abs{a_{n} }r^{n}   
\end{equation}

is convergent. 

The radius of convergence \(R\) can be found by the Cauchy-root test or the ratio test

\begin{equation}
    \frac{1}{R} = \lim_{n \to \infty} \abs{a_{n}  } ^{1/n} = \lim_{n \to \infty} \abs{\frac{a_{n} }{a_{n+1} } },  
\end{equation}

and it can be proved that the series is convergent if \(\abs{z} <R \) and divergent if \(\abs{z}>R \). If \(\abs{z} =R \) then no particular conclusion may be drawn and must be considered separately.   

It can also be shown that the power series \(\sum_{n=0}^{\infty} a_{n}z^{n}  \) has a sum that is an analytic function of \(z\)  inside its circle of convergence. As a corollary, it may further be shown that if \(f(z) = \sum_{n=0}^{\infty} a_{n}z^{n}  \) then, inside the circle of convergence of the series \(f'(z) = \sum_{n=0}^{\infty} n a_{n} z^{n-1}   \). Repeated application of this result demonstrates that any power series can be differentiated any number of times inside its circle of convergence.




\section{Solutions to the Laplace's Equation}

\subsection{Complex Potential}

We notice that if \(f(x,y)\) is analytic, then \(u(x,y) \text { and } v(x,y)\) are harmonic functions, \textit{i.e.,} they satisfy the Laplace's equation in two dimensions, since

\begin{equation}
    \laplacian u(x,y) = \frac{\partial }{\partial x} \left( \frac{\partial u}{\partial x}  \right) + \frac{\partial }{\partial y} \left( \frac{\partial u}{\partial y}  \right) = \frac{\partial }{\partial x} \left( \frac{\partial v}{\partial y}  \right) - \frac{\partial }{\partial y} \left( \frac{\partial v}{\partial x}  \right) = 0.
\end{equation}

The same holds for \(\laplacian v(x,y) = 0\). 

Now suppose we want to solve for the electric potential \(\Phi \) and electric field \(\vb{E} \) from the Laplace's equation in two dimensions for a charge \(q\) located at the origin

\begin{equation}
    \laplacian \Phi = 0 ~\text { and }~ E = \grad{\Phi }. 
\end{equation}

Using the Laplaceian in spherical coordinates we find 

\begin{equation}
    \Phi  = -2q\ln r ~\text { and }~ \vb{E} = \frac{2q}{r}\vu{r} . 
\end{equation}

Now we introduce the complex potential 

\begin{equation}
    f = -2q \ln z = -2q \ln r - 2q i \theta = \Phi + iV,
\end{equation}

where the real part of \(f\) is the real potential \(\Phi \), and since we know that for an analytic function the lines of constant \(u\) are orthogonal to the lines of constant \(v\) we also have that the lines of constant \(v\) are the electric field lines (since \(\vb{E} = \grad{\Phi } \) are orthogonal to constant \(\Phi \)).

For example we consider the \(x\)-axis where \(\Phi = \Phi _{0} = \text{constant}  \). The electric field \(\vb{E} (y) \) and potential \(\Phi (y)\) are then   

\begin{equation}
    \vb{E}(y) = \frac{\sigma }{\epsilon_0 } \vu{y}  ~\text { and }~ \Phi (y) = \Phi _{0} - \frac{\sigma }{\epsilon_0 }y.  
\end{equation}

Therefore the complex potential 

\begin{equation}
    f = \Phi _{0} + i \frac{\sigma }{\epsilon_0 }z  
\end{equation}

allows us to find both the electric potential and the electric field lines.

\subsection{Coordinates Transformation}

We now prove that if \(\Phi \) is harmonic in the coordinates \((x,y)\) it remains harmonic in \((u,v)\). This is because 

\begin{equation}\label{eq:107a}
\frac{\partial^2\Phi}{\partial x^2}
=\frac{\partial^2\Phi}{\partial u^2}\Bigl(\frac{\partial u}{\partial x}\Bigr)^2
+\frac{\partial\Phi}{\partial u}\,\frac{\partial^2u}{\partial x^2}
+\frac{\partial^2\Phi}{\partial v^2}\Bigl(\frac{\partial v}{\partial x}\Bigr)^2
+\frac{\partial\Phi}{\partial v}\,\frac{\partial^2v}{\partial x^2}
+2\,\frac{\partial u}{\partial x}\,\frac{\partial v}{\partial x}\,
\frac{\partial^2\Phi}{\partial u\,\partial v},
\end{equation}
\begin{equation}\label{eq:107b}
\frac{\partial^2\Phi}{\partial y^2}
=\frac{\partial^2\Phi}{\partial u^2}\Bigl(\frac{\partial u}{\partial y}\Bigr)^2
+\frac{\partial\Phi}{\partial u}\,\frac{\partial^2u}{\partial y^2}
+\frac{\partial^2\Phi}{\partial v^2}\Bigl(\frac{\partial v}{\partial y}\Bigr)^2
+\frac{\partial\Phi}{\partial v}\,\frac{\partial^2v}{\partial y^2}
+2\,\frac{\partial u}{\partial y}\,\frac{\partial v}{\partial y}\,
\frac{\partial^2\Phi}{\partial u\,\partial v}.
\end{equation}

Recall that
\begin{equation}\label{eq:108}
\lvert f'(z)\rvert^2
=\Bigl(\frac{\partial u}{\partial x}\Bigr)^2
+\Bigl(\frac{\partial v}{\partial x}\Bigr)^2
=\Bigl(\frac{\partial u}{\partial y}\Bigr)^2
+\Bigl(\frac{\partial v}{\partial y}\Bigr)^2.
\end{equation}

Taking a linear combination of \eqref{eq:107a} and \eqref{eq:107b} we get
\begin{equation}\label{eq:109}
\begin{split}
\frac{\partial^2\Phi}{\partial x^2}+\frac{\partial^2\Phi}{\partial y^2}
&=\lvert f'(z)\rvert^2\Bigl(\frac{\partial^2\Phi}{\partial u^2}
+\frac{\partial^2\Phi}{\partial v^2}\Bigr)
+\frac{\partial\Phi}{\partial u}\,\nabla^2u
+\frac{\partial\Phi}{\partial v}\,\nabla^2v\\
&\quad
+2\Bigl(\frac{\partial u}{\partial x}\frac{\partial v}{\partial x}
+\frac{\partial u}{\partial y}\frac{\partial v}{\partial y}\Bigr)
\frac{\partial^2\Phi}{\partial u\,\partial v},
\end{split}
\end{equation}

where only the first term on the RHS remains due to the harmonicity of \(u \text { and } v\), and the Cauchy's Riemann conditions.

\subsection{More Examples}

Now consider a plate held at a fixed potential \(\Phi = \Phi _{0} \) on the positive \(x \text { and } y\) axes. We can employ the transformation 

\begin{equation}
    w = z^2.
\end{equation}

The boundary will now be along the \(x\)-axis in the \(w\) plane, which is a problem we have solved earlier. In these new coordinates we have the complex potential 

\begin{equation}
    f = \Phi _{0} + i \frac{\sigma }{\epsilon_0 }w.  
\end{equation}

Therefore the real potenial is 

\begin{equation}
    \Phi = \mathfrak{Re} (f) = \mathfrak{Re} \left( \Phi _{0} + i \frac{\sigma }{\epsilon_0 }z^2  \right) = \Phi _{0} - 2 \frac{\sigma }{\epsilon_0 }xy.  
\end{equation}

Now consider a long hollow conducting cylinder with its surface described by \(x^2+y^2=1\), where the two semi-circle is set at \(\Phi = 0\) while the botoom half is fixed at \(\Phi  = 1\). In this case we can consider the Mobius transformation 

\begin{equation}
    z = \frac{i-w}{i+w}, 
\end{equation}

where we have chosen \(e^{i \theta _{0} } = -1 \text { and } w_{0} = i\) so that the positive \(x\)-axis is mapped to the top half of the cylinder and the negative \(x\)-axis the bottom half. 

Now the real potential function can be represented by 

\begin{equation}
    \Phi  = \frac{\arg (w)}{\pi }. 
\end{equation}

On the positive \(x\)-axis we have \(\arg (w)\) = 0 and hence \(\Phi  = 0\) while on the negative \(x\)-axis we have \(\arg (w) = \pi \) and hence \(\Phi  = 1\).  

The complex function is thus 

\begin{equation}
    f = -\frac{i}{\pi } \ln  w = -\frac{i}{\pi }\ln \left( i \frac{1-z}{1+z}  \right).
\end{equation}

Therefore the real potential is 

\begin{equation}
    \Phi  = \mathfrak{Re} (f) = \frac{1}{\pi } \tan ^{-1} \left( \frac{1-x^2-y^2}{2y}  \right).
\end{equation}



\section{Singularities}

\subsection{Definitions}

As we have defined eariler, a singulartiy is a point on the complex plane, where \(f(z)\) fails to be analytic. It can either be an isolated singularity, which includes a pole, a removable singularity and an essential singularity, or a non-isolated singularity.\footnote{NOte that a function is not necessarily infinite at a singularity. For instance the function \(f(z) = z^2 f\text { or } yge_0 , z f\text { or }  y < 0\) is singular at all points on the \(x\)-axis, but has the value \(z^2=x^2\) at these points.} 

Formally, if the limit of a function \(\lim_{z \to z_0 } f(z)\) does not exist but satisfies

\begin{equation}
    \lim_{z \to z_0 } ((z-z_0 )^{n}f(z) ) = a, \label{lim} 
\end{equation}

then \(z = z_0 \)  is a pole of order \(n\) and \(a \equiv \text{Res}(f,z) \) is the residue of \(f(z)\) if \(n =1\).\footnote{The formula for finding the residue with pole of any order will be introduced later.} If no finite value of \(n\) can be found such that this equation is satisified then \(z = z_0 \) is called an essential singularity. A non-isolated singularity occurs when poles accumluates together at one point.

If the limit \(\lim_{z \to z_0 } f(z)\) exists and unique then \(z = z_0 \) is called a removable singularities.  

The behaviour of a function \(f(z)\) at \(z = \infty\) is the same as the behaviour of the function \(f(1 /\xi )\) at \(\xi  = 0\).   

\subsection{Poles}

A pole is a point on the complex plane where the derivative \(df /dz\) is infinite.\footnote{In most cases however this is equivalent to \(f(z)\) being infinite.} A simple example is

\begin{equation}
    f(z) = \frac{1}{z}, 
\end{equation}

which has a pole at \(z = 0\) with order \(1\).

For another example the function

\begin{equation}
    f(z) = \frac{1}{(z-a)^{n} }
\end{equation}

has a pole at \(z = a\) with order \(n\). 

\subsection{Removable Singularities}

A removable singularity is one that has a finite limit at the singularity, so the function can be rendered completely analytic by setting \(f(z_0 ) = \lim_{z \to z_0 } f(z) \), for example,

\begin{equation}
    f(z) = \frac{\sin z}{z} 
\end{equation}

has a singularity at \(z = 0\), but can be easily removed by setting \(f(0) = 1\). Note that the function do not exist at removable singularity but the limit exists.

The behaviour of a function \(f(z)\) at infinity is given by that of \(f(1 /\xi )\) at \(\xi =0\), where \(\xi \equiv 1 /z\).   

\subsection{Essential Singularities}

A singularity which is neither removable or a pole is known as an essential singularity. A particularly notorious example is 

\begin{equation}
    f(z) = e^z.
\end{equation}

To analyse the function's behaviour at \(z = \infty\), consider the function \(f(1/\xi )\) at \(\xi =0\)

\begin{equation}
    f\left( \frac{1}{\xi }  \right) = e^{1/\xi } = \sum_{n=0}^{\infty} \frac{1}{\xi ^{n} n! }.  
\end{equation}

We have \(\xi =0\) as a pole with infinite order thus \(z = 0\) is an essential singularity.

\subsection{Non-isolated Singularities}

For the function 

\begin{equation}
    f(z) = \frac{1}{\sin (1 /z)}, 
\end{equation}

we have poles at \(z = 1/n \pi \) of order 1. However, at \(z = 0\) the poles accumulate together so we call the singularity at \(z = 0\) a non-isolated one.

Another example of a non-isolated singularity is the fucntion 

\begin{equation}
    f(z) = \tan z 
\end{equation}

at \(z = \infty\). This is because the function 

\begin{equation}
    f\left( \frac{1}{\xi }  \right) = \tan \left( \frac{1}{\xi }  \right) = \sum_{n=0}^{\infty} a_{2n-1} \xi ^{1-2n},  
\end{equation}

which has a pole of infinite order at \(\xi = 0\). 

\example{Singularities (1).}
{Find the singularities of the function

\begin{equation}
    f(z) = \tanh z.
\end{equation}
~
}
{We rewrite the function as 

\begin{equation}
    f(z) = \tanh z = \frac{e^{z}-e^{-z}  }{e^{z}+e^{-z}  }. 
\end{equation}

Therefore \(f(z)\) has a singularity when

\begin{equation}
    e^{z} = - e^{-z} = e^{i(2n+1)\pi -z} \implies z = \left( n+\frac{1}{2}  \right) \pi i.   
\end{equation}



} 

\example{Singularities (2).}
{Locate and classify the singular points of 

\begin{equation}
    f(z) = \frac{1}{z^2(1+e^{1 /z} )}.
\end{equation}
~
}
{At \(z = 0\), \(e^{1/z} \) has an essential singularity, so \(f(z)\) is essential at 0. Whenever \(1+e^{1/z} = 0\), or \(z = 1/i \pi (2k+1)\), we have simple poles. However we also find that there are infinite simple poles at \(z = 0\), so it is in fact a non-isolated singularity.}


\section{Branch Points, Branch Cuts, Principal Branch and Riemann Surface}

\subsection{Branch Points, Branch Cuts and Principal Branch}

In the definition of an analytic function, one of the conditions imposed was that the function is sinlge-valued. Nevertheless, it happens that the properties of analytic functions can still be applied to multi-valued functions provided that suitable care is taken. 

\subsubsection{Branch Points}

For a complex vector \(z\)

\begin{equation}
    z = re^{i \theta }, \quad \theta  = \theta _{0} + 2\pi k , \quad \theta _{0} \in (-\pi ,\pi ] \text { and } k \in \mathbb{Z},  
\end{equation}

the square root of \(z\) is

\begin{equation}
    f(z) = z^{1/2} = r^{1 /2} e^{i \theta /2}.
\end{equation}

It is clear that as the point \(z\) traverses any closed contour \(C\) that does not enclose the origin, \(\theta \) will return to its original value after one complete circuit. However, for any closed contour \(C'\) that does enclose the origin, after one circuit we have 

\begin{equation}
    \theta \to \theta +2\pi \implies f(z) \to -f(z).
\end{equation}

We call \(z = 0\) the branch point \(f(z)\) with order 1, since the function return to its original value after 2 loops (which is the minimum number of loops).

In fact any non-integer powers are multivalued, since it can always be written as \textit{e.g.,} \(z^{21/8} \), which involves the \(8^{\text{th} } \) root function. 

Further, infinity is also a second order branch point for \(f(z) = z^{1 /2} \), as \(\xi =0\) is a branch point of \(f(\xi ) = \xi ^{- 1/2} \), by the same argument as above.  

In general the function \(G(z)^{1/n} \) has branch points at \(G(z) = 0 \text { or } \infty\) with \(n\) order.

Now consider the logarithm of a complex vector

\begin{equation}
    f(z) = \ln z = \ln r + i \theta .
\end{equation}

With the same arguements as when we analyzed the square root function, \(z = 0 \text { and } \infty\) are branch points of the function. They have \(\infty\) order, since the function would not return to its original value no matter how many loop one transverse. In general, the function \(\ln (G(z))\) has branch points at \(G(z) = 0 \text { or } \infty\) with \(\infty\) order.   

To prove that a point is a branch point you consider a loop \(z = z_0 + \epsilon e^{i \theta } \) around the point of interest and determine whether \(z\) would change its value after \(\theta \) goes from 0 to \(2\pi \).   

\subsubsection{Branch Cuts}

So now imagine a complex vector a complex plane. If we apply any multivalued function to this vector, \textit{e.g.,} the square root function or the logarithm function, the vector will be splitted into several other image vectors, this is because the argument of the vector \(\arg (z) = \theta \) is ill-defined. For a concrete picture, the complex vectors \(z_1 = e^{i \pi /4} \text { and } z_2 = e^{i 9\pi /4} \) sit on the same place on the copmlex plane but when the square root function is applied the two vectors are mapped to different places \(z_1 ' = e^{i \pi /8} \text { and } z_2 ' = e^{i 9 \pi /8} \), in completely oposite direction. Other vectors which are orginally at the same place as \(z_1 \text { and } z_2 \) will get mapped either to \(z_1 ' \text { or } z_2 '\).

In order for \(f(z)\) to be treated as a single-valued function, we may define a branch cut, which is a curve in the complex plane that serves as an articficial barrier that we must not cross, preventing one from making a complete circuit around any branch point. 

For the both of the functions above \(f(z) = z^{1/2} \text { or } \ln z\), the branch cut can be any curve starting at the origin \(z = 0\) and extending out to \(\abs{z} = \infty \) in any direction, restricting \(\theta \) to lie in the range \(\theta \in (-\pi ,\pi ]\). 

\subsubsection{Principal Branch}

A branch is a single-valued choice of the multi-valued function on the complex plane with the branch cut. The principal branch is the standard and most commonly used branch. For both the functions \(f(z) = z^{1 /2} \text { and }  f(z) = \ln z \), the principal branch is obtained by cutting along the negative \(x\)-axis, and taking the argument as \(\arg (z) \in (-\pi ,\pi )\).   

\subsubsection{Riemann Surfaces}

Alternatively we can also introduce a Riemann surface. For examples, the Riemann surface of \(f(z) = \ln z\) is shown in \cref{logz} and that of \(f(z) = z^{1 /2} \) is shown in \cref{sqrtz}.

For the complex logarithm, we cut the complex plane along \(x > 0\) one edge of the first copy to one edge of another copy. On the first sheet we have \(0 \le \theta \le 2\pi \), and on the second sheet we have \(2\pi \le \theta \le 4\pi \) \textit{etc.} The infinite sheets required shows that the logarithmic function is infinitely-multivalued.

For the square root function, we start off the same way but after that we take the \(y<0\) edge of the second copy and glue it back onto the \(y >0\) edge of the first one. For the general \(f(z) = z^{ 1/n} \), we stack \(n\) copies of the complex plane before wrapping the last one onto the first one. On the first sheet then we have \(0 \le \theta \le 2\pi , 2\pi n \le \theta \le 4\pi n, \textit{etc.} \).   

\twofig{logz}{width=\textwidth}{sqrtz}{width=\textwidth}{logsqrtz} 

\example{Branch Points, Branch Cuts and Riemann Surfaces (1).}
{Find the location and order of the branch points of the function

\begin{equation}
    f(z) = \sqrt{z^2+1}, 
\end{equation}

and hence sketch suitable arrangements of branch cuts and describe the Riemann surfaces.}
{We begin by writing \(f(z)\) as 

\begin{equation}
    f(z) = \sqrt{z^2+1} = \sqrt{(z+i)(z-i)}.  
\end{equation}

We expect \(f(z)\) to have branch points at values of \(z\) that make the expression under the square root equal to zero, \textit{i.e.,} at \(z = i \text { and } z = -i\), and they are first order branch points.

To prove that they are indeed the branch points, we let 

\begin{equation}
    z - i  = r_1 e^{i \theta _{1} } ~\text { and }~ z+i = r_2 e^{i \theta _{2} } \implies f(z) = \sqrt{r_1 r_2 } e^{i(\theta _{1}+\theta _{2}  ) /2},     
\end{equation}

then we have the four cases: If \(C\) encloses

\begin{enumerate}
    \item neither branch points, then \(\theta _{1} \to \theta _{1} \text { and } \theta _{2}\to \theta _{2}    \) and so \(f(z) \to f(z)\);
    \item \(z = i\) but not \(z = -i\), then \(\theta _{1} \to \theta _{1}+2\pi   \text { and } \theta _{2} \to \theta _{2}  \) and so \(f(z) \to -f(z)\);
    \item \(z = -i\) but not \(z = i\), then \(\theta _{1} \to \theta _{1} \text { and } \theta _{2} \to \theta _{2} + 2\pi     \) and so \(f(z) \to -f(z)\); 
    \item both branch points, then \(\theta _{1} \to \theta _{1} + 2\pi   \text { and } \theta _{2} \to \theta _{2} + 2\pi   \) and so \(f(z) \to f(z)\).
\end{enumerate}

From this the suitable cuts are shown in \cref{cut1}.

The Riemann surface consists of two complex plane, each cut along the branch cut mentioned, with one edge of the first copy glued to the opposite edge of the second copy and vice versa.

Note that infinity is not a branch point, since at \(z \gg 1\), we have \(f(z) \approx z = \abs{z}e^{i \theta }  \), which does not flips the sign of \(f(z)\) as \(\theta  \to \theta + 2\pi \). 

Alternatively, we can see this by consider \(f(1 /\xi )= \sqrt{1+\xi ^2} /\xi  \), which does not have \(\xi = 0\) as one of its branch points. 
} 

\onefig{cut1}{scale=0.3} 

\example{Branch Points, Branch Cuts and Riemann Surface (2).}
{Find the location and order of the branch points of the function 

\begin{equation}
    w = (z-1)^{1 /3}
\end{equation}

and describe a branch cut. 

Describe a Riemann surface for this function and determine the image of each Riemann sheet in the \(w\) plane.
}
{\(z = 1 \text { and } \infty\) are second order branch points. A branch cut is a ray from \(z = 1\) to \(z = \infty\).

The Riemann surface consists of three sheets \(R_0 ,R_1 ,R_2 \) each cut along the chosen branch cut above, where the upper edge cut in \(R_2 \) is joined back to the lower edge cut in \(R_0\).

On sheet \(k\), we have 

\begin{equation}
    z-1 = re^{i \theta }, \quad \theta \in (2\pi k, 2\pi (k+1)), 
\end{equation}

so after the mapping we have

\begin{equation}
    w = (z-1)^{1 /3} = r^{1/3} e^{i \theta /3} \implies \arg (w) = \theta /3 \in \left( \frac{2\pi k}{3}, \frac{2\pi (k+1)}{3}   \right).
\end{equation}

Therefore \(R_0 \) gets mapped to \(0 < \arg (w) < 2\pi /3\), \(R_1 \) gets mapped to \(2\pi /3 < \arg (w) < 4\pi /3\) and \(R_2 \) gets mapped to \(4\pi /3 < \arg (w) < 2\pi \).      

In this way the full Riemann surface \(z\) covers the entire \(w\) plane exactly once through \(w(z)\), making the cube root a single-valued function.
}

\example{Branch Points and Principal Branch.}
{Show that the inverse sine function is given by 

\begin{equation}
    f(z) = \sin ^{-1} (z) = -i \ln (iz + \sqrt{1-z^2}). 
\end{equation}

Give the location and order of the branch points of this function.

Consider the branch of \(f(z)\) with the branch cut from -1 to \(-\infty\) and from \(+1\) to \(+\infty\). Taking the principal branch of the logarithm and the square root, determine the value of \(f(z)\) at the point \(z = 3\).       
}
{We have

\begin{equation}
    z = \sin w = \frac{e^{iw}-e^{-iw}  }{2i} \implies e^{iw} = iz \pm \sqrt{1-z^2} \implies \sin ^{-1} z = w = -i \ln (iz + \sqrt{1-z^2} ). \label{sin}  
\end{equation}

Note that we have neglected the \(\pm \) sign in the final expression. This is because the \(\pm \) sign is in fact comes from the multivaluedness of the square root function and by choosing the principal branch we only care about the plus sign. 

This is why we say \(\sqrt{4} =2 \) but solving \(x^2=4\) gives \(x = \pm 2\). Similarly, by choosing the principal branch the \(\sin ^{-1} (z)\) function is single-valued, however if we are told to solve the equation \(\sin z = a\) we would need to say \(z = \sin ^{-1} (a) + 2\pi n \text { or } \pi -\sin ^{-1} (a) + 2\pi n\).   

The branch point of this function is \(z = \pm 1\) due to the square root, and they are first order. Equating the expression inside the logarithm to be zero also gives \(z = \pm 1\), which gives not extra branch points. Note that \(z = \infty\) is not a branch point of \(f(z)\) since \(\xi = 0\) is not a branch point of \(f(1 /\xi )\).

Taking the principal branch we have 

\begin{equation}
    f(3) = -i \ln (3i +2\sqrt{2}i ) = -i \ln i - i \ln (3+2\sqrt{2} ) = \frac{\pi }{2} - i \ln (3+2 \sqrt{2} ). 
\end{equation}
~
} 



\section{Integration}

\subsection{Cauchy's Theorem}

Since the complex plane is two-dimensional we can talk about the contour integral 

\begin{equation}
    \int_{C}^{} f(z) dz = \int_{C}^{} (u+iv)(dx+idy) = \int_{C}^{} (udx-vdy) + i\int_{C}^{} (vdx+udy).   
\end{equation}

The Cauchy's theorem states that if \(f(z)\) is an analytic function in a region \(R\) enclosed by a contour \(C\), then 

\begin{equation}
    \oint_{C} f(z)dz = 0. \label{cau} 
\end{equation}

This is because using the Stokes' theorem we have 

\begin{equation}
    \begin{aligned} 
    \oint_{C}f(z) dz &= \oint_{C} (udx-vdy) + i \oint_{C} (vdx+udy) =\\
    & \int_{S}^{} \left( -\frac{\partial u}{\partial y} - \frac{\partial v}{\partial x}  \right) dxdy + i \int_{S}^{} \left( -\frac{\partial v}{\partial y} + \frac{\partial u}{\partial x}   \right)  dxdy = 0,
    \end{aligned} 
\end{equation}

according to the Cauchy-Riemann conditions.

By the usual argument in vector calculus since the loop integral vanishes the path integral is path independent, \textit{i.e.,} 

\begin{equation}
    \int_{C}^{} f(z)dz = \int_{C'}^{} f(z)dz.  
\end{equation}



\example{Fourier Transform of the Gaussian.}
{Evaluate the integral

\begin{equation}
    \int_{-\infty}^{+\infty} e^{-x^2} \cos (2kx)dx.   
\end{equation}
~
}
{The integral can be rewritten as a complex integral by 

\begin{equation}
    \int_{-\infty}^{+\infty} e^{-x^2} \cos (2kx)dx = \mathfrak{Re} \left( \int_{-\infty}^{+\infty} e^{-x^2} e^{-2ikx}     \right). 
\end{equation}

Normally we would take a change of variables \(u=x+ik\) and wave our hands into doing the integral on the real line. 

To do this formally we consider the contour shown in \cref{handwave}. The integral around the contour is zero since the function is analytic, so we have

\begin{equation}
    \oint_{\Gamma } e^{-z^2} dz = \int_{-R}^{R} e^{-x^2}dx + \int_{0}^{k} e^{-(R+iy)^2}dy + \int_{R}^{-R} e^{-(x+ik)^2} dx + \int_{k}^{0} e^{-(-R+iy)^2} dy.          
\end{equation}

When \(R \to \infty\) we get rid of the integrals associated to paths \(\ell _{-} \text { and } \ell _{+}  \). Flipping the order of integration in the third integral gives 

\begin{equation}
    \int_{-\infty}^{+\infty} e^{-(x+ik)^2} dx  = \int_{-\infty}^{+\infty} e^{-x^2}dx = \sqrt{\pi }.      
\end{equation}

Taking the real part we find the integral desired to be 

\begin{equation}
    \int_{-\infty}^{+\infty} e^{-x^2} \cos (2kx)dx = e^{-k^2}\sqrt{\pi }. 
\end{equation}
~
} 

\onefig{handwave}{scale=0.3} 

\example{Fresnel's Integrals.}
{Consider the intagral of the function \(f(z) = e^{iz^2} \) round the closed path \(\Gamma \) in the complex \(z\) plane given in \cref{fres} 

\begin{equation}
    \oint_{\Gamma } e^{iz^2}dz.  
\end{equation}

Evaluate this integral for arbitrary \(R > 0\).

Consider the third line segement \(\Gamma _{3} \), joining the points \(z = Re^{i \pi /4} \text { and } z = 0\). Evaluate this integral for \(R \to \infty\).

Consider the second line segement \(\Gamma _{2} \), along the circular arc between the points \(z = R \text { and } z = Re^{i \pi /4} \). Show that this integral vanishes for \(R \to \infty\).

Use the results to comupute the Fresnel's integrals

\begin{equation}
    \int_{0}^{\infty} \cos (x^2)dx ~\text { and }~ \int_{0}^{\infty} \sin (x^2)dx.    
\end{equation}
~
}
{Since \(f(z)\) is entire, \textit{i.e.,} analytic everywhere, so from Cauchy's Theorem we have

\begin{equation}
    \oint_{\Gamma } e^{iz^2} = 0.  
\end{equation}

We parameterize \(\Gamma _{3} \) by \(z = re^{i \pi /4} \), then the integral becomes 

\begin{equation}
    \int_{\Gamma _{3} }  e^{i z^2}dz = \int_{0}^{R} e^{i r^2 e^{i \pi /2} } (e^{i \pi /4}dr ) = e^{i \pi /4} \int_{0}^{\infty} e^{-r^2}dr = e^{i \pi /4} \frac{\sqrt{\pi } }{2}.  
\end{equation}

We parameterize \(\Gamma _{2} \) by \(z = Re^{i \theta } \), then

\begin{equation}
    \abs{e^{iz^2} } = \abs{e^{i R^2 (\cos 2\theta + i \sin 2\theta )} } = e^{-R^2\sin 2\theta }  \implies \text{max}(\abs{f(z)})= e^{-R^2}.  
\end{equation}

Using the ML inequality we have 

\begin{equation}
    \abs{\int_{\Gamma _{2} }^{} e^{i z^2}dz } \le (\text{max} (\abs{f(z)} ))  (\text{length of } \Gamma _{2} ) = e^{-R^2} \left( \frac{\pi R}{4}  \right).
\end{equation}

As \(R \to \infty\), we get the integral to be zero as desired since the exponential term \(e^{-R^2} \) grows faster than the counteracting \(R\).

From above we conclude that 

\begin{equation}
    \begin{aligned} 
    \oint_{\Gamma }e^{i z^2}dz &= \int_{\Gamma _{1} }^{} e^{i z^2} dz + \int_{\Gamma _{2} }^{} e^{i z^2}dz + \int_{\Gamma _{3} }^{}   e^{i z^2}dz = 0 \\
    \int_{0}^{\infty} e^{i x^2}dx &= e^{i \pi /4} \frac{\sqrt{\pi } }{2}.
    \end{aligned}       
\end{equation}

Taking the real and imaginary part we have

\begin{equation}
    \int_{0}^{\infty} \cos (x^2)dx = \frac{\sqrt{2\pi } }{4} = \int_{0}^{\infty} \sin (x^2)dx.     
\end{equation}
~
} 

\onefig{fres}{scale=0.3} 


\subsection{Cauchy's Integral Formula}\todo{Poisson's integral formula} 

In the previous subsection we consider the loop integral of \(f(z)\) alone (\cref{cau}). Now consider the integral of \(f(z) /(z-a)\) around a circle \(C\) centered at \(z = a\) with radius \(R\) 

\begin{equation}
    \oint_{C} \frac{f(z)}{z-a}dz = \oint_{C} \frac{f(a+Re^{i \theta } )}{R e^{i \theta } } i Re^{i \theta } d \theta = i \oint_{C} f(a + Re^{i \theta } ) d \theta ,
\end{equation}

which is analytic everywhere in the contour \(C\) except at \(z = a\). 

By the reasoning from the previous section \(R\) can take any value we want. Taking the limit as \(\epsilon \to 0\) yields 

\begin{equation}
    f(a)2\pi i = i \oint_{C} f(a+Re^{i \theta } )d \theta \implies f(a) = \frac{1}{2\pi } \oint_{C} f(a+Re^{i \theta } ) d \theta . 
\end{equation}

This is is known as the Gaussian mean-value theorem, which states that the average of an analytic function over a circle is equals to its value at the center.

Since the real part of any analytic function is harmonic, taking the real part of the Gaussian mean-value theorem we have that the average of any harmonic function over a circle is equals to its value at the center, coinciding with our understanding of the solution to the Laplace's equation.

Taking the same limit also gives

\begin{equation}
   f(a) =  \frac{1}{2\pi i}  \oint_{C} \frac{f(z)}{z-a} dz .  \label{cau2} 
\end{equation}

This is known as the Cauchy's integral formula, which states that we can know the value of any point of a function as long as we have know the value of the function at the contour, which is any circle centered at the point at interest.

Note that this is sipmly a special case of the Caucny's residue theorem, since the integral is since the integrand has a simple pole at \(z = a\), so the integral is just \(2\pi i f(a)\).   

Further we can determine the value of any derivative of \(f(a)\) from 

\begin{equation}
    f^{(n)}(a) = \frac{n!}{2\pi i} \oint_{C} \frac{f(z)}{(z-a)^{n+1} } dz. 
\end{equation}

Note that we are differentiating \(f(a)\) with respect to \(a\) since now \(a\) is the real variable and \(z\) is just a dummy variable in the integration. 

The taylor expansion around \(a\) is therefore 

\begin{equation}
    \begin{aligned}
        f(a+\epsilon) &= \frac{1}{2\pi i}\oint_C \frac{f(z)}{z - a - \epsilon}\,dz = \frac{1}{2\pi i}\oint_C \frac{f(z)}{(z - a)\bigl(1 - \frac{\epsilon}{z-a}\bigr)}\,dz \\
&= \frac{1}{2\pi i}\oint_C \frac{f(z)}{z - a}  \sum_{n=0}^{\infty} \frac{\epsilon^n}{(z - a)^n}\,dz  \\
&= \sum_{n=0}^{\infty} \epsilon ^{n} \frac{1}{2\pi i} \oint_{C} \frac{f(z)}{(z-a)^{n+1} } dz \\
&= \sum_{n=0}^{\infty} \frac{f^{(n)}(a) }{n!} \epsilon ^{n}.      
    \end{aligned}
\end{equation}

\example{Liouville's Theorem}
{Show that every bounded entire function must be constant.}
{From the Cauchy;s formula we have 

\begin{equation}
    f'(z_0 ) = \frac{1}{2\pi i} \oint_{\gamma _{R} } \frac{f(z)}{(z-a)^2} dz,   
\end{equation}

where \(\gamma _{R} \) is a circle centered at \(z = a\) with radius \(R\).

Applying the ML inequality we have 

\begin{equation}
    \abs{f'(z_0 )} \le (\max (\abs{f(z)} )) (\text{length of } \gamma _{R} ) = \frac{1}{2\pi } MR^{-2} (2\pi R) = \frac{M}{R}.   
\end{equation}

As \(R \to \infty\), \(f'(z_0 ) \to 0\), therefore \(f(z) = 0\) since \(z_0 \) is arbitrary.   
} 

\example{Gassian Mean-Value Theorem.}
{Evaluate the follwoing integrals

\begin{equation}
    I_1 = \int_{0}^{2\pi } \cos (\cos \theta ) \cosh (\sin \theta ) d \theta ~\text { and }~ I_2 = \int_{0}^{2\pi } \sin (\cos \theta ) \sinh (\sin \theta ) d \theta .   
\end{equation}
~
}
{First we notice that 

\begin{equation}
    I_1 + iI_2 = \int_{0}^{2\pi } \cos (\cos \theta + i \sin \theta ) d \theta = \int_{0}^{2\pi } \cos (e^{i \theta } ) d \theta .    
\end{equation}

To evaluate the last integral we have 

\begin{equation}
    \int_{0}^{2\pi } \cos (e^{i \theta } ) d \theta = \frac{1}{2} \int_{0}^{2\pi } \sum_{n=0}^{\infty} \frac{i ^{n} e^{i n \theta } + (-i)^{n} e^{i n \theta }}{n!} = \frac{1}{2} (1+1) (2\pi ) = 2\pi ,     
\end{equation}

where we have used the well known 

\begin{equation}
    \int_{0}^{2\pi } e^{in \theta } = 2\pi \delta _{n,0}.   
\end{equation}

Taking the real and imaginary part we conclude that \(I_1 = 2\pi \text { and } I_2 = 0\).

Alternatively, we can evaluate the integral directly using the Gaussian mean-value theorem

\begin{equation}
    \cos (0) = \frac{1}{2\pi i} \oint_{C} \frac{\cos z}{z}dz = \frac{1}{2\pi } \int_{0}^{2\pi } \cos (e^{i \theta } ) d \theta = 1,
\end{equation}

and get the same result from here on out.
} 



\subsection{Laurent Expansion}

Taylor expansion still works in the complex plane and we can expand the function about any point, but it would only converge inside the circular disc with radius smaller than the radius of convergence (the distance from the point of expansion to the nearest sigularity). Outside this disc we would need the Laurent expansion.

For a function \(f(z)\) which has a pole of order \(p \) at \(z = a\), we known from \cref{lim} that \(g(z) = (z-a)^{p} f(z) \) is analytic at \(z  = a\) and we can Taylor expand around this pole to get

\begin{equation}
    g(z) = (z-a)^{p} f(z) =  \sum_{n=0}^{\infty} b_{n} (z-a)^{n} \implies f(z) = \sum_{m=-p}^{\infty} a_{m} (z-a)^{m}.   
\end{equation}

This expansion which contains negative power of \(z-a\) is called the Laurent expansion. This part of the series which only contains negative power of \(z-a\) is called the principal part. We also note that the residue of the function is given by the coefficient \(\text{Res}(f,a) = a_{-1} \). 

Since we have 

\begin{equation}
    b_{n} = \frac{g^{(n)}(a) }{n!},
\end{equation}

we get the general formula for finding the residue as 

\begin{equation}
    \text{Res}(f,a) = a_{-1} = b_{p-1} = \frac{g^{(p-1)}(a) }{(p-1)!} = \frac{1}{(p-1)!} \lim_{z \to a} \left( \frac{d^{p-1} }{dz^{p-1} } ((z-a)^{p}f(z) )  \right).
\end{equation}

For a simple pole \(p = 1\) and we simply have 

\begin{equation}
    \text{Res} (f,a) = \lim_{z \to a} (z-a)f(z). 
\end{equation}

If the integrand is in the form 

\begin{equation}
    f(z) = \frac{g(z)}{h(z)}, 
\end{equation}

with a sipmle pole at \(z = a\), then the residue is 

\begin{equation}
    \begin{aligned} 
    \text{Res}(f,a) &= \lim_{z \to a} \left( (z-a)f(z) \right)\\
    &= \lim_{z \to a} \left( g(z) \left( \frac{z-a}{h(z)+h'(z)(z-a)+h''(z)(z-a)^2/2 + \cdots }  \right) \right) \\
    &= g(a) \lim_{z \to a} \left( \frac{1}{0 + h'(z) + h'(z)(z-a)/2 + \cdots }  \right) = \frac{g(a)}{h'(a)}. 
    \end{aligned} 
\end{equation}

However, if the pole is not simple then we would still require more deatiled analysis using the Laurent Expansion but the idea stands: expand the denominator about the pole using Taylor expansion and inverting the denominator.




\example{Laurent Expansion about a Pole.}
{Find the Laurent expansion of the fucntion 

\begin{equation}
    f(z) = \frac{(z+1)^2}{(z-1)^2} 
\end{equation}

about the pole \(z = 1\). 
}
{To obtain the Laurent expansion about the pole at \(z = 1\) we rewrite the function \(f(z)\) in terms of the variable \(z-1\)  

\begin{equation}
    f(z) = \frac{(z+1)^2}{(z-1)^2} = \frac{(z-1+2)^2}{(z-1)^2} = \frac{(z-1)^2+2(z-1)(2)+2^2}{(z-1)^2} = \frac{4}{(z-1)^2} + \frac{4}{z-1} + 1.
\end{equation}
} 

\example{Laurent Expansion about the Origin.}
{Find the Laurent expansion for the function

\begin{equation}
    f(z) = \frac{1}{(z+1)(z+3)} 
\end{equation}

\begin{enumerate}
    \item about the origin in the disk \(\abs{z} < 1 \);
    \item about the origin in the annulus \(1  < \abs{z} <3\);
    \item about the origin in the region \(\abs{z} > 3\);
    \item about the pole \(z = -1\) and give its region of convergence.
\end{enumerate}
~
}
{First it is easiest to begin with the partial fraction decomposition

\begin{equation}
    f(z) = \frac{1}{(z+1)(z+3)} = \frac{1}{2} \frac{1}{z+1} - \frac{1}{2} \frac{1}{z+3}.    
\end{equation}

\begin{enumerate}
    \item For \(\abs{z} <1 \), the Laurent series is the usual Taylor series 

    \begin{equation}
        f(z) = \frac{1}{2} \sum_{n=0}^{\infty} (-1)^{n} z^{n} -\frac{1}{2}  \sum_{n=0}^{\infty} (-1)^{n} \frac{z^{n} }{3^{n+1} } = \frac{1}{2} \sum_{n=0}^{\infty} (-1)^{n} (1-3^{-(n+1)} ) z^{n} .  
    \end{equation}

    \item For \(1 < \abs{z} < 3\), the Laurent series is found by expanding the first fraction in negative powers and the second fraction as usual
    
    \begin{equation}
        f(z) = \frac{1}{2z} \frac{1}{1+1 /z} - \frac{1}{2} \frac{1}{z+3} = \frac{1}{2} \sum_{n=0}^{\infty} (-1)^{n} z^{-(n+1)} - \frac{1}{2} \sum_{n=0}^{\infty} (-1)^{n} \frac{z^{n} }{3^{n+1} }.         
    \end{equation}

    \item For \(\abs{z} > 3\), we expand both fractions in negative powers
    
    \begin{equation}
        \begin{aligned} 
        f(z) &= \frac{1}{2z} \frac{1}{1+1 /z} - \frac{1}{2z} \frac{1}{1+3 /z} \\
        &= \frac{1}{2} \sum_{n=0}^{\infty} (-1)^{n}z^{-(n+1)} - \frac{1}{2} \sum_{n=0}^{\infty} (-1)^{n} 3^{n} z^{-(n+1)} \\
        &= \frac{1}{2} \sum_{n=0}^{\infty} (-1)^{n} (1-3^{n} ) z^{-(n+1)}.
        \end{aligned}             
    \end{equation}
    
    \item About the pole \(z = -1\) we let \(w = z+1\) and get 
    
    \begin{equation}
        f(z) = \frac{1}{w(w+2)} = \frac{1}{2w} \sum_{n=0}^{\infty} (-1)^{n} \left(\frac{w}{2} \right)^{n} = \sum_{n=0}^{\infty} (-1)^{n} \frac{(z+1)^{n-1} }{2^{n+1} }.      
    \end{equation}

    The radius of convergence is \(0 < \abs{z+1} <2 \). 
\end{enumerate}
~
} 

\example{Laurent Expansion about an Essential Singularity.}
{Determine the Laurent Expansion of the function 

\begin{equation}
    f(z) = (z-3) \sin \left( \frac{1}{z+2}  \right)
\end{equation}

about the point \(z=-2\).
}
{We let \(w = z+2\) and rewrite the function as 

\begin{equation}
    \begin{aligned} 
    f(z) &=  (w-5) \sin \left( \frac{1}{w}  \right) = (w-5)  \sum_{n=0}^{\infty} (-1)^{n} \frac{w^{-(2n+1)}}{(2n+1)!}\\
    & = \sum_{n=0}^{\infty} (-1)^{n} \frac{(z+2)^{-2n} - 5(z+2)^{-(2n+1)}  }{(2n+1)!}.      
    \end{aligned} 
\end{equation}

As we see there can be a Laurent expansion about an essential singularity, but not for a non-isolated singularity.
~
} 




\subsection{Cauchy's Residue Theorem}

Consider the following integral

\begin{equation}
    \oint_{C} (z-a)^{n} dz, 
\end{equation}

where \(C\) is a circle centered at \(z = a\) with an infinitesimal radius \(z = a+\epsilon e^{i \theta } \). We then have

\begin{equation}
    \oint_{C} (z-a)^{n} dz = i \int_{0}^{2\pi } \epsilon ^{n+1} e^{i(n+1)\theta } d \theta = \begin{cases}
        0,& n \neq -1,\\
        2\pi i,& n = -1.
    \end{cases}
\end{equation}

We can now use this fact to calculate such integral for an \(f(z)\) which has a Laurent expansion

\begin{equation}
    \oint_{C} f(z)dz = \sum_{n=-p}^{\infty} a_{n} \oint_{C} (z-a)^{n} dz = 2\pi i a_{-1}.
\end{equation}

In other words, the contour integral for a function \(f(z)\) around a loop that contains a pole is simply given by the residue of the pole (upto a factor of \(2\pi i\)). This is known as the Cauchy Residue Theorem.

If the contour encloses \(N\) poles at \(z = w_{k} \) then we have the general

\begin{equation}
    \oint_{C} f(z)dz = 2\pi i \sum_{k=1}^{N} \text{Res}(f,w_{k} ). 
\end{equation}

\example{Cauchy's Residue Theorem (1).}
{Evaluate the integral 

\begin{equation}
    \oint_{C} \frac{z+1}{z(z^2+1)}dz,
\end{equation}

where \(C\) is the circle centered at \(z = 0\) with radius \(2\). 
}
{We see that the integrand has 3 poles at \(z_0 =0 \text { and } \pm i\). To find the residues of each of these poles we use partial fraction to rewrite the integrand as 

\begin{equation}
    \frac{z+1}{z(z^2+1)} = \frac{1}{2} (z+1)\left( \frac{2}{z} - \frac{1}{z+i} - \frac{1}{z-i}    \right)
\end{equation}

and directly read off the residues using \cref{lim} as \(1,-(1+i)/2 \text { and } -(1-i) /2\), respectively.

Alternatively, we can find the residues in a more general way by considering the Laurent expansion at each poles. However, since all the poles here are first order using \cref{lim} is the fastest method. In fact, the partial fraction decomposition above is not even necessary.

Applying the Cauchy's residue theorem we have that 

\begin{equation}
    \oint_{C} \frac{z+1}{z(z^2+1)}dz = 2\pi i\left( 1 - \frac{1+i}{2} - \frac{1-i}{2}   \right) = 0.
\end{equation}
~
}

\example{Cauchy's Residue Theorem (2).}
{Evaluate the integral 

\begin{equation}
    \oint_{C} \frac{e^{1/z} }{z^2-1}, 
\end{equation}

where \(C\) is a circle centered at \(z = 1\) with radius \(3 /2\).  
}
{The sigularties are that lie inside \(C\) are \(z = 0 \text { and } z = 1\), which are essential singularity and a sipmle pole respectively. 

For \(z = 1\) we find the residue simply from \cref{lim} as 

\begin{equation}
    \text{Res}(f,1) = \lim_{z \to 1} (z-1)\frac{e^{1 /z} }{(z-1)(z+1)} = \frac{e}{2}.   
\end{equation}

For \(z = 0\) we expand the numerator with the Laurent series and the denominator with the usual Taylor series to get

\begin{equation}
    f(z) = \frac{e^{1 /z} }{z^2-1} =  -\left( 1+\frac{1}{z} + \frac{1}{2z^2} + \cdots    \right)\left( 1+z^2+z^4+\cdots  \right),
\end{equation}

so the residue is 

\begin{equation}
    \text{Res}(f,0) = -\left( 1+\frac{1}{3!}+\frac{1}{5!}  + \cdots   \right) = - \sinh (1).
\end{equation}

Applying the Cauchy's resideu theorem we get 

\begin{equation}
    \oint_{C} \frac{e^{1/z} }{z^2-1}= 2\pi i \left( \frac{e}{2} - \frac{e-e^{-1} }{2}   \right) = \frac{\pi i}{e}. 
\end{equation}
~
} 

\subsection{Integrations Around Algebraic Branch Cuts.}

\example{Integral Around Algebraic Branch Cuts (1).}
{Take the principal branch of square root function 

\begin{equation}
    f(z) = z^{1/2},
\end{equation}

where \(\arg (z) \in (0,2\pi )\) and the branch cut taken from \([0,\infty]\).

Evaluate the integral 

\begin{equation}
    I_{C} = \oint_{C} \sqrt{z}dz,  
\end{equation}

where \(C\) is the circle \(\abs{z} = 1\). 
}
{Consider the complex integral 

\begin{equation}
    I_{K} = \oint_{K} \sqrt{z}dz,  
\end{equation}

where \(K\) is the keyhole contour consisting of the large circle \(C\), the upper and lower straight lines \(L_1 \text { and } L_2 \), respectively, and the small circle \(C_{\epsilon } \). 

Along \(L_1 \) we have \(\arg (z) = 0\), so 

\begin{equation}
    \sqrt{z} = \abs{z}^{1/2}e^{i (\arg z)/2}  = \abs{z}^{1/2}
\end{equation}

while along \(L_2 \) we have \(\arg (z) = 2\pi \), so

\begin{equation}
    \sqrt{z} = \abs{z}^{1/2} e^{i (\arg (z)) /2} = \abs{z}^{1/2} e^{i \pi } = - \sqrt{\abs{z} }.
\end{equation}

Therefore the integrals along \(L_1 \text { and } L_2 \) are 

\begin{equation}
    \int_{L_1 }^{}   \sqrt{z} dz = \int_{0}^{1} \sqrt{\abs{z} } dz  = \frac{2}{3} ~\text { and }~ \int_{L_2 }^{}  \sqrt{z}dz = \int_{1}^{0} -\sqrt{\abs{z} } dz = \frac{2}{3}.  
\end{equation}

The integral along the small circle becomes zero as \(\epsilon \to 0\), so from the Cauchy's theorem we have

\begin{equation}
    \oint_{K} \sqrt{z}dz = 0 = \oint_{C+L_1 +L_2 +C_{\epsilon } } \sqrt{z}dz \implies \oint_{C} \sqrt{z}dz = -\frac{4}{3}.   
\end{equation}

Alternatively we can do a direct integral using \(\theta \) as the parameter 

\begin{equation}
    \oint_{C} \sqrt{z}dz = \int_{0}^{2\pi } e^{i \theta /2} (i e^{i \theta }d \theta  ) = -\frac{4}{3}.     
\end{equation}

Alternatively we can simply state

\begin{equation}
    \oint_{C} \sqrt{z}dz = \frac{2}{3} \eval{z^{3 /2} }_{z_2 = e^{i 2\pi } }^{z_1 = 1 } = -\frac{4}{3},
\end{equation}

where the beginning and the end points are just above and below the branch cut, respectively.
}

\example{Integrals Around Algebraic Branch Cuts (2).}
{Evaluate the real integral
\begin{equation}
  I=\int_{-1}^{1}\frac{dx}{\sqrt{1 - x^{2}}}.
\end{equation}
}
{Consider the complex integral

\begin{equation}
  I_{C} = \oint_{C} \frac{dz}{\sqrt{1-z^2} },
\end{equation}

where \(C\) consist of two closed loops \(D\) and \(R\). The first is the “dog‐bone” contour \(D\) that runs just above the cut from \(-1\) to \(1\), loops around \(z=1\), returns just below the cut from \(1\) back to \(-1\), and loops around \(z=-1\), and the second loop \(R\) is the circle with radius \(R\) centered at the origin.

Note that the “dog‐bone” contour \(D\) is positive in clockwise manner while the outer cirlce is assumed positive in anti-clockwise manner, which is since they can be consider as a single closed loop if one connect them with two opposite running straight vertical lines along the \(y\)-axis whcih cancels out each other. 

The region that we are considering is now the region between the two closed loops (but not the region inside the “dog‐bone” contour since it contains the branch cut and so the function is not analytic there).

From the Cauchy's theorem since there is no singularities in the region bounded by \(C\), we have 

\begin{equation}
    I_{C} = I_{R} + I_{D} = 0 \implies I_{R} = -I_{D},
\end{equation}

which means the two the integrals along two closed loops along anti-clockwise manner is the same.

For the outer circle with radius \(R\) we parametrize \(z = Re^{i \theta } \), so its contribution is 

\begin{equation}
    I_{R} = \int_{0}^{2\pi } \frac{i Re^{i \theta } d \theta }{\sqrt{1- R^2e^{2i \theta } } } \to 2\pi. 
\end{equation}

Here there are two branch points \(z = \pm 1\). For \(z = -1\) we assume that the branch cut extends from \(z = -1\) to \(z = -\infty\). For \(z = +1\) we assume that the branch cut extends from \(z= + 1\) to \(z = -\infty\). The combined branch cut is then just the interval between \(z = -1\) and \(z = +1\).

Now for the ``dog-bone'' contour we have to evaluate the integral

\begin{equation}
    \begin{aligned} 
    \oint_{D} \frac{dz}{\sqrt{1-z^2} }dz &= \oint_{D} \frac{dz}{\left( \abs{1-z}\abs{1+z}   \right)^{1/2} }\arg \left( \left( (1-z)(1+z) \right)^{-1/2}  \right) \\
    &= \oint_{D} \frac{dz}{\left( \abs{1-z}\abs{1+z}   \right)^{1/2} } \left( -1/2 \right) \left( \arg (1-z) + \arg (1+z) \right). 
    \end{aligned} 
\end{equation}

The arguments of \(1+z,1-z \text { and } (1-x^2)^{-1/2} \) are summarized below

\[
\begin{array}{c|ccc}
\text{Interval \& direction} 
  & \arg(1+z) 
  & \arg(1-z) 
  & \arg\bigl((z^2-1)^{-1/2}\bigr)
\\\hline
x\in(-1,1),\,\downarrow 
  & 0 
  & -2\pi  
  & \pi 
\\[6pt]
x\in(-1,1),\,\uparrow   
  & 0 
  & 0
  & 0
\\[6pt]
x\in(-\infty,-1),\,\downarrow 
  & \pi 
  & 2\pi 
  & -\pi /2
\\[6pt]
x\in(1,\infty),\,\uparrow 
  & -\pi 
  & 0 
  & -\pi /2
\end{array}
\]
For the argument of \(1-z\) one should treat, for example, the point \((0.9,-0.1)\) as having an argument of \(0\) and \((0.9,0.1)\) as having an argument of \(2\pi \).

We see that the argument of \((1-z^2)^{-1/2} \) is discontinuous across the branch cut but continuous everywhere else. 

Therefore above and below the ``dog-bone'' contour in anti-clockwise manner we have 

\begin{equation}
    I_{D} = \int_{1}^{-1} \frac{dz}{\sqrt{1-z^2} } e^{-i\pi } + \int_{-1}^{1} \frac{dz}{1-z^2} e^{i0 } = 2 \int_{-1}^{1} \frac{1}{\sqrt{1-x^2} } dx.  
\end{equation}

Using the relation between \(I_{R} \text { and } I_{D} \) derived above we finally get 

\begin{equation}
    \int_{-1}^{1} \frac{1}{\sqrt{1-x^2} }dx = \pi .  
\end{equation}

As we can see if \(f(z) \sim R\) as \(R \to \infty\) the integral along the outer circle converges to a non-zero finite value. We can also define the residue at infinty as the negative of the integral along the circle

\begin{equation}
    \text{Res}(f,\infty) = -\frac{1}{2\pi i} \oint_{R} f(z)dz = -\text{Res}\left( \frac{1}{z^2}f\left( \frac{1}{z}  \right),0  \right),
\end{equation}

For example for the function \(f(z) = (1-z^2)^{-1/2} \) we can expand the function \(f(1/z)\) by Laurent series about \(z = 0\) to get   

\begin{equation}
    \frac{1}{z^2} f\left( \frac{1}{z}  \right) = \frac{1}{z^2}\frac{1}{\sqrt{1-z^{-2} } } = \frac{i}{z} (1-z^2)^{-1/2} = \frac{i}{z} \left(1+ \frac{1}{2}z^2 + \cdots  \right) \implies \text{Res}(f(1/z)/z^2, 0) = i.    
\end{equation}

Since we have already calculated that the integral along the outer circle to be \(2\pi \), we have 

\begin{equation}
    \text{Res}(f,\infty) = -\frac{1}{2\pi i} \oint_{R} f(z)dz = i \implies \oint_{R} f(z)dz = 2\pi ,
\end{equation}

coinciding with our calculation earlier.

One can also prove the relation 

\begin{equation}
    \text{Res}(f,\infty)  = -\text{coefficient of \(z^-1\) in the Laurent expansion at \(\infty\)}. 
\end{equation}

Note that if we instead consider the complex integral 

\begin{equation}
    \oint_{C} \frac{1}{z^2-1}dz, 
\end{equation}

then the integration along the outer cirlce would instead be \(2\pi i\), while the integral along the ``dog-bone contour'' would be 

\begin{equation}
    \oint_{D} \frac{1}{z^2-1}dz = \int_{1}^{-1} \frac{1}{1-z^2}e^{-i\pi /2} dz + \int_{-1}^{1} \frac{1}{\sqrt{1-z^2} } e^{-i\pi /2}dz = 2i \int_{-1}^{1} \sqrt{1-x^2}dx,          
\end{equation}

where the integrand is \((1-z^2)^{-1/2} \) instead of \((z^2-1)^{-1/2} \) due to the fact that we are taking the modulus should always be real if we write it in polar form.  
}


\example{Integrals Around Algebraic Branch Cuts (3).}
{Evaluate the real integral 
\begin{equation}
    I=\int_{0}^{3} \frac{x^{3/4}(3-x)^{1/4}}{5-x}\,dx.
\end{equation}
}
{Consider the complex integral 

\begin{equation}
    I_{C} = \oint_{C} \frac{z^{3/4} (3-z)^{1/4} }{5-z}dz,  
\end{equation}

where \(C\) is the same contour as in the previous question, consisting of the clockwise ``dog-bone'' contour \(D\) and the anti-clockwise outer cirlce \(C\).

Let \(\arg (z) \in (-\pi ,\pi ) \text { and } \arg (3-z) \in (0,2\pi )\). Above the branch cut we have 

\begin{equation}
    \arg \left( z^{3/4} (3-x)^{1/4}   \right) = \frac{1}{4}(3 \arg (z) + \arg (3-z)) = \frac{1}{4}(0+2\pi ) = \frac{\pi }{2},  
\end{equation}

while below the branch cut we have 

\begin{equation}
    \arg \left( z^{3/4} (3-x)^{1/4}   \right) = \frac{1}{4} (3 \arg (z) + \arg (3-z))  =\frac{1}{4} (0+0) = 0. 
\end{equation}

Therefore around the ``dog-bone'' integral we have 

\begin{equation}
    \oint_{D} \frac{z^{3/4}(3-z)^{1/4}  }{5-z} dz = \int_{0}^{3} \frac{z^{3/4}(3-z)^{1/4}  }{5-z} e^{i\pi /2} dz + \int_{3}^{0} \frac{z^{3/4}(3-z)^{1/4}  }{5-z} e^{i0}dz = (i-1)I.
\end{equation}

The integral along the outer cirlce is 

\begin{equation}
    \begin{aligned} 
    \oint_{R} \frac{z^{3/4}(3-z)^{1/4}  }{5-z} dz &= \int_{0}^{2\pi } \frac{R^{3/4}e^{i 3 \theta /4} (3-R e^{i \theta } )^{1/4}}{5-Re^{i \theta } } Ri e^{i \theta }d \theta \\
    &= \int_{0}^{2\pi } R^{3/4}e^{i 3 \theta /4} (-Re^{ i \theta } )^{1/4} \left( 1-\frac{3}{Re^{i \theta } }  \right)^{1/4} (-Re^{ i \theta } )^{-1} \left( 1-\frac{5}{Re^{ i \theta } }  \right)^{-1} Ri e^{ i \theta }  d \theta \\
    &= \int_{0}^{2\pi } \frac{Re^{e^{2i \theta } } i}{-Re^{ i \theta } } \left( 1-\frac{3}{4Re^{i \theta } }  \right)   \left( 1-\frac{4}{Re^{ i \theta } }  \right) d \theta \\
    &= -iR e^{i \pi /4} \int_{0}^{2\pi } e^{ i \theta } \left( \frac{5}{Re^{i \theta } } - \frac{3}{4R e^{i \theta } }  \right)    d \theta \\
    &= -\frac{17}{2} i \pi e^{i \pi /4}.
    \end{aligned}   
\end{equation}

If we had not expand the integrand for large \(R\) we would get 

\begin{equation}
    Ri e^{i \pi /4} \int_{0}^{2\pi } e^{i \theta } d\theta  = 0, 
\end{equation}

since the integral is identically equals to zero but the prefactor \(R\) only tends to infinity.

The residue at \(z = 5\) is 

\begin{equation}
    \text{Res} (f,5) = 2\pi i e^{i \pi /4} 5^{3/4} 2^{1/4},    
\end{equation}

so using the Cauchy's residue theorem we have 

\begin{equation}
    I_{R} + I_{D} = I_{R} + (i-1)I =  2\pi i\text{Res}(f,5) \implies I = \frac{2\pi i\text{Res}(f,5) - I_{D} }{i-1} = \frac{\sqrt{2} \pi }{4} (17-40^{3/4} ). 
\end{equation}

Note that one can also use the formula for residue at infinity to calculate the contirubtion of the integral along the outer circle by 

\begin{equation}
    \oint_{R} f(z)dz = -2\pi i \text{Res}\left( \frac{1}{z^2}f\left(\frac{1}{z} \right),0  \right).
\end{equation}
~
}

\subsection{Integrals Around Logarithmic Branch Cuts}

\example{Integral Around Logarithmic Branch Cuts (1).}
{Evaluate the real integral 
\begin{equation}
    I = \int_{0}^{\infty} \frac{\ln x}{(1+x^2)^2}\,dx.
\end{equation}
}
{Consider the complex integral 

\begin{equation}
    I_{C} = \oint_{C} \left( \frac{\ln z}{(1+z^2)^2}  \right) dz,
\end{equation}

where \(C\) consist of two semi-circles with raidus \(r \text { and } R\) centered at the origin with the branch cut along the positive \(x\)-axis. The contributions from the two semi-circles vanish and we are left with the integral along the \(x\)-axis

\begin{equation}
    \begin{aligned} 
    I_{C} &= \int_{-\infty}^{0} \frac{\ln x}{(1+x^2)^2}dx+ \int_{0}^{\infty} \frac{\ln x}{(1+x^2)^2}dx \\
    &= I - \int_{0}^{-\infty} \frac{\ln (-x)_i\pi }{(1+x^2)^2}dx \\
    &= I - \int_{0}^{\infty} \frac{\ln u+i\pi }{(1+u^2)^2}(-du) \\
    &= I + \int_{0}^{\infty} \frac{\ln x+i\pi }{(1+x^2)^2}dx\\
    &= 2I + i\pi \int_{0}^{\infty} \frac{1}{(1+x^2)^2}dx \\
    &=2I + \frac{i\pi ^2}{4}.            
    \end{aligned} 
\end{equation}

Using the Cauchy's residue theorem we have 

\begin{equation}
    2I + \frac{i\pi ^2}{4} = 2\pi i \left( \frac{\pi +2i}{8}  \right) \implies I = -\frac{\pi }{4}.  
\end{equation}

Alternatively we can consider the complex integral 

\begin{equation}
    I_{C} = \oint_{C} \frac{(\ln z)^2}{(1+z^2)^2}dz,  
\end{equation}

where \(C\) is a keyhole contour with the branch cut along the negative \(x\)-axis. The contributions from the two circles vanish and we are left with the integral above and below the branch cut

\begin{equation}
    \begin{aligned}
        &\int_{-\infty}^{0} \frac{(\ln x)^2}{(1+x^2)^2} dx + \int_{0}^{-\infty} \frac{(\ln x)^2}{(1+x^2)^2}dx \\
        &= -\int_{0}^{-\infty} \frac{(\ln (-x)+i\pi )^2}{(1+x^2)^2}dx + \int_{0}^{-\infty} \frac{(\ln (-x)-i\pi )^2}{(1+x^2)^2}dx\\
        &= \int_{0}^{\infty} \frac{(\ln x+i\pi )^2}{(1+x^2)^2}dx - \int_{0}^{\infty} \frac{(\ln x-i\pi )^2}{(1+x^2)^2}dx \\
        &= 4\pi i \int_{0}^{\infty} \frac{\ln x}{(1+x^2)^2}dx = 4\pi iI.                
    \end{aligned}
\end{equation}

Using the Cauchy's residue theorem we have 

\begin{equation}
    4\pi i I = -i\pi ^2 \implies I = -\frac{\pi }{4}. 
\end{equation}

Alternatively we can consider the same complex integral but with the branch cut taken along the positive \(x\)-axis, so 

\begin{equation}
    \begin{aligned}
        I_{C} &= \int_{0}^{\infty} \frac{(\ln x)^2}{(1+x^2)^2}dx + \int_{\infty}^{0} \frac{(\ln x + 2i\pi )^2}{(1+x^2)^2} dx\\
        &= -4\pi i \int_{0}^{\infty} \frac{\ln x}{(1+x^2)^2}dx + 4\pi ^2\int_{0}^{\infty} \frac{1}{(1+x^2)^2}dx\\
        &= -4\pi i I + \pi ^3 .             
    \end{aligned}
\end{equation}

Using the Cauchy's residue theorem we have 

\begin{equation}
    -4\pi iI + \pi ^3 = -i\pi ^2?
\end{equation}
~
}  

\example{Integrals Around Logarithmic Branch Cuts (2).}
{Evaluate the real integral
\begin{equation}
  \int_{-1}^{1}\frac{dx}{\sqrt{1 - x^{2}}}.
\end{equation}
}
{Consider the complex integral

\begin{equation}
  \oint_{C} \frac{dz}{\sqrt{1-z^2} }  
\end{equation}

with branch points at \(z=\pm1\) and a branch cut taken along the real interval \([-1,1]\). 

Here \(C\) consist of two closed loops. The first is the “dog‐bone” contour that runs just above the cut from \(-1\) to \(1\), loops around \(z=1\), returns just below the cut from \(1\) back to \(-1\), and loops around \(z=-1\), and the second loop is the circle with radius \(R\) centered at the origin.

Note that the “dog‐bone” contour is in clociwse manner while the outer cirlce is in anti-clockwise manner, which is since they can be consider as a single closed loop if one connect them with two opposite running straight vertical lines along the \(y\)-axis whcih cancels out each other. 

The region that we are considering is now the region between the two closed loops (but not the region inside the “dog‐bone” contour since it contains the branch cut and so the function is not analytic there).

For the outer circle with radius \(R\) we parametrize \(z = Re^{i \theta } \), so its contribution is 

\begin{equation}
    I_{R} = \int_{0}^{2\pi } \frac{i Re^{i \theta } d \theta }{\sqrt{1- R^2e^{2i \theta } } } \to 2\pi. 
\end{equation}

While above the “dog‐bone” contour, \(1-z^2 = (1-x^2)e^{0i} \) and below the “dog‐bone” contour, \(1-z^2 = (1-x^2)e^{2\pi i} \), so its contibution is 

\begin{equation}
    I_{D} = \int_{-1}^{1} \frac{dx}{\sqrt{1-x^2} } + \int_{1}^{-1} \frac{dx}{-\sqrt{1-x^2} }  = 2\int_{-1}^{1} \frac{dx}{\sqrt{1-x^2} }.       
\end{equation}

Using the Cauchy's theorem we have 

\begin{equation}
    I_{R} + I_{D} = 0 \implies \int_{-1}^{1} \frac{dx}{\sqrt{1-x^2} } = -\pi .
\end{equation}



Alternatively we can calculate the residue at infinty by the expanding the function \(f(w)\) at \(w = 0\) where \(w = 1/z\)   

\begin{equation}
    \int_{R}^{} f(z)dz = \frac{1}{1-z^2} = \frac{1}{1-w^{-2} } = iw(1-w^2)^{-1/2} = iw + \cdots = \frac{i}{z} + \cdots \implies \text{Res}(f,\infty) = i.    
\end{equation}

Therefore the integral along the outer circle is 

\begin{equation}
    \int_{R}^{} f(z)dz = -2\pi i (i) = 2\pi , 
\end{equation}

where the negative sign 
~
}

\example{Integrations Around Branch Cuts (3).}
{Evaluate the real integrals 

\begin{equation}
    \int_{0}^{+\infty} \frac{\ln x}{x^2+1} dx ~\text { and }~ \int_{0}^{+\infty} \frac{(\ln x)^2}{x^2+1} dx.    
\end{equation}

~
}
{Consider the complex integral 

\begin{equation}
    I_{\Gamma } = \oint_{\Gamma } \frac{(\ln z)^2}{z^2+1} dz, 
\end{equation}

with branch point at \(z = 0\) and branch cut taken from the positive \(x\)-axis. 

Here \(\Gamma \) consists of two semi-circles in the upper half plane centered at the origin with radii \(r \text { and } R\) respectively, and two straight lines connecting them, as shown in \cref{contour3}.  

The singularity inside \(\Gamma \) is \(z = i\) and its residue is \((\ln i)^2/2i\), so by the Cauchy's residue theorem we get 

\begin{equation}
    I_{\Gamma } = \oint_{\Gamma } \frac{(\ln z)^2}{z^2+1} = 2\pi i \left( \frac{(\ln i)^2}{2i}  \right)  = -\frac{\pi ^3 }{4}. 
\end{equation}

As \(R \to \infty \text { and } r \to 0\), the small and large arc integrals go to zero, since

\begin{equation}
    \abs{\frac{(\ln z)^2}{z^2+1} } \approx  \frac{\abs{\ln R + i \theta } ^2}{\abs{z}^2-1 } \approx \frac{(\ln R)^2}{R^2} ~\text { and }~ \abs{\frac{(\ln z)^2}{z^2+1} } \approx  \frac{\abs{\ln r + i \theta } ^2}{\abs{z}^2-1 } \approx (\ln r)^2.
\end{equation}

\begin{equation}
    \begin{aligned} 
    I_{\Gamma } &= \int_{-\infty}^{0} \frac{(\ln x)^2}{x^2+1}dx + \int_{0}^{\infty} \frac{(\ln x)^2}{x^2+1}dx \\
    & \int_{-\infty}^{0} \frac{(\ln (-x) + i\pi )^2}{x^2+1}dx +  \int_{0}^{\infty} \frac{(\ln x)^2}{x^2+1}dx \\
    &= \int_{\infty}^{0}\frac{(\ln u + i\pi )^2}{x^2+1}(-du) + \int_{0}^{\infty} \frac{(\ln x)^2}{x^2+1}dx \\
    &= \int_{0}^{\infty} \frac{2(\ln x)^2 + 2i\pi \ln x - \pi ^2}{x^2+1}dx.   
    \end{aligned}                
\end{equation}

Using the Cauchy's residue theorem we equate the real part to \(-\pi ^3 /4\) and the imaginary part to zero 

\begin{equation}
    2 \int_{0}^{\infty} \frac{(\ln x)^2}{x^2+1} - \pi ^2 \int_{0}^{\infty} \frac{1}{x^2+1}dx = -\frac{\pi ^3 }{4} ~\text { and }~ 2i\pi \int_{0}^{\infty} \frac{\ln x}{x^2+1} = 0.         
\end{equation}

Therefore 

\begin{equation}
    \int_{0}^{\infty} \frac{(\ln x)^2}{x^2+1} = \frac{\pi ^3 }{8} ~\text { and }~ \int_{0}^{\infty} \frac{\ln x}{x^2+1} = 0.      
\end{equation}
~
} 



\subsection{ML Lemma and Jordan's Lemma}

\subsubsection{ML Inequality}

The ML (Max-Length) Lemma states that for any contour \(\gamma \) and any function \(f(z)\) continuous on \(\gamma \),

\begin{equation}
    \abs{\int_{\gamma }^{} f(z)dz} \le \int_{\gamma }^{} \abs{f(z)}\abs{dz} \le ML, \quad M = (\max _{z \in \gamma } \abs{f(z)}) \text { and } L = \int_{\gamma }^{} dz.  
\end{equation}

\subsubsection{Jordan's Lemma}

The Jordan's Lemma states that for the contour \(C_{R} \) (a semi-circular arc of radius \(R\) in the upper half-plane) and any function \(f(z)\) is continuous on \(C_{R} \). If \(k > 0\) is a real number, then

\begin{equation}
    \abs{\int_{C_{R} }^{} f(z) e^{ikz}dz   } \le \frac{\pi M}{k}, \quad M = (\max _{z \in C_{R} } \abs{f(z)}).
\end{equation}

This is because using the ML inequality we have

\begin{equation}
    \abs{\int_{C_{R} }^{} f(z) e^{ikz}dz } \le \int_{0}^{\pi } \text{max}(\abs{f(Re^{i \theta } )}) \abs{e^{ikz} } \abs{Ri e^{i \theta } } d \theta = MR \int_{0}^{\pi } e^{-kR \sin \theta } d \theta \le  \frac{\pi M}{k}.         
\end{equation}

If \(M \to 0\) as \(R \to \infty\) then we get  

\begin{equation}
    \lim_{R \to \infty} \int_{C_{R} }^{} f(z)e^{ikz}dz = 0, 
\end{equation}

If \(k < 0\) then we consider a semi-circular arc in the lower half-plane. 

In short, the Jordan's Lemma hinges on the fact that \(e^{i kz } = e^{i kx} e^{-iy}  \) tends to zero as \(x \to \infty \text { and } y \to \infty\).  

\example{ML inequalities.}
{Show that 

\begin{equation}
    \lim_{R \to \infty} \abs{R \int_{0}^{\alpha } e^{-R^2e^{2i \theta } } e^{i \theta } d \theta }=0, \quad 0 \le \alpha \le \frac{\pi }{4}. 
\end{equation}

By considering the sector contour with angle \(\arg (w)\) show that 

\begin{equation}
    \int_{0}^{\infty} e^{-w^2x^2}dx = w^{-1} \int_{0}^{\infty} e^{-x^2} dx.    
\end{equation}

Hence using \(\arg (w) = \pi /4\) evaluate the real integral 

\begin{equation}
    \int_{0}^{\infty} \cos (x^2)dx.  
\end{equation}
~
}
{For \(0 \le \alpha < \pi /4\), we use the ML inequality to get 

\begin{equation}
     \lim_{R \to \infty} \abs{R \int_{0}^{\alpha } e^{-R^2e^{2i \theta } } e^{i \theta } d \theta } \le R \int_{0}^{\alpha } \abs{e^{-Re^{e^{2i \theta } } } } \abs{e^{i \theta } } d \theta = R \int_{0}^{\alpha } e^{-Re^{ \cos (2 \theta )} }  d \theta \le R \int_{0}^{\alpha }e^{-R^2\cos (2 \alpha )} d \theta = R \alpha e^{-R^2\cos (2\alpha )} \to 0.      
\end{equation}

For \(\alpha  = \pi /4\) we split the integral into two parts 

\begin{equation}
     \lim_{R \to \infty} \abs{R \int_{0}^{\alpha } e^{-R^2e^{2i \theta } } e^{i \theta } d \theta }  = \lim_{R \to \infty} \abs{R \int_{0}^{\pi /4 - \epsilon } e^{-R^2e^{2i \theta } } e^{i \theta } d \theta } +  \lim_{R \to \infty} \abs{R \int_{\pi / 4 - \epsilon }^{\pi /4} e^{-R^2e^{2i \theta } } e^{i \theta } d \theta }.
\end{equation}

The first integral vanshies as we have shown, while for the second integral we make the subsitution \(\phi = \pi /4 - \theta \), then 

\begin{equation}
    \begin{aligned} 
    \lim_{R \to \infty} \abs{R \int_{\pi / 4 - \epsilon }^{\pi /4} e^{-R^2e^{2i \theta } } e^{i \theta } d \theta } &= R \int_{0}^{\epsilon } e^{-R^2 \sin (2 \phi )}d\phi \le R \int_{0}^{\epsilon } e^{-2R^2\phi \cos \epsilon } d \phi \\
    &= \frac{1}{2R\cos \epsilon }\left( 1-e^{-2R^2\epsilon \cos \epsilon }  \right) \to 0.
    \end{aligned} 
\end{equation}
~
} 


\subsection{Applications}

\subsubsection{Real Integrals involving \(\infty\) }

\example{Real Integrals involving \(\infty\)  (1).}
{Evaluate the real integral 

\begin{equation}
    \int_{-\infty}^{+\infty} \frac{x^2}{(x^2+1)(x^2+4)}dx.  
\end{equation}
~
}
{Consider the complex integral 

\begin{equation}
    I_{C} = \oint_{C} \frac{z^2}{(z^2+1)(z^2+4)}dz, 
\end{equation}

where \(C\) is a semi-circle in the upper half-plane centered at the origin with radius \(R\).

The singularities inside \(C\) are \(z = i \text { and } 2i\), and their residues are 

\begin{equation}
    \text{Res}(f,i) = \lim_{z \to i} (z-i)f(z)=  \frac{i}{6} ~\text { and }~ \text{Res}(f,2i) = \lim_{z \to 2i} (z-2i)f(z) = -\frac{i}{3}.   
\end{equation}

Using the Cauchy's residue theorem the integral is

\begin{equation}
    I_{C} = 2\pi i \left( \frac{i}{6} - \frac{i}{3}   \right) = \frac{\pi }{3}. 
\end{equation}

Therefore we get 

\begin{equation}
    I_{C} = \int_{-R}^{R} f(x)dx + \int_{\Gamma _{R} }^{}f(z)dz  = \int_{-\infty}^{\infty} \frac{x^2}{(x^2+1)(x^2+4)}dx = \frac{\pi }{3},    
\end{equation}

since using the ML inequality we can show that 

\begin{equation}
    \int_{\Gamma _{R} }^{} f(z)dz \le \left( \max \abs{f(z)}  \right) (\text{length of }\Gamma _{R}  ) \approx \frac{\pi }{R} \to 0 \text{ as } R \to 0.  
\end{equation}
~
} 

\example{Real Integrals from involving \(\infty\)  (2).}
{Evaluate the real integral

\begin{equation}
    \int_{-\infty}^{+\infty} \frac{e^{x /2} }{\cosh x}dx.  
\end{equation}
~
}
{Consider the complex integral 

\begin{equation}
    I_{C} = \oint_{C} \frac{e^{z /2} }{\cosh z}dz,  
\end{equation}

where \(C\) is a rectangular contour with vertices \(-L,L,L+i\pi ,-L+i\pi \). 

Thesingularities inside \(C\) is \(z = i\pi /2\), and its residue is 

\begin{equation}
    \text{Res}\left( f, \frac{i\pi }{2}  \right) = \lim_{z \to i\pi /2} \left( z - \frac{i\pi }{2}  \right) \frac{e^{x /2} }{\cosh x} = \frac{e^{i \pi /4} }{i} .
\end{equation}

The contour \(C\) can be broken into four pieces. The integral along the real axis is the one we want to find. The two integrals along the vertical side tends to zero as \(L\) tends to infinity, since as \(L \to \infty\) we have 

\begin{equation}
    \frac{e^{x /2} }{\cosh x} \to e^{-L/2} \to 0 \text{ as } L \to \infty.  
\end{equation}

The integral along the top side of the rectangle is 

\begin{equation}
    \int_{L+i\pi }^{-L+i\pi } f(z)dz = -\int_{-L}^{L} f(x+i\pi )dx = -\int_{-L}^{L} \frac{-i e^{x /2} }{\cosh x} dx = i \int_{-L}^{L} \frac{e^{x /2} }{\cosh x}dx.          
\end{equation}

Using the Cauchy's residue theorem we get 

\begin{equation}
    I_{C} = (1+i) \int_{-\infty}^{+\infty} \frac{e^{-x /2} }{\cosh x}dx = 2\pi i \left( \frac{e^{i \pi /4} }{i}  \right) \implies \int_{-\infty}^{+\infty} \frac{e^{x /2} }{\cosh x}dx = \sqrt{2}\pi .   
\end{equation}
~
} 

\example{Real Integrals Involving \(\infty\) (3).}
{Evaluate the real integrals 

\begin{equation}
    \int_{0}^{\infty} \frac{\ln x}{(1+x^2)}dx ~\text { and }~ \int_{0}^{\infty} \frac{\ln (1+x^2)}{1+x^2}dx.     
\end{equation}
~
}
{Consider the integral 

\begin{equation}
    F(\alpha ) = \int_{0}^{\infty} \frac{x^{\alpha } }{(1+x^2)^{\alpha } }dx.   
\end{equation}

We evaluate this integral by considering the more general complex integral 

\begin{equation}
    G(\alpha ) = \int_{0}^{\infty} \frac{z^{\alpha } }{(1+z^2)^{\alpha } }dz.  
\end{equation}

Our goal is then to calculate \(F'(0)\), where the differentiation is with respect to \(\alpha \)  

\begin{equation}
    a^2f
\end{equation}




} 


\subsubsection{Real Integrals with Trigonometric Functions}

\example{Real Integrals with Trigonometric Functions (2).}
{Evaluate the real integral 

\begin{equation}
    \int_{-\infty}^{+\infty} \frac{\cos (3x)}{1+x^2}dx.  
\end{equation}
~
}
{Consider the complex integral 

\begin{equation}
    I_{C} = \oint_{C} \frac{e^{3ix} }{1+z^2} dz
\end{equation}

where \(C\) is a semi-circle in the upper half-plane centered at the origin with radius \(R\).

The singularity inside \(C\) is \(z = i\), and its residue is

\begin{equation}
    \text{Res}(f,i) = \lim_{z \to i} (z-i)f(z) = \frac{e^{-3} }{2i}.   
\end{equation}

Using the Cauchy's residue theorem the integral is

\begin{equation}
      \oint_{C} \frac{e^{3ix} }{1+z^2} = 2\pi i \left( \frac{e^{-3} }{2i} \right) = \frac{\pi }{e^3}. 
\end{equation}

Therefore we get 

\begin{equation}
      \oint_{C} \frac{e^{3ix} }{1+z^2} = \int_{-R}^{R} f(x)dx + \int_{\Gamma _{R} }^{}f(z)dz  = \int_{-\infty}^{+\infty} \frac{\cos (3x)}{1+x^2}dx = \frac{\pi }{e^3},    
\end{equation}

since using the Jordan's lemma we have 

\begin{equation}
    \frac{1}{1+z^2} \to \frac{1}{R^2} \text{ as } R \to \infty ,  
\end{equation}

which grows slower than \(1 / \abs{z} \), so the integral 

\begin{equation}
    \int_{\Gamma _{R} }^{} \frac{e^{3iz} }{1+z^2} dz \to 0 \text{ as } R \to \infty.     
\end{equation}
~} 




\example{Real Integrals with Trigonometric Functions (3).}
{Evaluate the real integral

\begin{equation}
    \int_{0}^{2\pi } \frac{1}{1+8\cos ^2\theta } d \theta .   
\end{equation}
~
}
{We make the standard substitution 

\begin{equation}
    z = e^{i \theta } \implies d \theta = \frac{dz}{iz} ~\text { and }~ \cos \theta = \frac{z^2+1}{2z}.  
\end{equation}

The integral then becomes

\begin{equation}
    \oint_{C} \frac{1}{1+8 ((z^2+1) /2z)^2} \frac{dz}{i z} = \oint_{C} \frac{z}{i(2z^{4} + 5z^2+2)}dz,   
\end{equation}

where \(C\) is a unit circle centered at the origin. The residues and the poles are 

\begin{equation}
    \text{Res} \left( f, \frac{i}{\sqrt{2} }  \right) = -\frac{i}{6} = \text{Res} \left( f, -\frac{i}{\sqrt{2} }  \right).
\end{equation}

So from the Cauchy's residue theorem the integral is 

\begin{equation}
    \int_{0}^{2\pi } \frac{1}{1+8\cos ^2\theta } d \theta = \oint_{C} \frac{z}{i(2z^{4} + 5z^2+2)}dz = 2\pi i \left( -\frac{2i}{6}  \right) = \frac{2\pi }{3}. 
\end{equation}
~} 

\example{Real Integrals with Trigonometric Functions (4).}
{Evaluate the real integral 

\begin{equation}
    \int_{0}^{\infty}  \frac{\sin x}{x}dx.  
\end{equation}
~
}
{Consider the complex integral 

\begin{equation}
    I_{C} = \oint_{C} \frac{e^{iz} }{z}dz,
\end{equation}

where \(C\) are the two semi-circles in the half plane centered at the origin with radii \(r \text { and } R\) respectively, as shown in \cref{contour3}.  

There are no singularities inside \(C\) so we get \(I_{C} = 0\). 

As \(R \to \infty\) the integral vanishes so we are left with the contributions along the real axis and the integral along the smaller semi-circle with raidus \(r\).

\begin{equation}
    \int_{-\infty}^{\infty} \frac{e^{ix} }{x}dx + \int_{0}^{\pi } \frac{e^{i re^{i \theta } } }{re^{i \theta } } ir e^{i \theta }d \theta = 0.    
\end{equation}

Simplifying we get 

\begin{equation}
    2 \int_{0}^{\infty} \frac{e^{ix} }{x}dx + i \pi = 0 \implies \int_{0}^{\infty} \frac{\sin x}{x} = \mathfrak{Im} \left( \int_{0}^{\infty} \frac{e^{ix} }{x}dx   \right) = \frac{\pi }{2}.    
\end{equation}

To be more formal for the integral along the negative \(x\)-axis we should use the parameterization \(z = \abs{x}e^{i\pi } = -\abs{x}   \), then the integral becomes

\begin{equation}
    \int \frac{e^{iz} }{z} dz = \int_{\infty}^{0} \frac{e^{-i \abs{x} } }{\abs{x} } d(\abs{x} ) = \int_{-\infty}^{0} \frac{e^{iu} }{u}du,    
\end{equation}

where we have used the substitution \(u = -\abs{x} \) at the last step. 

In fact one can also choose a contour that include the pole at \(z = 0\) instead of excluding it. One would then find that the negative sign incurred from the integral of the semi-circle would cancels out with the residue now that the pole is inside our contour to get the same result. 
} 


\subsubsection{Others}

\example{Sum of \(1 /n^2 \). }
{Evaluate the sum

\begin{equation}
    S = \sum_{n=1}^{\infty} \frac{1}{n^2} ~\text { and }~ S' = \sum_{n=1}^{\infty} \frac{1}{n^2+a^2}. 
\end{equation}
~
}
{We start by considering the complex integral

\begin{equation}
    I_{Q} = \oint_{Q_{N} } \frac{\pi \cot (\pi z)}{z^2}  dz,
\end{equation}

where \(Q_{N} \) is a sqaure contour with length \(2N + 1/2\) centered at the origin.  

The singularities inside \(Q_{N} \) are \(z = n < N\). For \(n \neq 0\) the residue is easily found by 

\begin{equation}
    \text{Res}(f,n \neq 0) = \lim_{z \to n} (z-n)\frac{\pi \cot (\pi z)}{z^2} = \frac{\pi \cos (\pi n)}{n^2} \lim_{z \to n} \frac{z-n}{\sin (\pi z)} = \frac{\pi }{n^2}.   
\end{equation}

For \(z = 0\) however we need to obtain the residue through Laurent expansion

\begin{equation}
    \frac{\pi \cos (\pi z)}{z^2\sin (\pi z)} = \frac{\pi (1-\frac{(\pi z)^2}{2!} + \cdots )}{z^2(\pi z - \frac{(\pi z)^3 }{3!} + \cdots )} = \frac{1}{z^3 } - \frac{\pi ^2}{3z} + \cdots \implies \text{Res}(f,0) = - \frac{\pi ^2}{3}.      
\end{equation}

The contour integral vanishes as \(N \to \infty\), since \(\frac{1}{n^2} \) goes to zero as \(n \to \infty\) and \(\abs{\pi } \cot (\pi z)\) is bounded on the contour. For example on the vertical lines we have \(z = N+1/2+iy\), so 

\begin{equation}
    \cot (\pi z) = i \frac{e^{i\pi (N+1/2+i\pi y)} + e^{-i\pi (N+1/2+i\pi y)} }{e^{i\pi (N+1/2+i\pi y)} - e^{-i\pi (N+1/2+i\pi y)} } = i \frac{i(-1)^{N}e^{-\pi y} + (-1)^{N}(-i)e^{\pi y}}{i(-1)^{N}e^{-\pi y} - (-1)^{N}(-i)e^{\pi y}} = \frac{e^{\pi y} - e^{-\pi y} }{e^{\pi y} + e^{-\pi y} } = \tanh (\pi y),   
\end{equation}

which is obviously bounded.

Therefore by the Cauchy's residue theorem we have 

\begin{equation}
    \oint_{Q_{N} }  \frac{\pi \cot (\pi z)}{z^2} dz = 0 = 2\pi i \left( -\frac{\pi ^2}{3} + 2 \sum_{n=1}^{\infty} \frac{\pi }{n^2}  \right).
\end{equation}

We therefore conclude that 

\begin{equation}
    S = \sum_{n=1}^{\infty} \frac{1}{n^2} = \frac{\pi ^2}{6}.   
\end{equation}

To extend our result and calculate \(S'\), we consider the complex integral 

\begin{equation}
    I_{Q}' = \oint_{_{Q_{N} } }  \frac{\pi \cot (\pi z)}{z^2+a^2}dz. 
\end{equation}

The sigularities inside \(Q_{N} \) are \(z = \pm ia \text { and } z = n < N\). For the singularites \(z = n < N\) the resiues are 

\begin{equation}
    \text{Res}(f,n<N) = \lim_{z \to n} (z-n)\frac{\pi \cot (\pi z)}{z^2+a^2} = \frac{\pi \cos (\pi n)}{n^2+a^2} \lim_{z \to n} \frac{z-n}{\sin (\pi z)} = \frac{\pi }{n^2+a^2}.   
\end{equation}

For the singularities \(z = \pm ia\) the residues are  

\begin{equation}
    \text{Res}(f,\pm ia) = \lim_{z \to \pm ia} (z-\pm ia) \frac{\pi \cot (\pi z)}{z^2+a^2} = -\frac{\pi }{2} \coth (\pi a). 
\end{equation}

The contour integral vansihes as \(N \to \infty\) as the same reason as above and therfore by the Cauchy's residue theorem we have

\begin{equation}
    \oint_{Q_{N} }\frac{\pi \cot (\pi z)}{z^2+a^2}dz = 0 = 2\pi i \left( 2 \left(-\frac{\pi }{2} \coth (\pi a) \right) + 2 \sum_{n=1}^{\infty} \frac{1}{n^2+a^2} + \frac{1}{a^2}   \right).  
\end{equation}

We therefore conclude that 

\begin{equation}
    S' = \sum_{n=1}^{\infty} \frac{1}{n^2+a^2} = \frac{1}{2}\left( \pi \coth(\pi a) - \frac{1}{a^2} \right). 
\end{equation}
~
} 




\section{Temperory}

The sterographic projection is when we map each point on a sphere with radius \(1\) centered at \((0,0,1)\) onto a complex number, where the a line strating from the north pole at \((0,0,2)\) and ending at complex number intersect the sphere exactly once. By this mapping any point at infinity on the plane will be identified with the north pole. The sphere is called the Riemann sphere and is shown in \cref{sphere}.

\onefig{sphere}{scale=0.3} 

If \((x,y,z)\) are the coordinates on the sphere and \((X,Y)\) are coordinates on the plane we have the mapping 

\begin{equation}
    (X,Y) = \left(\frac{2x}{2-z}, \frac{2y}{2-z}  \right) ~\text { and }~ (x,y,z) = \left( \frac{4X}{4+X^2+Y^2},\frac{4Y}{4+X^2+Y^2}, \frac{2(X^2+Y^2)}{4+X^2+Y^2}    \right).
\end{equation}




\chapter{Fourier Series and Integral Transforms}

\section{Fourier Series}

The Fourier series expansion of the function \(f(x)\) with period \(L\) is conventionally written as 

\begin{equation}
    f(x) = \frac{a_0 }{2} + \sum_{r=1}^{\infty} \left( a_{r} \cos \left( \frac{2\pi rx}{L}  \right) + b_{r} \sin \left( \frac{2\pi rx}{L}  \right)  \right). 
\end{equation}

All the terms of a Fourier series are mutually orthogonal, \textit{i.e.,} 

\begin{equation}
    \begin{aligned}
        \int_{x_0}^{x_0+L} \sin\left(\frac{2\pi r x}{L}\right) \cos\left(\frac{2\pi p x}{L}\right) dx &= 0 \quad \text{for all } r \text{ and } p, \\
        \int_{x_0}^{x_0+L} \cos\left(\frac{2\pi r x}{L}\right) \cos\left(\frac{2\pi p x}{L}\right) dx &=
\begin{cases} 
    0 & \text{for } r = p = 0, \\
    \frac{L}{2} & \text{for } r = p > 0, \\
    0 & \text{for } r \neq p,
\end{cases} \\
\int_{x_0}^{x_0+L} \sin\left(\frac{2\pi r x}{L}\right) \sin\left(\frac{2\pi p x}{L}\right) dx &=
\begin{cases} 
    0 & \text{for } r = p = 0, \\
    \frac{L}{2} & \text{for } r = p > 0, \\
    0 & \text{for } r \neq p.
\end{cases}
    \end{aligned}
\end{equation}

Thus, the Fourier coefficient of a certain cosine or sine function with a particular \(r\) can be found by multiplying \(f(x)\) same cosine and sine function and then integrate, which would yield the result \(a_{r}L/2  \text { or } b_{r}L/2  \). Thus the Fourier coefficients are given by 

\begin{equation}
    a_{r} = \frac{2}{L} \int_{x_0}^{x_0 + L} f(x) \cos \left( \frac{2\pi rx}{L}  \right) dx \text { and } b_{r} = \frac{2}{L} \int_{x_0 }^{x_0 + L} f(x) \sin \left( \frac{2\pi rx}{L}  \right) dx.   
\end{equation}

Any arbitrary function \(f(x)\) can be decomposed into the sum of an even and an odd function, since

\begin{equation}
    f(x) = \frac{1}{2}(f(x) + f(-x)) + \frac{1}{2} (f(x) - f(-x)) = f_{\text{odd} }(x) + f_{\text{even} }(x).
\end{equation}

Comparing the above equation with the Fourier expansion of \(f(x)\), we see that all the cosines terms sum up to \(f_{\text{even}}(x)\) and all the sines terms sum up to \(f_{\text{odd} }(x)\). 

Therefore, if the function \(f(x)\) is even, the all the coefficients of the sines terms are zero and vice versa. 

For a function \(f(x)\) that is symmetric (even or odd) about \(L /4 \), \textit{i.e.,} \(f(L /4-x ) = \pm f(x - \frac{L}{4} )\), we make the substitution \(s = x-L /4 \) and we have 

\begin{equation}
    \begin{aligned} 
    b_{r} &= \frac{2}{L} \int_{x_0 }^{x_0 + L} f(s) \sin \left( \frac{2 \pi rs}{L} + \frac{\pi r}{2} \right) ds \\ &= \frac{2}{L} \int_{x_0 }^{x_0 + L} f(s) \left( \sin \left( \frac{2 \pi  rs}{L}  \right) \cos \left( \frac{\pi r}{2}  \right) + \cos \left( \frac{2 \pi rs}{L}  \right) \sin \left( \frac{\pi r}{2} \right)\right) ds.        
    \end{aligned} 
\end{equation}

If \(r\) is even then the second term in the integrand vanishes. The integral becomes the normal Fourier coefficient, but the dummy variable is now \(s\) instead of \(x\). If \(f(s)\) is also even, then we can conclude that the integral is zero, as for all even function the fourier coefficient \(b_{r} = 0\). By similar means, we can conclude that 

\begin{enumerate}
    \item If \(f(x)\) is even about \(\frac{L}{4} \) then \(a_{2r+1} = 0 \text { and } b_{2r} = 0 \).
    \item If \(f(x)\) is odd about \(\frac{L}{4} \) then \(a_{2r} = 0 \text { and } b_{2r+1} = 0 \).      
\end{enumerate}

For non-periodic function in a finite range we can simply extend the function to make it periodic. However, if the periodic function has discontinuity then the value obtained from the Fourier series will converge to a value halfway between the upper and lower values.

Leveraging the Euler's identity \(e^{irx} = \cos (rx) + i\sin (rx) \), the Fourier series can be written in a more compact form

\begin{equation}
    f(x) = \sum_{r=-\infty}^{+\infty} c_{r} e^{\left( \frac{2\pi i rx}{L}  \right)}dx,  
\end{equation}

where the coefficients are 

\begin{equation}
    c_{r} = \frac{1}{L} \int_{x_0 }^{x_0 + L} f(x)e^{\left( -\frac{2\pi irx}{L}  \right)}dx,     
\end{equation}

since

\begin{equation}
    \int_{x_0 }^{x_0 + L} e^{\left( -\frac{2\pi ipx}{L}\right)} e^{\left( \frac{2\pi irx}{L} \right)} dx = \begin{cases} L & \text{for } r=p, \\ 0 & \text{for } r\neq p.\end{cases}   
\end{equation}

To relate \(a_{r},b_{r} \text { and } c_{r}  \), we have

\begin{equation}
    c_{r} = \frac{1}{2} (a_{r} -ib_{r}  ) \text { and } c_{-r} = \frac{1}{2}(a_{r} + ib_{r}  ).   
\end{equation}

If \(f(x)\) is real then \(c_{-r} = c_{r}^*  \).

Parseval's theorem states that 

\begin{equation}
    \frac{1}{L} \int_{x_0 }^{x_0 + L} \abs{f(x)}^2 dx = \sum_{r=-\infty}^{+\infty} \abs{c_{r} }^2 = \left(\frac{a_0 }{2} \right)^2 + \frac{1}{2} \sum_{r=1}^{\infty} (a_{r}^2 + b_{r}^2).         
\end{equation}

To prove this theorem, consider two functions \(f(x) \text { and } g(x)\) with Fourier series 

\begin{equation}
    f(x) = \sum_{r=-\infty}^{+\infty} c_{r} e^{\left( \frac{2\pi irx}{L}  \right)} ~\text { and }~ g(x) = \sum_{p=-\infty}^{+\infty} d_{p} e^{\left( \frac{2\pi ipx}{L}  \right)}.      
\end{equation}

Now consider 

\begin{equation}
    \begin{aligned} 
    \frac{1}{L} \int_{x_0 }^{x_0 + L} f(x)g^*(x)dx &= \sum_{r=-\infty}^{+\infty} c_{r} \frac{1}{L} \int_{x_0 }^{x_0 + L} g^*(x) e^{\frac{2\pi irx}{L} }dx \\ &= \sum_{r=-\infty}^{+\infty} c_{r} \left( \frac{1}{L} \int_{x_0 }^{x_0 + L} g(x) e^{\left( \frac{-2\pi irx}{L}  \right)}   \right)^* = \sum_{r=-\infty}^{+\infty} c_{r} \gamma _{r}^*.            
    \end{aligned} 
\end{equation}

\section{Fourier Transforms}

Replacing the general variable \(x\) with time \(t\), we can express any time-varing function with period \(T\) as 

\begin{equation}
    f(t) = \sum_{r=-\infty}^{+\infty} c_{r} e^{\left( \frac{2\pi irt}{T}  \right)} = \sum_{r=-\infty}^{+\infty} c_{r} e^{i\omega _{r} t }, ~~~ c_{r} = \frac{1}{T} \int_{-\frac{T}{2} }^{\frac{T}{2} } f(t) e^{-\frac{2\pi irt}{T} }dt = \frac{\Delta \omega }{2\pi } \int_{-\frac{T}{2} }^{\frac{T}{2} } f(t) e^{-i \omega _{r} t} dt    ,        
\end{equation}

where we have defined 

\begin{equation}
    \omega _{r} \equiv \frac{2\pi r}{T} \implies \Delta \omega = \frac{2\pi }{T}.   
\end{equation}

For function with no periodicity, we have \(T \to \infty\) and \(\Delta \omega = 2\pi /T \to 0 \). Thus we have

\begin{equation}
    \begin{aligned} 
    f(t) &= \sum_{r=-\infty}^{+\infty} \frac{\Delta \omega }{2\pi } \left( \int_{-\infty}^{\infty } f(t) e^{- i \omega _{r} t} dt \right) e^{i \omega _{r} t} \\
    &= \frac{1}{2\pi } \int_{-\infty}^{+\infty} e^{i \omega t}  \left( \int_{-\infty}^{\infty } f(t) e^{- i \omega t} dt \right) d \omega 
    \end{aligned} 
\end{equation}

The integral in the bracket (times \(1 /\sqrt{2\pi }  \)) is defined to be the Fourier transform of \(f(t)\), denoted by 

\begin{equation}
    \tilde{f}(\omega ) = \frac{1}{\sqrt{2\pi } } \int_{-\infty}^{+\infty} f(t) e^{-i \omega t}dt.     
\end{equation}

The whole integral is the inverse Fourier transform, denoted by 

\begin{equation}
    f(t) = \frac{1}{\sqrt{2\pi } } \int_{-\infty}^{+\infty} \tilde{f}(\omega )e^{i \omega t} d \omega .     
\end{equation}

\example{The Uncertainty Principle}
{Find the Fourier transform of the normalized Gaussian distribution 

\begin{equation}
    f(t) = \frac{1}{\tau \sqrt{2\pi } } e^{-\frac{t^2}{2\tau ^2} }.
\end{equation}~
}
{The Fourier transform of \(f(t)\) is given by 

\begin{equation}
    \begin{aligned} 
    \tilde{f}(\omega ) &= \frac{1}{\sqrt{2\pi } } \int_{-\infty}^{+\infty} \frac{1}{\tau \sqrt{2\pi } } e^{-\frac{t^2}{2\tau ^2} } e^{-i \omega t}dt \\
    &= \frac{1}{2\pi  } \int_{-\infty}^{+\infty}  e^{-\frac{1}{2\tau ^2} (t^2 + 2\tau ^2i \omega t + (\tau ^2i \omega )^2 - (\tau ^2 i \omega )^2) } dt \\
    &= \frac{e^{-\frac{\tau ^2\omega ^2}{2} } }{2\pi  }  \int_{-\infty}^{+\infty} e^{-\frac{(t-i\tau ^2\omega ^2)^2}{2\tau ^2} }dt = \frac{e^{-\frac{\tau ^2\omega ^2}{2} } }{2\pi  },
    \end{aligned}         
\end{equation}

which is another Gaussian distribution with a root mean square deviation of \(\frac{1}{\tau } \). Thus the standard deviation in \(t \text { and } \tau \) is inversely related, \textit{i.e.,} \(\sigma _{t}\sigma _{\omega }=1  \), independent of the value of \(\tau \). 

In quantum mechanics, \(f(t) \text { or }  f(x)\) represents a wave function evoluting in time or space and the probability of finding the particle at position \(x\) at time \(t\) is given by \(\abs{f(x)}^2 \text { or } \abs{f(t)}^2  \), which is also a Gaussian but with the standard deviation multiplied by a factor of \(\frac{1}{\sqrt{2} } \). 

Similarly, the probability distribution in terms of frequency and wave vector is given by \(\abs{f(\omega )}^2 \text { or } \abs{f(k)}^2 \). 

Therefore, since \(p = \hbar k \text { and } E = \hbar \omega \), we have 

\begin{equation}
    \Delta E \Delta t = \frac{\hbar }{2} ~\text { and }~ \Delta p\Delta x = \frac{\hbar }{2}.  
\end{equation}


} 


\chapter{Statistics}
		
\section{Standard Deviation}

For a set of data which contains of \(N\) distinct values \(j_1, j_2, \ldots , j_i, \ldots , j_N\) and each with frequency \(f_1, f_2, \ldots , f_i, \ldots f_N\), we can define \( P_i = f_i / \sum_{i=1}^{N} f_i\) as the probability of selecting the data \(j_i\), then the average value of any function \(g(j)\) can be written as 
	
\begin{equation}
	 \avg{g(j)}  = \frac{f_1 g(j_1) + f_2 g(j_2) + \cdots + f_N g(j_N)}{f_1 + f_2 + \cdots + f_N} = \sum_{i=0}^{N} P_j g(j_i). \label{prob} 
\end{equation}
	
To measure the dispersion of the set of data, the most intuitive way is to calculate the average of difference between each data and the mean

\begin{equation} 
	\sigma' = \frac{f_1(j_1 - \avg{ j }) + f_2(j_2 - \avg{ j }) + \cdots + f_N(j_N - \avg{ j })}{f_1 + f_2 + \cdots + f_N}. \label{abc} 
\end{equation}

However, \(\sigma'\) always equals to zero since \( \sum_{i=1}^{N} f_i j_i = \avg{ j } \sum_{i=1}^{N} f_i \). So, either we take the absolute value of each term or we square each term in \cref{abc} such that the result is non trivial. We adopt the latter choice since the former is tedious. We introduce the quantity standard deviation \(\sigma\) defined by

\begin{equation} 
	\sigma^2 = \frac{f_1(j_1 - \avg{ j })^2 + f_2(j_2 - \avg{ j })^2 + \cdots + f_N(j_N - \avg{ j })^2}{f_1 + f_2 + \cdots + f_N} = \sum_{i=0}^{N} P_j (j_i - \avg{ j })^2. \label{sigma} 
\end{equation}

Note that \(\sigma\) in \cref{sigma} is squared so that the standard deviation has the same dimension as \(j\).

By expanding the bracket in \cref{sigma} and applying \cref{prob}, we have

\begin{equation} 
	\begin{aligned} 
		\sigma^2 &= \sum_{i=1}^{N} P_i (j_i^2 - 2j_i\avg{ j } + \avg{ j }^2) \\ &= \sum_{i=1}^{N} (j_i)^2 P_i - 2 \avg{ j } \sum_{i=1}^{N} (j_i) P_i + \avg{ j }^2 \sum_{i=1}^{N} P_i \\ &= \avg{ j^2 } - 2\avg{ j } \avg{ j } + \avg{ j }^2 = \avg{ j^2 } - \avg{ j }^2. 
	\end{aligned} 
\end{equation}

Therefore, we have the useful identity

\begin{equation} 
	\sigma = \sqrt{\avg{ j^2 } - \avg{ j }^2}. 
\end{equation}
	
\section{Probability Density Function}
	
When we consider continuous variable, the probability of obtaining a certain value becomes meaningless now as there are infinite choices now so we define the probability density function \(\rho(x)\) such that the probability of obtaining a value between \(x\) and \(x + dx\) equals to \(\rho(x)dx\) (its discrete counterpart being \(P_{i}\)). Therefore, just like the previous section, we have the relations
	
\begin{equation} 
	\int_{-\infty}^{+\infty} \rho(x)dx = 1 \text { and } 	\avg{ f(x) } = \int_{-\infty}^{+\infty} f(x)\rho(x) dx .
\end{equation}

	
\example{Free Falling of an Object.}
{Consider an object being released at height \(h\). Find the average distance \(\avg{x}\) from the point of release if a random instant is chosen.}
{Let \(\rho(x)dx\) be the probability of a random instant being located between \(x\) and \(x + dx\) which is equals to \(\frac{dt}{T}\). Since \(v = \dv{x}{t} = gt\) and \(T = \sqrt{\frac{2h}{g}}\), so we have \(\rho(x) = \frac{1}{2\sqrt{hx}}\).\(\avg{x}\) can then be obtained from straightforward integration 
\begin{equation} 
	\avg{x} = \int_{0}^{h} \frac{x}{2\sqrt{hx}} dx = \frac{h}{3}.
\end{equation}}

We can define a joint probability distribution \(\rho _{x,y}(x,y) \), where \(\rho _{x,y}(x,y)dxdy \) is the probability for the variable \(x\) to obtain a value between \(x \text { and } x+dx\), and for the variable \(y\) to obtain a value between \(y \text { and } y+dy\). 

The marginal distribution \(\rho _{x}(x) \) regardless of the value of \(y\) is obtained by integrating the joint probability density function over all allowed values of \(y\) to get \(\rho _{x}(x) = \int_{-\infty}^{+\infty}  \rho _{x,y}(x,y)dy\).

The conditional distribution \(\rho _{x} (x)\) given \(y = y_0 \) is obtained by \(\rho _{x} (x) = \frac{\rho _{x,y} (x,y_0 )}{\rho _{y}(y_0 ) } \), where the denominator serving a renormalization purpose.

\example{Joint Probability Density Function.}
{Alice and Bob agree to meet for lunch at some time between noon and 1 pm. They are both willing to wait up to 10 min for the other to arrive, but will leave otherwise. Find the probability that they meet for lunch, if
\begin{enumerate}[itemsep=10pt]
	\item their arrival times are independent and uniformly distributed, or
	\item their arrival times are independent, but while Alice's probability of arrival is uniform, Bob is quadractically more likely to arrive later in the hour.    
\end{enumerate}~}
{\begin{enumerate}
    \item For the first case, we have \(\rho _{x} = \rho _{y} = C\). Normalizing gives \(C = \frac{1}{60 \text{mins} } \). So the joint probability density function is \(\rho _{x,y} = \frac{1}{3600 \text{mins} }  \). We then have to integrate the joint probability density function over the region in which \(\abs{y-x} \le 10 \) 
    
    \begin{equation}
        P(\abs{y-x}\le 10 ) = \int_{\abs{y-x} \le 10}^{}\rho _{x,y}dxdy ,
    \end{equation}
    
    which is the area of the region bounded by the \(x,y\) axes, the vertical and horizontal \(y=60 \text { and } x=60\), respectively, and the lines \(y = x+10 \text { and } y = x-10\), divided by 3600. So we get \( P(\abs{y-x}\le 10 ) = 1100 /3600 \approx 31 \% \).
    
    \item In the second case, for alice we still have \(\rho _{x} = \frac{1}{60 \text{mins} }  \), for Bob we have \(\rho _{y}  = Cy^2 \), where upon normalization \(C = \frac{3}{60^3 \text{mins} } \). The joint probability density function is therefore \( \rho _{x,y} = 3 y^2 / 60^2\). Carrying out the double integral over the same region, we get \( P(\abs{y-x}\le 10 ) = 767 /2592 \approx 30\% \).  
\end{enumerate}~
} 

\example{Relations Between Variables.}
{\(X\) has the probability distribution function

\begin{equation}
    f_{X}(x) = \frac{1}{2}e^{- \abs{x} }.
\end{equation}

Find the culmulative distribution function and probability distribution function for \(Y = X^2\), \textit{i.e.,} \(F_{Y}(y) \text { and } f_{Y}(y) \).  
}
{For the culmulative distribution function, since \(Y \ge 0\), \(P(Y \le 0) = 0\), so \(F_{Y}(y) = 0 \) for \(y \le 0\). For \(y \ge 0\),

\begin{equation}
    F_{Y}(y) = P(Y \le y) = P(-\sqrt{y} \le X \le \sqrt{y}  ) = \int_{-\sqrt{y} }^{\sqrt{y} } \frac{1}{2} e^{- \abs{x} }dx = 1-e^{-\sqrt{y} }. 
\end{equation}

For the probability distribution function, we simply take the derivative

\begin{equation}
    f_{Y}(y) = \frac{d}{dy} (1-e^{-\sqrt{y} } ) = \frac{e^{-\sqrt{y} } }{2\sqrt{y} }.  
\end{equation}

This is for \(y \ge 0\), and for \(y \le 0\) it is still zero.  
} 


\example{Marginal Probability Density Functions.}
{A two dimensional joint probability density function is given by 

\begin{equation}
    f_{XY}(x,y) = \begin{cases}
        6xy,& 0 \le x \le 1, 0 \le y \le \sqrt{x}, \\
        0,& \text{otherwise} .
    \end{cases}
\end{equation}

Find the marginal probability density functions, \(f_{X}(x) \text { and } f_{Y}(y)  \).
}
{The marginal probabilty density functions are 

\begin{equation}
    f_{X}(x) = \int_{0}^{\sqrt{x} } 6xy dy = 3x^2 ~\text { and }~ f_{Y}(y) = \int_{y^2}^{1} 6xy dx = 3y(1-y^4).      
\end{equation}

Note that to find \(f_{X}(x) \), we are focusing on a particular value of \(x\), and we sum up all the \(6xy \times dy\). The same holds for \(f_{Y}(y) \).    
} 











































\end{document}
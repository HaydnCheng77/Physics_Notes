\documentclass[english,a4paper,12pt]{report}
\usepackage{mypackage}

\title{Calculus}

\author{Haydn Cheng}

\date{\today}

\begin{document}
\maketitle
\tableofcontents

\chapter{Differentiation}

\section{Ordinary Differentiation}

\subsection{Leibnitz' Theorem} \label{leibnitz} 
\begin{theorem}
    The \(n^{\text{th }} \) order derivative of the product of two fucntions \(f(x) = u(x)v(x)\) is\footnote{Proof given in \cref{leibnitzapp}.}  
    \begin{equation}
        f^{(n)} = \sum_{r=0}^{n} \binom{n}{r} u^{(r)} v^{(n-r)}. \label{lei} 
    \end{equation}
\end{theorem}

\subsection{Speecial Points of a Function}

A stationary piont is characterised by \(\frac{df}{dx} = 0\), and can be further classified into 

\begin{enumerate}
    \item Minimum point: \(\frac{d^2f}{dx^2} > 0\) ,
    \item Maximum point: \(\frac{d^2f}{dx^2} < 0\) and
    \item Inflection point (which is also stationary): \(\frac{d^2f}{dx^2} = 0 \text { and }  \frac{d^2f}{dx^2} \)  changes sign.
\end{enumerate}

If \(\frac{d^2f}{dx^2} = 0\) but it does not change sign before and after the stationary point, it could be either of the three cases; we would have to check higher derivatives to verify its nature. 

An inflection point (which is not stationary) is when \(\frac{d^2f}{dx^2} = 0\) but \(\frac{df}{dx} \neq 0\) where the concavity of the fucntion changes.  

\section{Partial Differentiation}

In this section we investigate how a function with more than one variable changes when the variables change\footnote{It is fine if the variables are themselves connected with each other, say\(y = y(x)\).}. We will restrict ourselves most to functions that depend on two variables, since \(f(x,y)\) can still be visualized by a surface in a three-dimensional space, similar to how we represent \(f(x)\) as a curve in a two-dimensional space. However, it is difficult to visualise functions of more than two variables. 

\subsection{Partial Derivatives}

We start by finding how \(f(x,y)\) changes when one of the variables, say \(x\), changes, while the other variable (\(y\)) is kept constant. But now this becomes an ordinary differentiation since \(f(x,y) = f(x)\) when \(y\) is kept constant. In analogous to how ordinary derivativce is defined, we have

\begin{equation}
    \left( \frac{\partial f}{\partial x} \right)_{y} = \frac{\partial f}{\partial x} = f_{x}  = \lim_{\Delta x \to 0} \frac{f(x+\Delta x,y) - f(x,y)}{\Delta x},
\end{equation}

where 3 equivalent notations are used to denote the partial derivative of \(f(x,y)\) with respect to \(x\) in order of descending formality.

A very useful fact about the second partial derivative which the proof is not given here is that 

\begin{equation}
    \frac{\partial^2 f}{\partial x \partial y} = \frac{\partial }{\partial x} \left( \frac{\partial f}{\partial y}  \right) = f_{xy} = f_{yx} = \frac{\partial }{\partial y} \left( \frac{\partial f}{\partial x}  \right) = \frac{\partial^2 f}{\partial y \partial x}.     
\end{equation}

\subsection{Total Derivatives}

Now we consider how \(f(x,y)\) changes when both \(x \text { and } y\) change. We have

\begin{equation} \label{totaldf} 
    \begin{aligned}
        \Delta f &= f(x+\Delta x,y+\Delta y) - f(x,y) \\
        &= f(x+\Delta x,y+\Delta y) - f(x,y) + f(x,y+\Delta y) - f(x,y+\Delta y) \\
        &= \frac{f(x+\Delta x,y+\Delta y)-f(x,y+\Delta y)}{\Delta x}\Delta x + \frac{f(x,y+\Delta y)-f(x,y)}{\Delta y} \Delta y \\
        &\approx \frac{\partial f}{\partial x} \Delta x + \frac{\partial f}{\partial y} \Delta y. 
    \end{aligned}
\end{equation}

The approximation becomes exact as \(\Delta x \rightarrow  0 \text { and }  \Delta y \rightarrow 0\). 

This result shows that if the changes in \(x \text { and } y\) are small enough, we can consider the change in \(f(x,y)\) due to \(x \text { and } y\) separately, as any change in \(f(x,y)\) that is not linear to \(\Delta x \text { or } \Delta y\) is negligble as \(\Delta x \rightarrow 0 \text { and } \Delta y \rightarrow 0\).     


\subsection{Exact Differentials}

An arbitrary differential 

\begin{equation}
    A(x,y) dx + B(x,y) dy
\end{equation}

is exact if it is the differential of a function 

\begin{equation}
    df(x,y) = \frac{\partial f}{\partial x} dx + \frac{\partial f}{\partial y} dy.
\end{equation}

Therefore, we have

\begin{equation}
    A(x,y) = \frac{\partial f}{\partial x} \text { and } B(x,y) = \frac{\partial f}{\partial y}
\end{equation}

Since \(\frac{\partial^2 f}{\partial x \partial y} = \frac{\partial^2 f}{\partial y \partial x}\), we obtain a necessary (and a sufficient) condition for the differential to be exact, which is

\begin{equation}
    \frac{\partial A}{\partial y} = \frac{\partial B}{\partial x}\footnote{Determining whether a differential containing many variables \(x_1, x_2, \ldots, x_{n}\) is exact is a simple extension of the above: a differential \(df = \sum_{i=1}^{n} g_{i}(x_1 ,x_2 ,\ldots , x_{n} )dx_{i}  \) is exact if \(\frac{\partial g_{i} }{\partial x_{j} } = \frac{\partial g_{j} }{\partial x_{i} } \) for all pairs \(i,j\).} .
\end{equation}

\subsection{Reciprocity Relation and Cyclic Relation}

So far our discussion has centred on a function \(f(x,y)\) dependent on two variables, \(x\text { and } y\). However, f(x,y) is not superior, \(x(f,y) \text { and } y(x,f)\) are equally valid and are expressing the identical relation between \(x,y \text { and } f\). To emphasise the point that all the variables are of equal standing we now replace \(f\) by \(z\). Then we have

\begin{equation}
    \begin{aligned}
    dx &= \left( \frac{\partial x}{\partial y}  \right)_{z} dy + \left( \frac{\partial x}{\partial z}  \right)_{y} dz \text { and }   dy = \left( \frac{\partial y}{\partial x}  \right)_{z} dx + \left( \frac{\partial y}{\partial z}  \right)_{x} dz \\
    \implies dx &= \left( \frac{\partial x}{\partial y}  \right)_{z} \left( \frac{\partial y}{\partial x}  \right)_{z} dx + \left( \left( \frac{\partial x}{\partial y}  \right)_{z}  \left( \frac{\partial y}{\partial z}  \right)_{x} + \left( \frac{\partial x}{\partial z}  \right)_{y}  \right) dz. 
    \end{aligned}
\end{equation}

Since \(dx \text { and }  dz\) are independent, we the reciprocity and the cyclic relation 

\begin{equation}
    \left( \frac{\partial x}{\partial y}  \right)_{z} = \left( \frac{\partial y}{\partial x}  \right)_{z}^{-1} \text { and } \left( \frac{\partial y}{\partial z}  \right)_{x} \left( \frac{\partial z}{\partial x}  \right)_{y} + \left( \frac{\partial x}{\partial y}  \right)_{z} = -1 
\end{equation}

\subsection{Change of Variables}

Again, we emphasize that it is completely fine if the variables are related by some separate relations or cosntriant. Suppose \(x \text { and } y\) are fucntions of some other variable \(u\). Then to find out how \(f(x,y)\) changes with \(u\), we simplify divide the total derivative of \(f\) with respect to \(x \text { and } y\) by \(du\), so

\begin{equation}
    \frac{df}{du} = \frac{\partial f}{\partial x} \frac{dx}{du} + \frac{\partial f}{\partial y} \frac{dy}{du},
\end{equation}

which is analogous to chain rule in ordinary differentiation.

Suppose now instead of having a constriatn on \(x\text { and } y\), we would like to change the whole set of variables \((x,y)\) to \((u,v)\). Then we have \(x = x(u,v) \text { and } y = y(u,v)\). So the derivatives become

\begin{equation}
    \frac{\partial f}{\partial u} = \frac{\partial f}{\partial x} \frac{\partial x}{\partial u} + \frac{\partial f}{\partial y} \frac{\partial y}{\partial u} \text { and } \frac{\partial f}{\partial v} = \frac{\partial f}{\partial x} \frac{\partial x}{\partial v} + \frac{\partial f}{\partial y} \frac{\partial y}{\partial v}.  
\end{equation}



\subsection{Taylor's Theorem}
When \(\Delta x \text { and }  \Delta y\) are finite, we can no longer neglect the terms which are not linear in \(\Delta x \text { or } \Delta y\) in \cref{totaldf}, instead, we get the taylor series 

\begin{equation}
    \begin{aligned}
    f(x,y) &= f(x_0 ,y_0 ) + \eval{\frac{\partial f}{\partial x}}_{(x_0 ,y_0 )}  \Delta x + \eval{\frac{\partial f}{\partial y}}_{(x_0 ,y_0 )} \Delta y \\ &+ \frac{1}{2!} \left( \eval{\frac{\partial^2 f}{\partial x^2}}_{(x_0 ,y_0 )}  (\Delta x)^2 + 2\eval{\frac{\partial^2 f}{\partial x \partial y}}_{(x_0 ,y_0 )}(\Delta x)(\Delta y) + \eval{\frac{\partial^2 f}{\partial y^2}}_{(x_0 ,y_0 )} (\Delta y)^2 \right) \\ &+ \mathcal{O}((\Delta x)^3 ) + \mathcal{O}((\Delta y)^3 ).        
    \end{aligned}
\end{equation}

It can be shown that the general Taylor's theorem can be written as 

\begin{equation}
    f(\vb{x} ) = \sum_{n=0}^{\infty} \frac{1}{n!} \eval{\left[ (\Delta \vb{x} \cdot \nabla )^{n} f(\vb{x} ) \right]}_{\vb{x} = \vb{x} _{0}}  .
\end{equation}

\subsection{Speical Points of a Function}

From the Taylor's series above, we can see that a necessary and sufficient condition for a stationary point is that both partial derivatives vanish

\begin{equation}
    \eval{\frac{\partial f}{\partial x}}_{(x_0 ,y_0 )} = \eval{\frac{\partial f}{\partial y}}_{(x_0 ,y_0 )} =0.
\end{equation}

To find the natures of the sationary points, we first complete the square so that 

\begin{equation}
    df = f(x,y) - f(x_0 , y_0 ) \approx  \frac{1}{2} \left[ f_{xx}\left( \Delta x+ \frac{f_{xy}\Delta y }{f_{xx} }  \right)^2 + (\Delta y)^2\left( f_{yy} - \frac{f_{xy}^2 }{f_{xx} }   \right)  \right].
\end{equation}

For a minimum point, we require that \(df>0\) for arbitrary \(\Delta x \text { and } \Delta y\). This implies that \(f_{xx} >0 \text { and } \left( f_{xx}f_{yy} > f_{xy}^2 \right)\). Due to symmtry of \(x \text { and } y\), \(f_{\vb{y} } >0\) is also necessary. For saddle point, \(df\) can be positve, negative or zero depending on the choice of \(\Delta x \text { and } \Delta y\). Therefore,

\begin{enumerate}
    \item Minimum point: both \(f_{xx} > 0, f_{yy} > 0 \text { and } f_{xy}^2 < f_{xx}f_{yy}\),
    \item Maximum point: both \(f_{xx} < 0, f_{yy} < 0 \text { and } f_{xy}^2 < f_{xx}f_{yy}\) and
    \item Saddle point: \(f_{xx} \text { and } f_{yy}\) have opposite signs (or \(f_{xy}^2 > f_{xx}f_{yy}\)). 
\end{enumerate}

If \(f_{xy}^2 = f_{xx}f_{yy}\), then \(df\) must be one of the four fomrs \(\pm \frac{1}{2} (\abs{f_{xx} }^{\frac{1}{2} } \Delta x \pm \abs{f_{yy} }^{\frac{1}{2} }\Delta y)^2\), then for some choice of the ration \(\frac{\Delta y}{\Delta x}\) \(df = 0\) so higher order terms are needed to find the nature of the stationary point. 

For functions with more than 2 variables, the conditions for stationary points are 

\begin{equation}
    \frac{\partial f}{\partial x_{i} } = 0 ~~~\forall~ x_{i},
\end{equation}

where \(x_{i} \) are the variables. 

To investigate the nature of the stationary points, we again use the second order term of the Taylor's series

\begin{equation}
    df = f(\vb{x} ) - f(\vb{x} _{0} ) \approx \frac{1}{2}\sum_{i} \sum_{j} \frac{\partial^2 f}{\partial x \partial y} \Delta x_{i}\Delta x_{j},      
\end{equation}

which must be positive for all \(\Delta x_{i} \).

\section{Curvilinear coordinates}

\subsection{General Curvilinear Coordinates}

A point in three-dimensional space can be specified by three coordinates \(u,v,w\). In Cartesian coordinates, \((u,v,w) = (x,y,z)\); In spherical coordinates, \((u,v,w) = (r, \theta, \phi)\); In cyilndrical coordintes, \((u,v,w) = (\rho, \phi, z)\). 

The infinitesimal displacement vector \(d \vb{r} \)  from \((u,v,w)\) to \((u+du, v+dv, w+dw)\) can be written as

\begin{equation} 
	d\vb{r} = \frac{\partial \vb{r} }{\partial u} du + \frac{\partial \vb{r} }{\partial v}dv + \frac{\partial \vb{r} }{\partial w}dw. 
\end{equation}

If the coordinate system is orthogonal \ie \(\vu{u} \perp \vu{v} \perp \vu{w}\), where \(\vu{u} ,\vu{v} \text { and } \vu{w} \) are the unit vectors whose direction are directed along increaseing \(u, v \text { and } w\) respectively, then we have

\begin{equation}
    \frac{\partial \vb{r} }{\partial u} = f \vu{u}, \frac{\partial \vb{r} }{\partial v} = g \vu{v}  \text { and } \frac{\partial \vb{r} }{\partial w} = h \vu{w}  ,
\end{equation}

where \(f,g\) and \(h\) are characteristic constants of a coordinates system which scale the unit vectors. In Cartesian coordinates, \((f,g,h) = (1,1,1)\); In spherical coordinates, \((f,g,h) = (1,r,r\sin{\theta})\); In cyilndrical coordinates, \((f,g,h) = (1,\rho ,1)\).
	
The infinitesimal displacement vector is now 

\begin{equation}
    d \vb{r} = f(du\vu{u}) + g(dv\vu{v}) + h(dw\vu{w}) \label{dl} 
\end{equation}

and the arc length is the norm of \(d \vb{r} \), which is 

\begin{equation}
    ds = \sqrt{d \vb{r} \cdot d \vb{r} } = \sqrt{(fdu)^2 + (gdv)^2 + (hdw)^2}.  
\end{equation}



The infinitesimal area perpendicular to \(\vu{w}\) will be a rectangle with area
\begin{equation}
	da = (fg)dudv \label{da}
\end{equation} 

as shown in \cref{infloop}.

\onefig{infloop}{scale=0.3}
	
The infinitesimal volume is a parallelepiped (rectangular solid if the system is orthogonal) with volume

\begin{equation}
    d \tau = \abs{fd \vu{u} \cdot (gd \vu{v} \cross hd \vu{w} )}dudvdw = (fgh)dudvdw 
\end{equation}

as shown in \cref{infvol}. 

\onefig{infvol}{scale=0.3}
	
\subsection{Spherical Coordinates}
\onefig{spherical}{scale=0.7}


From \cref{spherical}, the relations of the two set of variables \((x,y,z) \text { and } (r,\theta ,\phi  )\)  are

\begin{equation}
    \begin{cases} x = r\sin \theta \cos \phi \\ y = r\sin \theta \sin \phi \\ z = r\cos \theta \end{cases} \text { or } \begin{cases} r = \sqrt{x^2+y^2+z^2} \\ \theta = \arctan {\left(\frac{\sqrt{x^2+y^2} }{z} \right)} \\ \phi = \arctan {\left(\frac{y}{x}\right)} \end{cases}. 
\end{equation}

A general position vector can then be written as 

\begin{equation}
    \vb{r} = x \vu{x} + y \vu{y} + z \vu{z} = r\sin \theta \cos \phi \vu{x} + r\sin \theta \sin \phi \vu{y} + r \cos \theta \vu{z} .
\end{equation}

A general infinitismal displacement vector can be written as 

\begin{equation}
    \begin{aligned}
    d \vb{r} &= \frac{\partial \vb{r} }{\partial x} dx + \frac{\partial \vb{r} }{\partial y} dy + \frac{\partial \vb{r} }{\partial z} dz = dx \vu{x} + dy \vu{y} + dz \vu{z} \\ &= \frac{\partial \vb{r} }{\partial r} dr + \frac{\partial \vb{r} }{\partial \theta }d\theta + \frac{\partial \vb{r} }{\partial \phi }d \phi =f dr \vu{r} +g d\theta \vu{\boldsymbol{\theta } } +h  d \phi \vu{\boldsymbol{\phi } }. 
    \end{aligned}
\end{equation}

where \(\frac{\partial \vb{r} }{\partial r}, \frac{\partial \vb{r} }{\partial \theta } \text { and } \frac{\partial \vb{r} }{\partial \phi } \) can be found by direct differentiaion as 

\begin{equation}
	\begin{aligned} 
		\frac{\partial \vb{r} }{\partial r}   &= f \vu{r} = \sin{\theta}\cos{\phi}\vu{x} + \sin{\theta}\sin{\phi}\vu{y} + \cos{\theta}\vu{z}, \\
		\frac{\partial \vb{r} }{\partial \theta }  &= g \vu{\boldsymbol{\theta }} = r(\cos{\theta}\cos{\phi}\vu{x} + \cos{\theta}\sin{\phi}\vu{y} - \sin{\theta}\vu{z})\text { and }  \\
		\frac{\partial \vb{r} }{\partial \phi }  &= r \vu{\boldsymbol{\phi } } = \sin \theta (-\sin{\phi}\vu{x} + \cos{\phi}\vu{y}). 
	\end{aligned} 
\end{equation}

Thus \(f = 1, g = r \text { and }  h = r\sin \theta \).

We can thus solve for \((\vu{r} , \vu{\boldsymbol{\theta } }, \vu{\boldsymbol{\phi } })\) in terms of \((\vu{x}, \vu{y} ,\vu{z} )\) as 

\begin{equation}
    \begin{cases}
        \vu{r} = \sin \theta \cos \phi  \vu{x}  + \sin \theta \sin \phi  \vu{y}  + \cos \theta  \vu{z},  \\
        \vu{\boldsymbol{\theta } } = \cos \theta \cos \phi \vu{x}  + \cos \theta \sin \phi \vu{y} 0 \sin \theta \vu{z}, \\
        \vu{\boldsymbol{\phi } } = -\sin \phi  \vu{x} + \cos \phi \vu{y}. 
    \end{cases}
\end{equation}



We can also solve for \((\vu{x} , \vu{y}, \vu{z} )\) in terms of \((\vu{r} , \vu{\boldsymbol{\theta } }, \vu{\boldsymbol{\phi } } )\) as  

\begin{equation}
    \begin{cases}
        \vu{x} = \sin \theta \cos \phi \vu{r} + \cos \theta \cos \phi \vu{\boldsymbol{\theta } } - \sin \phi \vu{\boldsymbol{\phi } }, \\
        \vu{y} = \sin \theta \sin \phi \vu{r} + \cos \theta \sin \phi \vu{\boldsymbol{\theta } } + \cos \phi \vu{\boldsymbol{\phi } }, \\
        \vu{z} = \cos \theta \vu{r} - \sin \theta \vu{\boldsymbol{\theta } }.
    \end{cases}
\end{equation}



	
\subsection{Cylindrical Coordinates}
\onefig{cylindrical}{scale=0.5}

From \cref{cylindrical}, the relations of the two set of variables \((x,y,z) \text { and } (\rho , \phi , z)\)  are

\begin{equation}
    \begin{cases} x = \rho \cos \phi \\ y = \rho \sin \phi \\ z = z \end{cases} \text { or } \begin{cases} \rho  = \sqrt{x^2+y^2} \\ \phi = \arctan {\left( \frac{y}{x}  \right)} \\ z = z \end{cases}. 
\end{equation}

A general position vector can be written as 

\begin{equation}
    \vb{r} = x \vu{x} + y \vu{y} + z \vu{z} = \rho \cos \phi  \vu{x} + \rho \sin \phi \vu{y} + \vu{z} .
\end{equation}

A general infinitismal displacement vector can be written as 

\begin{equation}
    \begin{aligned}
    d \vb{r} &= \frac{\partial \vb{r} }{\partial x} dx + \frac{\partial \vb{r} }{\partial y} dy + \frac{\partial \vb{r} }{\partial z} dz = dx \vu{x} + dy \vu{y} + dz \vu{z} \\ &= \frac{\partial \vb{r} }{\partial \rho } d\rho  + \frac{\partial \vb{r} }{\partial \phi  }d \phi  + \frac{\partial \vb{r} }{\partial z}d z =f d \rho  \vu{\boldsymbol{\rho } }  +g d\phi \vu{\boldsymbol{\phi  } } +h  d z\vu{\boldsymbol{z} }. 
    \end{aligned}
\end{equation}

where \(\frac{\partial \vb{r} }{\partial \rho }, \frac{\partial \vb{r} }{\partial \phi } \text { and } \frac{\partial \vb{r} }{\partial z} \) can be found by direct differentiaion as 

\begin{equation}
	\begin{aligned} 
		\frac{\partial \vb{r} }{\partial \rho }  &= f \vu{\boldsymbol{\rho } } = \cos{\phi}\vu{x} + \sin{\phi}\vu{y}, \\
		\frac{\partial \vb{r} }{\partial \phi }  &= g \vu{\boldsymbol{\phi } } = \rho (-\sin{\phi}\vu{x} + \cos{\phi}\vu{y}) \text { and }  \\
		\frac{\partial \vb{r} }{\partial z }  &= h \vu{z} = \vu{z}. 
	\end{aligned} 
\end{equation}

Thus \(f = 1, g = \rho  \text { and }  h = 1\). 

We can thus solve for \((\vu{\boldsymbol{\rho } }, \vu{\boldsymbol{\phi } }, \vu{z} )\) in terms of \((\vu{x} ,\vu{y} ,\vu{z} )\) as

\begin{equation}
    \begin{cases} 
        \vu{\boldsymbol{\rho } } = \cos \phi \vu{x} + \sin \phi \vu{y}, \\
        \vu{\boldsymbol{\phi } } = -\sin \phi \vu{x} + \cos \phi \vu{y}, \\
        \vu{z} = \vu{z}.
        \end{cases}
\end{equation}



We can also solve for \((\vu{x} , \vu{y}, \vu{z} )\) in terms of \((\vu{\boldsymbol{\rho } }, \vu{\boldsymbol{\phi } }, \vu{z} )\) as  

\begin{equation}
    \begin{cases}
        \vu{x} &= \cos \phi  \vu{\boldsymbol{\rho } } - \sin \phi \vu{\boldsymbol{\phi } }, \\
        \vu{y} &= \sin \phi \vu{\boldsymbol{\rho } } + \cos \phi \vu{\boldsymbol{\phi } }, \\
        \vu{z} &= \vu{z}. 
        \end{cases}
\end{equation}

\subsection{Space Curves}

A curve in space can be described by the vector \(\vb{r} (t)\) joining the origin \(O\) of a coordinate system to a point on the curve. As the parameter \(t\) varies, the end-point on the curve moves along the curve. Some common examples of the parameter are time and arclength. In Cartesian coordinates, 

\begin{equation}
	\vb{r} (u) = x(u) \vu{x} + y(u) \vu{y} + z(u) \vu{z} .
\end{equation}

Alternatively, a space curve in three-dimensional space can be represented by two simultaneous equations \(F(x,y,z) = G(x,y,z) = 0\). 

Imagine two position vectors \(\vb{r} (u) \text { and } \vb{r} (u + du)\), the difference \(d \vb{r} \)  is a vector tangent to \(C\) at that point in the direction of increasing \(u\). In the special case where the parameter \(u\) is the arc length \(s\) along the curve 

\begin{equation}
	\vu{t} = \frac{d\vb{r} }{ds} = \frac{d \vb{r} }{\abs{d \vb{r} } } 
\end{equation}

is the unit tangent vector.

The curvature \(\kappa \) and the pricinpal normal unit vector are defined together the rate of change of \(\vu{t} \) with respect to \(s\)

\begin{equation}
	\kappa \vu{n}  = \frac{d \vu{t} }{ds} = \frac{d^2\vb{r} }{ds^2}
\end{equation}

and the radius of curvature is defined as \(\rho = \frac{1}{\kappa } \). 

The binormal unit vector is then defined as the unit vector perpendicular to both \(\vu{t}  \text { and } \vu{n} \) 

\begin{equation}
	\vu{b} = \vu{t} \cross \vu{n} .
\end{equation}

We can similarly define the torsion \(\tau \) as the rate of change of \(\vu{b} \) with respect to \(s\)  

\begin{equation}
	-\tau \vu{n} =  \frac{d \vu{b} }{ds}, 
\end{equation}

and radius of torsion as \(\sigma  = \frac{1}{\tau } \). 

In summary, \(\vu{t} , \vu{n} \text { and } \vu{b} \) and their derivatives with respect to \(s\) are related to one another by the relations (called the Frenet-Serret formulae) 

\begin{equation}
	\frac{d \vu{t} }{ds} = \kappa \vu{n} , ~~\frac{d \vu{n} }{ds} = \tau \vu{b} - \kappa \vu{t}~~ \text { and } ~~\frac{d \vu{b} }{ds} = -\tau \vu{n} .  
\end{equation}

\example{Acceleration of a Particle}
{Show that the acceleration of a particle travelling along a trajectory \(\vb{r} (t)\) is given by 

\begin{equation}
	\vb{a} (t) = \frac{dv}{dt} \vu{t} + \frac{v^2}{\rho } \vu{n} .  
\end{equation}
~
}
{The velocity of the particle is 

\begin{equation}
	\vb{v} (t) = \frac{d \vb{r} }{dt} = \frac{d\vb{r} }{ds} \frac{ds}{dt} = \frac{ds}{dt} \vu{t} = v \vu{t} .   
\end{equation}

So the acceleration is 

\begin{equation}
	\vb{a} (t) = \frac{d\vb{v} }{dt} = \frac{dv}{dt} \vu{t} + v \frac{d \vu{t} }{dt}.   
\end{equation}

But since 

\begin{equation}
	\frac{d \vu{t} }{dt} = \frac{ds}{dt} \frac{d \vu{t} }{ds} = v \kappa \vu{n} = \frac{v}{\rho }\vu{n},   
\end{equation}

we have

\begin{equation}
	\vb{a} (t) = \frac{dv}{dt} \vu{t} + \frac{v^2}{\rho }\vu{n} .  
\end{equation}
~
}

\section{Space Surfaces}

In Cartesian coordinates a surface is given parametrically by 

\begin{equation}
	\vb{r} (u,v)  = x(u,v) \vu{x} + y(u,v) \vu{y} + z(u,v) \vu{z},
\end{equation}

or algebrically as \((F(x,y,z)) = 0\). 

The infinitesimal displacement vector is 

\begin{equation}
	d\vb{r} = \frac{\partial \vb{r} }{\partial u} du + \frac{\partial \vb{r} }{\partial v}dv 
\end{equation}

and thus the infinitesimal area is 

\begin{equation}
	da = \abs{\frac{\partial \vb{r} }{\partial u} du \cross \frac{\partial \vb{r} }{\partial v}}.
\end{equation}

\example{Area of a Sphere}
{Find the element of area on the surface of a sphere of radius \(a\) , and hence calculate the total surface area of the sphere.}
{We can represent a point \(\vb{r} \)  on the surface of the sphere in terms of the two parameters \(\theta \text { and } \phi \) as

\begin{equation}
	\vb{r} = a \sin \theta \cos \phi \vu{x} + a \sin \theta \sin \phi \vu{y} + a \cos \theta \vu{z} .
\end{equation}

An infinitesimal area is given by 

\begin{equation}
	da = \abs{\frac{\partial \vb{r} }{\partial \theta } \cross \frac{\partial \vb{r} }{\partial \phi } } = a^2\sin \theta d \theta d \phi 
\end{equation}

And the total surface area is then 

\begin{equation}
	A = \int_{0}^{\pi }\int_{0}^{2\pi } a^2 \sin \theta d \theta d \phi = 4\pi a^2.    
\end{equation}
} 












\section{Gradient, Divergence and Curl} 

We start by stating the gerneral form of del operator, gradient, divergence, curl, and Laplacian are defined as

\begin{equation} \label{all} 
\begin{aligned}
\grad &= \frac{1}{f}\vu{u}\frac{\partial}{\partial u} + \frac{1}{g}\vu{v}\frac{\partial}{\partial v} + \frac{1}{h}\vu{w}\frac{\partial}{\partial w}\footnote{The del operator is not written as \(\frac{1}{f} \frac{\partial}{\partial u}\vu{u}  + \frac{1}{g} \frac{\partial}{\partial v}\vu{v} + \frac{1}{h} \frac{\partial}{\partial w}\vu{w}\) because in a general coordinates system, unit vector is not a constant but depends on the coordinates of the point in space, so we take the unit vectors out of the partial derivatives to avoid confusion since we are not differentiating them In fact, when we calculate the divergence in \cref{div}, the order of them becomes even more prominent}, \\[10pt]
\grad{t }&= \frac{1}{f} \vu{u} \frac{\partial t}{\partial u} 
+ \frac{1}{g} \vu{v}\frac{\partial t}{\partial v}  
+ \frac{1}{h} \vu{w}\frac{\partial t}{\partial w} , \\[10pt]
\div{\vb{T}}  &= \frac{1}{fgh} \left[ 
\frac{\partial}{\partial u} (ghT_{u} ) + 
\frac{\partial}{\partial v} (fhT_{v} )+ 
\frac{\partial}{\partial w} (fgT_{h} ) \right], \\[10pt]
\curl{\vb{T} }  &= \frac{1}{fgh} 
\begin{vmatrix} 
f \vu{u} & g \vu{v} & h \vu{w} \\ 
\frac{\partial}{\partial u} & \frac{\partial}{\partial v} & \frac{\partial}{\partial w} \\ 
fT_{u}  & g T_{v}  & h T_{w}  
\end{vmatrix}, \\[10pt]
\laplacian t &= \frac{1}{fgh} \left[
\frac{\partial}{\partial u} \left( \frac{gh}{f} \frac{\partial t}{\partial u} \right) + 
\frac{\partial}{\partial v} \left( \frac{fh}{g} \frac{\partial t}{\partial v} \right) + 
\frac{\partial}{\partial w} \left( \frac{fg}{h} \frac{\partial t}{\partial w} \right)
\right],
\end{aligned}
\end{equation}

where \(t (u,v,w)\) is a scalar field and \(\vb{T} = T_{u}\vu{u} + T_{v}\vu{v} + T_{w}\vu{w} \) is a vector field.  

\subsection{Gradient}
Using the del operator defined in \cref{all}, we can write the infinitesimal change of a scalar function \(t(u,v,w)\) as

\begin{equation}
    dt = \pdv{t}{u}du + \pdv{t}{v}dv + \pdv{t}{w}dw = \grad{t} \cdot dr = \abs{\grad{t} }\abs{d \vb{r} }\cos \theta   . \label{dt} 
\end{equation}

where \(\theta\) is the angle between \(\grad{t}\) and \(d\vb{r}\).
	
From the above equation, it is evident that \(dt\) attains maximum when \(\theta = 0\), \textit{i.e.} \(d\vb{r} \parallelsum \grad{t}\). Thus, the gradient \(\grad{t}\) points in the direction of maximum increase of the function \(t\) and \(\abs{\grad{t}}\) gives the slope along this maximal direction.

%\example{Griffiths (5th ed.) Problem 1.12}
%{The height of a certain hill is given by \(h(x,y) = 10(2xy - 3x^2 - 4y^2 -18x + 28y +12)\). Find the location of the summit, and the magnitude and direction of the sleepest slope at \((1,1)\).}
%{The gradient is \(\grad{h} = 10((2y - 6x - 18)\vu{x} + (2x - 8y + 28)\vu{y})\). At the summit, \(\grad{h} = 0\). So, \(\begin{cases}
%	2y - 8x - 18 = 0  \\
%	2x - 8y + 28 = 0
%\end{cases}\), which gives \((x,y) = (3,2)\).
%\(\grad{h} = 220(-\vu{x} + \vu{y})\) at \((1,1)\), therefore the slope at \((1,1)\) equals to \(\abs{\grad{h}} = 220\sqrt{2}\) and the direction is northwest.}

\todo{problem 1.14, 1.17, 1.1.5}
	
Integrating , we get the fundamental theorem for gradients

\begin{equation} 
	t(\vb{b}) - t(\vb{a}) = \int_{\vb{a}}^{\vb{b}} \grad{t} \cdot d\vb{r}. 
\end{equation}
	
This equation shows that if one would like to determine the height of Mountain Everest, one could place altimeters at the top and the bottom and subtract the two readings, or climb the mountain and measure the rise at each step.

A quick corollary is that the integral \(\int_{\vb{a}}^{\vb{b}} \grad{t} \cdot d\vb{r}\) is independent of the path from \(\vb{a}\) to \(\vb{b}\) but only depends on the beginning and end points. Hence, \(\oint_{C} \grad{t} \cdot d\vb{r} = 0\) for any closed loop, since \(t(\vb{b}) - t(\vb{a}) = 0\).
	
\example{Gradient of \(\rcurs ^{-1} \) in Cartesian Coordinates.}
{Evaluate \(\grad({\rcurs ^{-1} })\), where \(\rcurs = \abs{\brcurs} = \abs{\vb{r} - \vb{r'}} = \abs{(x - x')\vu{x} + (y - y')\vu{y} + (z - z')\vu{z}} = \sqrt{(x-x')^2+(y-y')^2+(z-z')^2}\). Generalize the result to obtain \(\grad{(\rcurs^n)}\).}
{\begin{equation} 
	\begin{aligned} 
		\grad{\rcurs ^{-1} } &= \vu{x}\pdv{x}((x - x')^2 + (y - y')^2 + (z - z')^2)^{-\frac{1}{2}} \\ &+ \vu{y}\pdv{y}((x - x')^2 + (y - y')^2 + (z - z')^2)^{-\frac{1}{2}} \\ &+ \vu{z}\pdv{z}((x - x')^2 + (y - y')^2 + (z - z')^2)^{-\frac{1}{2}} \\ &= (-\frac{1}{2})(2)(((x - x')^2 + (y - y')^2 + (z - z')^2))^{-\frac{3}{2}} \\ &((x - x')\vu{x} + (y - y')\vu{y} + (z - z')\vu{z}) \\ &=- \brcurs \rcurs ^{-1} . 
	\end{aligned} 
\end{equation}
		
This result can be easily generalised to get
		
\begin{equation} 
	\grad{(\rcurs^n)} = n\rcurs^{n-1}\hrcurs. \label{gradrcurs} 
\end{equation}}

The gradient in Cartesian and spherical coordinates are stated here for reference:

\begin{equation} 
	\grad{t} = \frac{\partial t}{\partial x} \vu{x} + \frac{\partial t}{\partial y} \vu{y} + \frac{\partial t}{\partial z} \vu{z} = \pdv{t}{r}\vu{r} + \frac{1}{r}\pdv{t}{\theta}\vu{\boldsymbol{\theta } } + \frac{1}{r\sin{\theta}}\pdv{t}{\phi}\vu{\boldsymbol{\phi } }. 
\end{equation}
	
\subsection{Divergence}

	
In order to seek geometrical interpretation of the divergence operator, we consider the closed surface integral of \(\vb{T}\) over the surface of an infinitesimal volume depicted in \cref{infvol} (here we adopt the sign convention of \(\vb{A}\) is positive if \(\vb{A}\) is pointing outwards from the interior of the volume)

\begin{equation} \label{divpre} 
	\begin{aligned} 
    \oint_{S} \vb{T} \cdot d\vb{A} &= ((T_u)|_{u+du} - (T_u)|_{u})(ghdvdw) \\ &+ ((T_v)|_{v+dv} - (T_v)|_{v})(fhdudw) \\ &+ ((T_w)|_{w+dw} - (T_w)|_{w})(fgdudv) \\
    &= \frac{1}{fgh} \left( 
		\frac{\partial}{\partial u} (ghT_{u} ) + 
		\frac{\partial}{\partial v} (fhT_{v} )+ 
		\frac{\partial}{\partial w} (fgT_{h} ) \right) d\tau \\
	&= (\div{\vb{T}}) d\tau
    \end{aligned} 
\end{equation} 
	
This result can be extended easily. As any arbitary volume can be divided infinitely into infinitesimal pieces, and the surface integral of each individual pieces cancel in pairs, the remaining part is only the surface integral of the surface of the whole volume. Therefore,
	
\begin{equation} 
	\oint_{S} \vb{T} \cdot d\vb{A} = \int_{V}(\div{\vb{T} }) d\tau \label{divthm}. 
\end{equation}
	
This is the divergence theorem (also known as the Gauss's theorem or the Green's theorem). From the LHS of \cref{divthm}, it is evident that the divergence of a vector function is a measure of how much the function spreds out and diverges from a given point in space.

If \(\vb{T} \) satisfies \(\div{\vb{T} } = 0 \), then \(\vb{T} = \curl{\vb{T} ' + \grad{t} + \vb{C} } \) can be written as a curl of a vector \(\vb{T} '\), which statisfies \(\curl{\vb{T} '} = 0 \) plus a gradient of a scalar function \(t\) plus a constant vector \(\vb{C} \).        

The divergence in Cartesian and spherical coordinates are stated here for reference:
\begin{equation} 
	\div{\vb{T}} = \pdv{T_x}{x} + \pdv{T_y}{y} + \pdv{T_z}{z} = \frac{1}{r^2}\pdv{r}(r^2T_r) + \frac{1}{r\sin{\theta}}\pdv{\theta}(\sin{\theta}T_{\theta}) + \frac{1}{r}\pdv{\phi}(rT_{\phi}). 
\end{equation}
	
\subsection{Curl}


In order to seek geometrical interpretation of the curl operator, we consider the loop integral of \(\vb{T}\) over an infinitesimal loop depicted in \cref{infloop} (here since the coordinates system is right handed, \(\vu{w}\) points out of the page, hence we are obliged by the right-hand rule to run the line integral counterclockwise such that \(\vb{A}\) points in the same direction as \(\vu{w}\))
	
\begin{equation} 
	\begin{aligned} 
		\oint_{C} \vb{T} \cdot d\vb{r} &= (T_u)|_{v}fdu + (T_v)|_{u+du}gdv + (T_u)|_{v+dv}(-fdu) + (T_v)|_{u}(-gdv) \\ &= \frac{1}{fg}\left(\frac{\partial }{\partial u} (T_{v} g) - \frac{\partial }{\partial v} (T_{u}f)\right)(\vu{w} \cdot d\vb{A}) \\ &= (\curl{\vb{T} } ) \cdot d\vb{A} . 
	\end{aligned} 
\end{equation}

With the same argument as \cref{divpre}  to \cref{divthm}, the above equation can be extended to
	
\begin{equation} 
	\oint_{C} \vb{T} \cdot d\vb{r} = \int_{S} (\curl{\vb{T}}) \cdot d\vb{A}. \label{stothm} 
\end{equation}
	
This is the Stoke's theorem. From the LHS of \cref{stothm}, it is evident that the curl of a vector function is a measure of how much the function rotates and curls around a given point in space.
	
A quick corollary is that the integral \(\int_{S} (\curl{\vb{T}}) \cdot d\vb{A}\) is independent of the surface used but only depends on the boundary line. Hence, \(\oint_{S} (\curl{\vb{T}}) \cdot d\vb{A} = 0\) for any closed surface, since the boundary line, like the mouth of a ballon, shrinks down to a point, and thus \(\oint_{P} \vb{T} \cdot d\vb{r} = 0\).

\(\vb{T} \) is called conservative if \(\int_{A}^{B}  \vb{T} \cdot d\vb{r}  \) is independent of the path taken from \(A\) to \(B\). This implies that \(\oint_{C} \vb{T} \cdot d\vb{r} = 0\) and thus \(\curl{\vb{T} } = 0\) and \(\vb{T} = \grad{t} \) can be written as a gradient of some scalar function \(t\). Also, \(\vb{T} \cdot d\vb{r} \) is an exact differential.      

The curl in Cartesian and spherical coordinates are stated here for reference:
\begin{equation} 
	\begin{aligned}
	\curl{\vb{T}} &= (\pdv{T_z}{y} - \pdv{T_y}{z})\vu{x} + (\pdv{T_x}{z} - \pdv{T_z}{x})\vu{y} + (\pdv{T_y}{x} - \pdv{T_x}{y})\vu{z} \\ &= \frac{1}{r\sin{\theta}}\left(\pdv{\theta}(\sin{\theta}T_{\phi}) - \pdv{T_{\theta}}{\phi}\right)\vu{r} + \frac{1}{r}\left(\frac{1}{\sin{\theta}}\pdv{T_r}{\phi} - \pdv{r}(rT_{\phi})\right)\vu{\boldsymbol{\theta } } + \frac{1}{r}\left(\pdv{r}(rT_{\theta}) - \pdv{T_r}{\theta}\right)\vu{\boldsymbol{\phi } }. 
    \end{aligned}
\end{equation}
	
\subsection{Product Rules}
The two product rules for gradient are

\begin{equation}
\begin{cases} 
	\grad{(fg)} = f\grad{g} + g\grad{f},  \\
	\grad{(\vb{A} \cdot \vb{B})} = \vb{A} \cross (\grad \cross \vb{B}) + \vb{B} \cross (\grad \cross \vb{A}) + (\vb{A} \cdot \grad)\vb{B} + (\vb{B} \cdot \grad)\vb{A}. 
\end{cases}
\end{equation}
	
The two product rules for divergence are 

\begin{equation}
\begin{cases} 
	\div{(f\vb{A})} = f(\div{\vb{A}}) + \vb{A} \cdot (\grad{f}), \\
	\div (\vb{A} \cross \vb{B}) = \vb{B} \cdot (\curl {\vb{A}}) = \vb{A} \cdot (\curl{\vb{B}}). 
\end{cases}
\end{equation}

	
The two product rules for curl are
	
\begin{equation}
\begin{cases} 
	\curl{(f\vb{A})} = f(\curl{\vb{A}}) - \vb{A} \cross (\grad{f}), \\
	\curl (\vb{A} \cross \vb{B}) = (\vb{B} \cdot \grad)\vb{A} - (\vb{A} \cdot \grad)\vb{B} + \vb{A}(\div{\vb{A}}) - \vb{B}(\div{\vb{A}}). 
\end{cases}
\end{equation}

	
Here note that

\begin{equation} 
	\begin{aligned} 
		(\vb{A} \cdot \grad) \vb{B} &= (A_x\pdv{x} + A_y\pdv{y} + A_z\pdv{z})(B_x\vu{x} + B_y\vu{y} + B_z\vu{z}) \\ &= (A_x\pdv{B_x}{x} + A_y\pdv{B_x}{y} + A_z\pdv{B_x}{z})\vu{x} \\ &+ (A_x\pdv{B_y}{x} + A_y\pdv{B_y}{y} + A_z\pdv{B_y}{z})\vu{y} \\ &+ (A_x\pdv{B_z}{x} + A_y\pdv{B_z}{y} + A_z\pdv{B_z}{z})\vu{z} \\ &\neq \vb{A} \cdot (\grad{\vb{B}}) \\ &= A_x\pdv{B}{x} + A_y\pdv{B}{y} + A_z\pdv{B}{z} 
	\end{aligned} 
\end{equation}
	
With the product rules in hand, we can perform the so-called ``Integration by part'' trick. For example, by integrating the first product rule of divergence and using divergence theorem, we have
	
\begin{equation} 
	\begin{aligned}
	\int_{V} \div{(f\vb{T})} d\tau &= \int_{V} f(\div{\vb{T}}) d\tau + \int_{V} \vb{T} \cdot (\grad{f}) d\tau = \oint_{S} f\vb{T} \cdot d\vb{A} \\
	\implies \int_{V} f(\div{\vb{T}}) d\tau &= \oint_{S} (f\vb{T}) \cdot d\vb{A} - \int_{V} \vb{T} \cdot (\grad{f}) d\tau. 
	\end{aligned}
\end{equation}
	
Here we transform the integrand from the product of one function (\(f\)) and one derivative \(\div{\vb{T}}\) to another integrand of the product of one function that is orginally the derivative \((\vb{T})\) and one derivative which is orginally the function \((\grad{f})\), at a cost of a minus sign and a boundary term \((\oint_{S} (f\vb{T}) \cdot d\vb{A})\), just like integration by part in ordinary derivatives, where
	
\begin{equation} 
	\int_{a}^{b} f(\dv{g}{x})dx = -\int_{a}^{b} g(\dv{f}{x})dx + \eval{(fg)}_a^b 
\end{equation}
	
comes from the product rule
	
\begin{equation} 
	\dv{x}(fg) = f(\dv{g}{x}) + g(\dv{f}{x}). 
\end{equation}

Similarly, we can show that 
	
\begin{equation} 
	\int_{S} f(\curl{\vb{T}}) \cdot d\vb{A} = \int_{S} (\vb{T} \cross (\grad{f})) \cdot d\vb{A} + \oint_{C} f\vb{T} \cdot d\vb{r} 
\end{equation}
	
and

\begin{equation} 
	\int_{V} \vb{B} \cdot (\curl{\vb{T}}) d\tau = \int_{V} \vb{T} \cdot (\curl{\vb{B}}) d\tau + \oint_{S} (\vb{T} \cross \vb{B}) \cdot d\vb{A}. 
\end{equation}
	
\subsection{Second Derivatives}
	
From the nature of gradient, divergence and curl, we can construct five species of second derivatives. They are 
\begin{enumerate}
	\item Divergence of gradient \(\div{(\grad{t})}\):
		
	\begin{equation} 
		\div{(\grad{t})} = (\vu{x}\pdv{x} + \vu{y}\pdv{y} + \vu{z}\pdv{z}) \cdot (\vu{x}\pdv{t}{x} + \vu{y}\pdv{t}{y} + \vu{z}\pdv{t}{z}) = \pdv[2]{t}{x} + \pdv[2]{t}{y} + \pdv[2]{t}{z}, \label{prelap} 
	\end{equation}
		
	In fact, the divergence of gradient operator is so frequently used in physics that it gets its own name and symbol known as the Laplacian:
		
	\begin{equation}
		\laplacian{t} = \div{(\grad{t})}. \label{lap} 
	\end{equation}
		
	With reference to \cref{lap}, the Laplacian of a scalar function in spherical coordinates is listed here for reference:
	
	\begin{equation} 
		\laplacian{t} = \frac{1}{r^2}\pdv{r}(r^2\pdv{t}{r}) + \frac{1}{r^2\sin{\theta}}\pdv{\theta}(\sin{\theta}\pdv{t}{\theta}) + \frac{1}{r^2\sin{\phi}}\pdv[2]{t}{\phi}. 
	\end{equation}

	In some case, we can simplify the expression by rewriting the fisrt term on the RHS as 

	\begin{equation}
		\frac{1}{r^2} \frac{\partial }{\partial r} \left( r^2 \frac{\partial t}{\partial r}  \right) = \frac{1}{r} \frac{\partial^2 }{\partial r^2} (rt).   
	\end{equation}
	
	
		
	\item Curl of gradient:
		
	\begin{equation} 
		\curl{(\grad{t})} = 
		\begin{vmatrix}
			\vu{x}  & \vu{y}  & \vu{z}   \\
			\frac{\partial }{\partial x}  & \frac{\partial }{\partial y}  & \frac{\partial }{\partial z}   \\
			\frac{\partial t}{\partial x} & \frac{\partial t}{\partial y}  & \frac{\partial t}{\partial z}   \\
		\end{vmatrix} = (\pdv{t}{z}{y} - \pdv{t}{y}{z})\vu{x} + (\pdv{t}{x}{z} - \pdv{t}{z}{x})\vu{y} + (\pdv{t}{y}{x} - \pdv{t}{x}{y})\vu{z} = 0. \label{curlgrad} 
	\end{equation}
		
	\item Gradient of divergence (not identical to the divergence of gradient):
		
	\begin{equation} 
		\grad{(\div{\vb{T}})} \neq (\div{\grad{} } )\vb{T}. 
	\end{equation}
		
	\item Divergence of curl:
		
	\begin{equation} 
		\div{(\curl{\vb{T}})} = \pdv{x}(\pdv{T_z}{y} - \pdv{T_y}{z}) + \pdv{z}(\pdv{T_x}{z} - \pdv{T_z}{x}) + \pdv{z}(\pdv{T_y}{x} - \pdv{T_x}{y}) = 0. \label{divcurl} 
	\end{equation}
		
	\item Curl of curl:
		
	\begin{equation} 
		\curl{(\curl{\vb{T}})} = \grad{(\div{\vb{T}})} - \laplacian{\vb{T}}. \label{curlcurl} 
	\end{equation} 
		
	Here, \(\laplacian{\vb{T}}\) is the Laplacian of a vector function defined as\footnote{In fact, \cref{curlcurl} is often used to define the Laplacian of a vector, since \cref{lap} makes explicit reference to Cartesian coordinates.}
		
	\begin{equation} 
		\laplacian{\vb{T}} = (\laplacian{T_x})\vu{x} + (\laplacian{T_y})\vu{y} + (\laplacian{T_z})\vu{z}. 
	\end{equation}	
\end{enumerate}	
	
For the 5 second derivatives listed above, only \cref{prelap,curlcurl} are used regularly in physics enough that they are worth remembering.
	
\subsection{Dirac Delta Function}
	
The motivation of the dirac delta function comes from the result of the divergence of the vector function \(\vb{T} = \frac{\vu{r}}{r^2}\):
	
\begin{equation} 
	\div{\left(\frac{\vu{r}}{r^2}\right)} = \frac{1}{r^2} \pdv{r}(r^2\left(\frac{1}{r^2}\right)) = 0, \label{notmatchone} 
\end{equation}
	
which is not consistent with the result we would expect from the divergence theorem, since the suface integral over a hypothetical sphere with raidus \(R\) is 	

\begin{equation}
	\oint_{S} \left( \frac{\vu{r} }{R^2} \right) \cdot  (R^2\sin \theta d \theta d \phi \vu{r} )  = 4\pi .
\end{equation}


	
The root of this problem lies on the fact that the function itself blows up at the origin, so while it is true that the divergence of this function equals to 0 at every point, it does not apply to the origin. The \(4\pi\) contribution in \cref{notmatchtwo} comes entirely from the orgin.
	
To describe this behaviour, we introduce the dirac delta function which is defined by
	
\begin{equation} 
	\delta(x) = \begin{cases} \infty &\text{if} ~~~ x=0 \\ ~0 &\text{if} ~~~ x\neq0 \end{cases} \text{ and }	\int_{-\infty}^{+\infty} \delta(x) dx = 1. \label{dd2} \footnote{Therefore, \(\delta(x)\) has the dimension of the inverse of its argument} 
\end{equation}	
	
The appearance of this function is shown in \cref{dd}.\onefig{dd}{scale = 0.7}
	
Let \(f(x)\) to be an ordinary (continuous) function, then it follows that

\begin{equation} 
	f(x)\delta(x) = f(0)\delta(x), \label{ddimport} 
\end{equation}
	
since \(f(x) \delta(x) \neq 0\) only if \(x = 0\).
	
Integrating the above equation,

\begin{equation} 
	\int_{-\infty}^{+\infty} f(x) \delta(x) dx = \int_{-\infty}^{+\infty} f(0) \delta(x) dx = f(0) \int_{-\infty}^{+\infty} \delta(x) dx = f(0). \label{pickout} 
\end{equation} 
	
Using the integral, the dirac delta function picks out the value of \(f(x)\) at the origin.
	
By changing the variable in \cref{pickout}, we can pick out the value of \(f(x)\) at any arbitary point \(x = a\)
	
\begin{equation} 
	\int_{-\infty}^{+\infty} f(x) \delta(x-a) dx = f(a) 
\end{equation}
	
\example
{Dirac Delta Function (1)}
{Show that \(\delta(kx) = \frac{1}{\abs{k}}\delta(x)\).}
{Consider the integral
			
\begin{equation} 
	\int_{-\infty}^{+\infty} f(x) \delta(kx) dx, 
\end{equation}

Making the substitution \(u=kx\), we have
			
\begin{equation} 
	\int_{-\infty}^{+\infty} f(x) \delta(kx) dx = \pm \frac{1}{k} \int_{-\infty}^{+\infty} f\left(\frac{u}{\abs{k}}\right) \delta(u) du = \frac{1}{\abs{k}} f(0) = \int_{-\infty}^{+\infty} f(x) \frac{\delta(x)}{\abs{k}} dx.
\end{equation}
			
By comparing the integrands, we yield the desired result.}	
		
\example{Dirac Delta Function (2)}{Show that \(-\delta(x) = x\dv{x}(\delta(x))\)}

\example{Dirac Delta Function (3)}{Show that \(\delta(x) = \dv{\theta}{x}\), where \(\theta(x)\) is the Heaviside step function defined as \(\theta(x) = \begin{cases} 0 ~~~ \text{if} ~~ x~\le~0, \\  1 ~~~ \text{if} ~~ x~>~0. \end{cases}\)}
	
It is natural to generalize \(\delta(x)\) to three dimensions as follows:
	
\begin{equation} 
	\delta(\vb{r}) = \delta(x)\delta(y)\delta(z) 
\end{equation}
	
The characteristic equations the three-dimensional delta function are then 
	

\begin{equation} 
	\int_{all~space} \delta^3(\vb{r})
	d\tau = \int_{-\infty}^{+\infty}\int_{-\infty}^{+\infty}\int_{-\infty}^{+\infty} \delta(x)\delta(y)\delta(z) ~dxdydz = 1 
\end{equation}
	
and
	
\begin{equation} 
	\int_{all~space} f(\vb{r}) \delta^3(\vb{r} - \vb{a}) = f(\vb{a}). 
\end{equation} 
	
As in the one-dimensional case, the \(\delta^3(\vb{r} - \vb{a})\) picks out the value of \(f(\vb{r})\) at \(\vb{a}\).
	
The inconsistency in \cref{notmatchone,notmatchtwo} can now be resolved as the divergence of the vector function \(\vb{T} = \frac{\vu{r}}{r^2}\) is in fact
	
\begin{equation} 
	\div{\frac{\vu{r}}{r^2}} = 4\pi\delta^3(\vb{r}). 
\end{equation}
	 
which equals to 0 except in the origin where it equals to \(4\pi\).
	
In general,
	
\begin{equation} 
	\div{\left(\frac{\hrcurs}{\rcurs^2}\right)} = 4\pi\delta^3(\brcurs). \label{divdelta} 
\end{equation} 
 	
Here, the derivative is evaluated with respect to \(\vb{r}\) and \(\vb{r'}\) is fixed.
 	
From \cref{gradrcurs}, we have also
 	
\begin{equation} 
	\laplacian{\left(\frac{1}{\rcurs}\right)} = -4\pi\delta^3(\brcurs). \label{laprj} 
\end{equation}
	
%\example{Griffith (5th ed.) Problem 1.47}
%{Find the charge density \(\rho(\vb{r})\) for
%\begin{enumerate}
%	\item a point charge  \(q\) located at \(\vb{r'}\),\\
%	\item an electric dipole consisting of a point charge \(-q\) at the origin and \(+q\) at \(\vb{a}\) and\\
%	\item an infinitesimal sphere of charge \(q\) and radius \(a\) centered at the origin
%\end{enumerate}}
%{\begin{enumerate}
%	\item \(\rho(\vb{r}) = q\delta(\vb{r} - \vb{r'}) \)\\

%	\item \(\rho(\vb{r}) = -q\delta(\vb{r}) + q\delta(\vb{r} - \vb{a})\)\\	

%	\item \(\rho(r) = A\delta(r - a)\), where \(A\) can be determined by \(\int_{V} \rho(r) d\tau = \int A\delta(r-a) 4\pi r^2 dr = 4\pi Aa = q\), thus \(A = \frac{q}{4\pi a}\). Therefore, \(\rho(r) = \frac{q}{4\pi a}\delta(r - a)\).
%\end{enumerate}}

	
\subsection{Helmholtz Theorem}
	
The existence theorem of the Poisson's equation states there always exists an unique solution to the differential equation

\begin{equation}
	\laplacian \Phi = -\frac{\rho }{\epsilon_0}  .
\end{equation}

The proof of this theorem is mathematically advanced but somewhat trivial because it simply implies that we can assign each point in space an electric potential for any arbitrary charge distribution.
	
With this theorem in hand, we can prove an useful theorem in vector calculus which states that any differentiable vector function \(\vb{T} \) can be written as a gradient plus a curl.
	
To prove this, we invoke the existence theorem of the Poisson's equation and states that there exists an unique solution to the scalar function \(h\) which satisfies the differential equation 

\begin{equation}
	\laplacian h = t
\end{equation}

where \(t = \div{\vb{T} } \) is the divergence of \(\vb{T} \).

So we have 

\begin{equation}
	\begin{aligned}
		\div{(\grad{h} )} &= \div{\vb{T} }  \\
		\div{(\vb{T} - \grad{h} )} &= 0.
	\end{aligned}
\end{equation}
	
But we know that \cref{divcurl}, we know that any divergenceless function can be written as the curl of a function. Thus, \(\vb{T} \) can be written as 

\begin{equation}
	\vb{T} = \grad{h} + \div{\vb{H} } 
\end{equation}

where \(\vb{H} \) is some vector function.

The Helmholtz Theorem states that if a differentiable vector function \(\vb{T} \rightarrow 0 \text{ as } r \rightarrow \infty \text{ faster than } \frac{1}{r} \), then \(\vb{T} \) can be decomposed to

\begin{equation}
	\vb{T} = -\grad{\Phi } + \curl{\vb{A} } \label{decom} 
\end{equation}
	
where \(\Phi \text{ and }  \vb{A} \) satisfy

\begin{equation}
	\Phi(\vb{r} ) = \frac{1}{4\pi } \int_{all \text{ } space} \frac{\boldsymbol{\nabla}' \cdot \vb{T} (\vb{r} ')}{\rcurs } d\tau '
\end{equation}

and 

\begin{equation}
	\vb{A} (\vb{r} ) = \frac{1}{4\pi } \int_{all \text{ } space} \frac{\boldsymbol{\nabla}' \cross \vb{T} (\vb{r} ')}{\rcurs } d\tau '
\end{equation}

To ensure that \(\Phi \text{ and }  \vb{A} \) don't diverge, both  \(\boldsymbol{\nabla}' \cdot \vb{T} (\vb{r} ') \text{ and } \boldsymbol{\nabla}' \cross \vb{T} (\vb{r} ')\) have to goes zero faster than \(\frac{1}{r} \) as \(r \rightarrow \infty\) which is guaranteed by the requirement of \(\vb{T} \) above in which \(\vb{T} \rightarrow 0 \) faster than \(\frac{1}{r} \) as \(r \rightarrow  \infty\).

Testing the divergence of \cref{decom}, we have \footnote{Here and after, we will omit the limit of the integrals.}

\begin{equation}
	\begin{aligned}
		\div{\vb{T} } &= -\div{(\grad{\Phi} )} + \div{(\curl{\vb{A} } )} = -\laplacian \Phi \\ 
		&= -\frac{1}{4\pi } \int \boldsymbol{\nabla}' \cdot \vb{T} (\vb{r} ') \laplacian (\frac{1}{\rcurs } ) d\tau ' \\ 
		&= \int \boldsymbol{\nabla}' \cdot \vb{T} (\vb{r} ') \delta ^3(\vb{r} -\vb{r} ')d\tau ' = \boldsymbol{\nabla}' \cdot \vb{T} (\vb{r} '). \label{divT}  
	\end{aligned}
\end{equation}

where \(\boldsymbol{\nabla}' \cdot \vb{T} (\vb{r} ')\) is taken out of the Laplacian since it depends on \(\vb{r} '\) instead of \(\vb{r} \). Also we have used the fact that \(\laplacian (\frac{1}{\rcurs }) = -4\pi \delta ^3(\brcurs )\) (\cref{laprj}).

Testing the curl,

\begin{equation}
	 \curl{\vb{T}} = -\curl{\grad{\Phi}} + \curl{(\curl{\vb{A}})} = -\laplacian{\vb{A}} + \grad{(\div{\vb{A}})}. \label{int1} 
\end{equation}

where we have used the identity in \cref{curlcurl}.

Now, the first term is 

\begin{equation}
	-\laplacian \vb{A} = -\frac{1}{4\pi } \int \boldsymbol{\nabla}' \cross \vb{T} (\vb{r} ') \laplacian (\frac{1}{\rcurs } ) d\tau '= \boldsymbol{\nabla}' \cross \vb{T} (\vb{r} )
\end{equation}
	
in a similar fashion as \cref{divT}.

To prove that the second term equals to zero, we consider

\begin{equation}
	\begin{aligned}
		4\pi (\div{\vb{A} } ) &= \int \div{\frac{\boldsymbol{\nabla}' \cross \vb{T} (\vb{r} ')}{\rcurs }} d\tau ' = \int (\boldsymbol{\nabla}' \cross \vb{T} (\vb{r} ')) \cdot \grad{(\frac{1}{\rcurs } )} d\tau ' \\
	 	&= -\int (\boldsymbol{\nabla}' \cross \vb{T} (\vb{r} ')) \cdot \boldsymbol{\nabla}'(\frac{1}{\rcurs } ) d\tau ' = \int \frac{1}{\rcurs }\boldsymbol{\nabla}' \cdot (\boldsymbol{\nabla}' \cross \vb{T} (\vb{r} ')) d\tau  - \oint \frac{1}{\rcurs } (\boldsymbol{\nabla}' \cross \vb{T} (\vb{r} ')) \cdot d\vb{A}  \label{com} 
	\end{aligned}
\end{equation}

where we used \cref{int2} and \(\grad{(\frac{1}{\rcurs } )} = - \boldsymbol{\nabla}'(\frac{1}{\rcurs } ) \) since the derivative of \(\rcurs = \left| \vb{r} - \vb{r} ' \right| \) with respect to the primed coordinates differ by a sign from those with respect to unprimed coordinates.

Now, the first term in \cref{com} is zero since

\begin{equation}
	\boldsymbol{\nabla}' \cdot (\boldsymbol{\nabla}' \cross \vb{T} (\vb{r} ')) = - \div{(\curl{\vb{T} (\vb{r} ')})} = 0.
\end{equation}
	
and the second term is also zero as long as \(\boldsymbol{\nabla}' \cross \vb{T} (\vb{r} ') \) goes to zero faster than \(\frac{1}{r^2} \) 

	The uniqueness of the solution doesn't necessary hold, however, since we can add to \(\vb{T} \) a vector function whose divergence and curl both vanish. However, it so happens that there is no function that satisfies both of the requirement and goes to zero at infinity. Therefore, the solution is unique. \todo{proof in 3.1.5}

	So, combining the results above, \(\vb{T} \) can be written as

\begin{equation}
	\vb{T} (\vb{r} ) = \grad{\frac{1}{4\pi } \int \frac{\boldsymbol{\nabla}' \cdot \vb{T} (\vb{r} ')}{\rcurs }d\tau ' } + \div{\frac{1}{4\pi } \int \frac{\boldsymbol{\nabla}' \cross \vb{T} (\vb{r} ')}{\rcurs } d\tau '} .	
\end{equation}
	
For example, in electrostatics, since \(\div{\vb{E} } = \frac{\rho }{\epsilon_0}  \text{ and } \curl{\vb{E} } = 0\), so
	
\begin{equation}
	\vb{E} (\vb{r} ) = -\grad{(\frac{1}{4\pi\epsilon_0} \int \frac{\rho (\vb{r} ')}{\rcurs } d\tau ')} = -\grad{V} 
\end{equation}
	
where \(V\) is defined as the electric potential.

While in magnetostatics, since \(\div{\vb{B} } = 0 \text{ and } \curl{\vb{B} } = \mu_0 \vb{J} \), so

\begin{equation}
	\vb{B} (\vb{r} ) = \curl{(\frac{\mu_0}{4\pi } \int \frac{\vb{J} (\vb{r} ')}{\rcurs } d\tau ')} = \curl{\vb{A} } 
\end{equation}

where \(\vb{A} \) is defined as the magnetic potential.\footnote{In electrodynamics, the boundary condition of requiring the electric field and magnetic field to vanish at infinity is well justified. However, if the charge or current distribution extend to infinity in some artificial problems as well, then we have to rely on symmetric argument to provide sufficient boundary conditions and other means to prove the existence and uniqueness of the Maxwell equations.}






\chapter{Integration}

Different from ordinary integrations, when there are more than one variable, we have to perform integrations over a line, a surface or a volume.

To evaluate integrals involving vectors, we must reduce them into scalar integrals, \ie Cartesian form, since it is the only coordiante system where the unit vectors are fixed (and so can be brought out of the integral sign).

\section{Line Integrals}
\subsection{Evaluation}

Integrals along a line can invovle vector and scalar fields. There are three kinds of line integrals, namely

\begin{equation}
	\int_{C}^{} \phi d\vb{r} , ~~ \int_{C}^{} \vb{a} \cdot d\vb{r} ~ \text { and }  \int_{C}^{} \vb{a} \cross d\vb{r} . 
\end{equation}

The curve \(C\) can be open, \ie the beginning and end point are not the same; or closed, where \(C\) is a closed loop and we will add a circle to the integral sign as \(\oint_{C} \). For a closed curve the direction of integration is conventionally taken to be anticlockwise.

\example{Line Integral (1)}
{Evaluate the line integral \(I = \int_{C}^{} \vb{a} \cdot d\vb{r}  \) from \((1,1)\) to \((4,2)\), where \(\vb{a}  = (x+y)\vu{x} + (y-x)\vu{y} \), along 
\begin{enumerate}
	\item the parabola \(y^2 = x\),
	\item the curve \(x = 2u^2+u+1, y= 1+u^2\), and
	\item the line \(y=1\) from \((1,1)\) to \((4,1)\), followed by the line \(x = 4\) from \((4,1)\) to \((4,2)\).      
\end{enumerate}
~
}
{Evaluating the dot product explicitly, we have 

\begin{equation}
	 I = \int_{(1,1)}^{(4,2)} ((x+y)dx + (y-x)dy).
\end{equation}

\begin{enumerate}
	\item Along the parabola \(y^2 = x\), we have \(2ydy = dx\), so 
	
	\begin{equation}
		I = \int_{1}^{2} ((y^2+y)2y + (y - y^2))dy = \frac{34}{3}.    
	\end{equation}
	
	\item We have \(dx = (4u+1)du \text { and } dy = 2udu\), so
	
	\begin{equation}
		I = \int_{0}^{1} ((3u^2+u+2)(4u+1)-(u^2+u)(2u))du = \frac{32}{3}  
	\end{equation}
	
	\item We split the integral into two parts, then 
	
	\begin{equation}
	\begin{aligned} 
		I &= \int_{(1,1)}^{(4,1)} ((x+y)dx + (y-x)dy) + \int_{(4,1)}^{(4,2)} ((x+y)dx + (y-x)dy) \\ &= \int_{1}^{4} (x+1)dx + \int_{1}^{2} (y-4)dy = 8.      
	\end{aligned} 
    \end{equation}
\end{enumerate}
~
} 


\example{Line Integrals (2)}
{Evaluate the line integral \(I = \oint_{C} x dy\), where \(C\) is the circle in the \(xy\)-plane defined by \(x^2 + y^2 = a^2, z=0\). }
{Since \(x\) is not a single-valued function of \(y\), we must divide the path into two parts with \(x = +\sqrt{a^2-y^2} \) for \(x\geq 0\) and \(x = -\sqrt{a^2-y^2} \) for \(x \le 0\). So

\begin{equation}
	I = \int_{-a}^{a} \sqrt{a^2-y^2}dy + \int_{a}^{-a} (-\sqrt{a^2-y^2}dy= \pi a^2 )   .
\end{equation}

Alternatively, we can represent the entire circle parametrically, by \(x = a \cos \phi , y = a \sin \phi \) with \(\phi \) running from \(0\) to \(2 \pi \) and we have 

\begin{equation}
	I = a^2 \int_{0}^{2\pi } \cos ^2 \phi d\phi  = \pi a^2.
\end{equation}
} 

\example{Line Integral (3)}
{Evaluate the line integral \(I = \int_{C}^{} (x-y)^2 ds \), where \(C\) is the semicircle of radius \(a\) running from \(A = (a,0)\) to \(B = (-a,0)\) and for which \(y \ge 0\).}
{Introducing a parametric variable \(\phi \) running from \(0\) to \(2\pi \), we have 

\begin{equation}
	\vb{r} (\phi ) = a \cos \phi \vu{x} + a \sin \phi \vu{y} \text { and } ds = \sqrt{\frac{d \vb{r} }{d\phi }\cdot \frac{d \vb{r} }{d\phi } = a d\phi}. 
\end{equation}

Thus

\begin{equation}
	I = \int_{0}^{\pi } a^3 (1-\sin 2\phi ) d\phi = \pi a^3 . 
\end{equation}
} 

\subsection{Green's Theorem}

Green's theorem states that 

\begin{equation}
	\oint_{C} (Pdx + Qdy) = \int \int_{R}^{} \left( \frac{\partial Q}{\partial x} - \frac{\partial P}{\partial y}  \right) dxdy.  
\end{equation}

To prove this theoerem we refer to \cref{doubleintegral}. Let \(y = y_1 (x) \text { and } y = y_2 (x)\) be the equations of the curves \(STU\) and \(SVU\) respectively. We then find

\begin{equation}
	\begin{aligned} 
	\int \int_{R}^{} \frac{\partial P}{\partial y} dxdy &= \int_{a}^{b} dx \int_{y_1 (x)}^{y_2 (x)} \frac{\partial P}{\partial y} dy = \int_{a}^{b} \eval{P(x,y)}_{y=y_1 (x)}^{y=y_2 (x)} dx \\
	&= \int_{a}^{b} \left[ P(x,y_2 (x)) - P(x,y_1 (x)) \right] dx \\ 
	&= -\int_{a}^{b} P(x,y_1 (x)) dx - \int_{b}^{a} P(x,y_2 (x)) dx = -\oint_{C} Pdx.      
	\end{aligned}      
\end{equation}

If we now let \(x= x_1 (y) \text { and } x = x_2 (y)\) as the equations of the curves \(TSV \text { and } TUV\) respectively, then we can similarly show that 

\begin{equation}
	\int \int_{R}^{} \frac{\partial Q}{\partial x} dx dy = \oint_{C} Q dy.   
\end{equation}

Subtracting the two equations gives Green's theorem.

\example{Area of an Ellipse}
{Show that the area of a region \(R\) enclosed by a simle closed curve \(C\) is given by \(A = \frac{1}{2} \oint_{C}(xdy - ydx) = \oint_{C}xdy = - \oint_{C}y dx\). Hence calculate the area of the ellipse \(x = a \cos \phi , y = b\sin \phi \). }
{By Green's theorem we have 

\begin{equation}
	\oint_{C} (xdy- ydx) = \int \int_{R}^{} (1+1) dxdy = 2A.  
\end{equation}

Therefore the area of an ellipse is 

\begin{equation}
	A = \frac{1}{2} \int_{0}^{2\pi } ab(\cos ^2\phi + \sin ^2\phi ) d\phi  = \pi ab.   
\end{equation}
} 

The Green's theorem is also valid for region with holes, however, the line integral must be carry out in the direction that a person ttravelling along the boundaries always has the region \(R\) on their left.

We also see that if the line integral around a closed loop is zero, Green's theorem implies that \(\frac{\partial P}{\partial y} = \frac{\partial Q}{\partial x} \), which is equivalent to saying that \(P(x,y) dx + Q(x,y) dy \) is an exact differential such that it equals to the differential for some function \(\phi (x,y)\) and for a closed loop the beginning and the end points are the same thus we evaluate \(\phi \) at the same point and thus the result is zero.




\section{Surface Integrals}

As with line integrals, integrals over a surface can involve vector and scalar fields. There are four kinds of surface integrals, namely 

\begin{equation}
    \int_{S}^{} \phi dS, ~~ \int_{S}^{} \phi d\vb{S} , ~~ \int_{S}^{} \vb{a} \cdot d\vb{S} ~ \text { and } \int_{S}^{} \vb{a} \cross d\vb{S},    
\end{equation}

where \(d\vb{S} = \vu{n} dS\) is the infinitesimal vector area element. The direction of \(\vu{n} \) is conventionally assumed to be directed outwards from the nclosed volume if the surface is closed; or given by the right-hand rule if the surface is open and spans some perimeter curve \(C\). 

We start with the first and simplest surface integral involving only scalars \(\int_{S}^{} \phi dS\). In Cartesian coordinates, 

\begin{equation}
    I = \int_{S}^{} f(x,y) dS = \iint_{S}^{} f(x,y) dx dy  
\end{equation}

where one or two integral signs are used depending on whether \(dS = dx dy \) is written explicitly.  

Refering to \cref{doubleintegral}, we can see that the integral can be evaluated two different ways. 

\onefig{doubleintegral}{scale=0.3} 

The first is to sum up all the horizontal strips, then 

\begin{equation}
    I = \int_{c}^{d} \int_{x_1 (y)}^{x_2 (y)} f(x,y) dx dy,   
\end{equation}

where \(x_1 (y) \text { and } x_2 (y)\) are the equations of the curves \(TSV \text { and } TUV\) respectively. 

For a specific range \(y \rightarrow y+dy\) , the inner integral calculates the contribution to \(I\) by the horizontal strip located from \(y\) to \(y+dy\). The outer integral then sums up the contributions of these horizontal strips.

The second way is to sum up all the vertical strips, then

\begin{equation}
    I = \int_{a}^{b} \int_{y_1 (x)}^{y_2 (x)} f(x,y) dy dx,
\end{equation}

where \(y_1 (x) \text { and } y_2 (x)\) are the equations of the curves \(STU \text { and } SVU\) respectively.   

A useful trick invovle Pappus' second theorem, which states that the surface of revolution of a plance curve is given by the length of the curve \(L\) multiplied by the distance moved by its centroid, since the suface area generated is given by \(S = \int 2\pi y ds = 2 \pi \overline{y} L\), where \(\overline{y} = \frac{1}{L} \int y ds \) is the definition of the centroid. 

\section{Volume Integrals}

\example{Volume of a Tetrahedron}
{Find the volume of the tetrahedron bounded by the three coordinate surfaces \(x=0, y=0 \text { and }  z=0\) and the plane \(\frac{x}{a} + \frac{y}{b} + \frac{z}{c} =1\) as shown in \cref{tetrahedron}
\onefig{tetrahedron}{scale=0.3} }
{\(V = \int_{0}^{a} \int_{0}^{b-\frac{bx}{a} } \int_{0}^{c(1-\frac{y}{b} - \frac{x}{a}  )} dxdydz\). The limit of integral over \(z\) can be obtained as integration over \(z\) adds up the boxeds frmo the shaded column in the figure. A quicker way is to simply sum up all the vertical columns as \(V = \int_{0}^{a} \int_{0}^{b-\frac{bx}{a} dy c \left( a-\frac{y}{b} - \frac{x}{a}\right)}\) which skips the step of integration over \(z\) as it is trivial. The result is \(V = \frac{abc}{6} \). } 


A useful trick invovle Pappus' first theorem, which states that the volume of revolution of a plance surface is given by the area of the surface \(A\) multiplied by the distance moved by its centroid, since the suface area generated is given by \(S = \int 2\pi y dA = 2 \pi \overline{y} A\), where \(\overline{y} = \frac{1}{A} \int y dA \) is the definition of the centroid. 

\section{Chnage of Variables}




















\begin{appendices}
\chapter{Rigorous Proofs}
\section{Leibnitz' Theorem} \label{leibnitzapp} 

Here we provide a proof for \cref{leibnitz}.

\begin{proof}
Suppose \cref{lei} is valid for \(n\) equals to some integer \(N\), then

\begin{equation}
    \begin{aligned}
        f^{(N+1)} &= \sum_{r=0}^{N} \binom{n}{r} \frac{d}{dx}(u^{(r)} v^{(N-r)} ) \\
        &= \sum_{r=0}^{N} \binom{N}{r} (u^{(r)} v^{(N-r+1)} + u^{(r+1)}v^{(N-r)}  ) \\
        &= \sum_{s=0}^{N} \binom{N}{s}u^{(s)}v^{(N+1-s)} + \sum_{s=1}^{N+1} \binom{N}{s-1} u^{(s)}v^{(N+1-s)} \\
        &= \binom{N}{0}u^{(0)} v^{(N+1)} + \sum_{s=1}^{N} \binom{N+1}{s}u^{(s)}v^{(N+1-s)} + \binom{N}{N}u^{(N+1)} v^{(0)} \\
        &= \binom{N+1}{0}u^{(0)} v^{(N+1)} + \sum_{s=1}^{N} \binom{N+1}{s}u^{(s)}v^{(N+1-s)} + \binom{N+1}{N+1}u^{(N+1)} v^{(0)} \\
        &= \sum_{s=0}^{N+1} \binom{N+1}{s} u^{(s)}v^{(N+1-s)}.  
    \end{aligned}
\end{equation}

Since \(N=1\) corresponds to prodouct rule, which is trivial, by induction we have proved \cref{lei} holds for all positive integers \(n\). 

\end{proof}


\end{appendices}
\end{document}
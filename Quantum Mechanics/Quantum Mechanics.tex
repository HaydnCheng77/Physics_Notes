\documentclass[a4paper,12pt]{report}
\usepackage{mypackage}


\title{Quantum mechanics}

\author{Haydn Cheng}

\date{}

\begin{document}
\maketitle
\tableofcontents

\chapter{Hilbert Space}

\section{Scalar Product in Hilbert Space}

Hilbert space, denoted \(H\), in quantum mechanics, is an infinitesimal vector space containing all sqaure integrable functions\footnote{Mathematically, a Hilbert space is a complete scalar product space, and the collection of square-integrable functions is only one example of a Hilbert space.}

\begin{equation}
  H \equiv L^2([a,b]) \equiv \left\{ f:[a,b]\to\mathbb{C} \,\bigg|\, \int_{a}^{b} |f(x)|^2 \, dx < \infty \right\}.
\end{equation}

For a finite-dimensional vector space \(V\) over \(\mathbb{C}\), a scalar product can be defined for any pairs of vectors \(\vb{u} \in V \text { and } \vb{w} \in V\) as 

\begin{equation}
  \left \langle {\vb{u} ,\vb{w} } \right \rangle = \vb{u} {}^{\dagger}  \vb{w} ,
\end{equation}

which gives a complex number. 

Alternatively we can introduce the dual space \(V^*\)

\begin{equation}
  V^* = \{ f: V \to \mathbb{C} \mid f \text{ is linear} \},
\end{equation}

which is the set of all linear operators that operate on a vector \(\vb{v} \in  V\) to give a complex number. \(V^*\) is always isomorphic to the vector space \(V\), meaning that there exist a linear, bijective map \(\Phi \) between the two. In fact, \(\Phi \) is the simple action of the hermitian conjugate (also known as the hermitian adjoint or the conjugate transpose), \textit{i.e.,}

\begin{equation}
  \Phi: V \to V^*, \quad \vb{v}  \mapsto \vb{v} ^\dagger.
\end{equation}

This is because the scalar product between \(\vb{u} \in V \text { and } \vb{w} \in V\) can be regarded as the hermitian conjugate of \(\vb{u} \), \textit{i.e.,} \(\vb{u} {}^{\dagger} \),  operating on the vector \(\vb{w} \).\footnote{It seems that the concept of dual space is overcomplicating the simple scalar prouct, but the dual space can only replace scalar product if the vector space \(V\) and its dual \(V^*\) are isomorphic, which is always true in finite-dimensional vector space and the Hilbert sapce, but is not necessary true in other vector spaces. Also, the dual space is a natural extension and is not some artificial tools, in the same way multiplication is not redudant just because repeated addition can do the same thing.}   

A vector in a Hilbert space \(H\) is represented exclusively by the ket vector \(\ket{\mathcal{\cdot }} \) and a vector in the dual Hilbert space \(H^*\) is exclusively denoted by the bra vector \(\bra{\cdot } \). 

Although Hilbert space \(H\) has infinite dimensions, according to the Riesz representation theorem, Hilbert space \(H\) and its dual \(H^*\) are isomorphic, so we can carry our results from the previous subsection and conclude that bras and kets are related, one-to-one, by the action of hermitian conjugate, and the operation by a bra on a ket is equivalent to the scalar products of two kets

\begin{equation}
  \ket{\psi} = (\bra{\psi})^{\dagger} ~\text { and }~ \bra{\psi }\left( \ket{\phi }  \right) = \avg{\left( \bra{\psi }  \right)^{\dagger}, \ket{\phi } } = \avg{\ket{\psi }, \ket{\phi }  } ,
\end{equation}

For simplicity, it is customary to drop the parenthesis surrounding the ket vector and merge the midrules during operation, \textit{i.e.,} \(\bra{\psi }\left( \ket{\phi }  \right) \equiv \braket{\psi}{\phi}\). 

It is useful to keep in mind that the scalar product bewteen two kets \(\ket{\psi } \text { and } \ket{\phi }  \), \textit{i.e.,} \(\braket{\psi }{\phi } \) is the projection of \(\ket{\phi } \) onto \(\ket{\psi } \). More specifically, it is the component of the \(\ket{\phi } \) vector along \(\ket{\psi } \) given that their norm are equal to 1.      

The scalar product of two functions in Hilbert space is defined as 

\begin{equation}
  \avg{f, g} \equiv \braket{f}{g} \equiv  \int_{a}^{b} f(x)^*g(x)dx. \footnote{This scalar product is gauranteed to exist for every pair of functions by the Schwarz inequality \(\abs{\braket{\alpha }{\beta } }^2 \le \braket{\alpha }{\alpha }\braket{\beta }{\beta }   \).} 
\end{equation}

\section{Operators}

\subsection{Matrix Elements}

For an orthonormal basis \(\{\ket{e_{n} }\} \), a vector in the Hilbert space can be represented by 

\begin{equation}
  \ket{\alpha } = \sum_{n}^{} a_{n}\ket{e_{n} }, \quad a_{n} = \braket{e_{n} }{\alpha }.     
\end{equation}

A operator \(\hat{Q} \) transforms the vector \(\ket{\alpha } \) into another vector \(\ket{\beta } \)

\begin{equation}
  \begin{aligned} 
  \ket{\beta } &= \hat{Q} \ket{\alpha }\\
  \sum_{n}^{} b_{n} \ket{e_{n} } &= \sum_{n}^{} a_{n}\hat{Q} \ket{e_{n} }\\
\sum_{n}^{} b_{n} \braket{e_{m} }{e_{n} } &= \sum_{n}^{} a_{n} \bra{e_{m} }{\hat{Q} }\ket{e_{n} }\\
b_{m} &= \sum_{n}^{} Q_{mn}a_{n}, \quad Q_{mn} \equiv \bra{e_{m} }{\hat{Q} }\ket{e_{n} },         
  \end{aligned} 
\end{equation}

where \(Q_{mn} \equiv \bra{e_{m} }{\hat{Q} }\ket{e_{n} } \) are called the matrix elements of the operator \(\hat{Q}\), in ananogous to the matrix entries in finite-dimensional matrix. 



\subsection{Operators on Bras}

The linear operators such as the Hamiltonian operator begin life as operators that act on kets, mappin them into other kets but the definition of these operators is easily extended to allow them to act on bras to produce other bras, just as how a matrix can be multiplied by a row vector on its left to produce another row vector. Acting on another ket \(\ket{\phi } \) gives 

\begin{equation}
  (\bra{\psi }A )(\ket{\phi } ) = \bra{\psi }(A\ket{\phi } ) \equiv \bra{\psi }A\ket{\phi } \equiv \braket{\psi }{A \phi  } .  
\end{equation}

Another frequently used notation is \(\braket{A \psi }{\phi } \), which means to take the scalar product of \(A \ket{\psi } \text { and } \ket{\phi }   \), \textit{i.e.,} 

\begin{equation}
  \braket{A \psi }{\phi } \equiv \left \langle {(A \ket{\psi }), \phi  } \right \rangle = \braket{\phi }{(A \ket{\psi } )}^* = \bra{\phi }{A}\ket{\psi }^*.  \label{herm1}   
\end{equation}

While writing the more laborious \(\bra{\psi }{A}\ket{\phi } \) makes it symmetric and indicate that \(A\) can either operate on \(\ket{\phi } \text { or }  \bra{\psi } \), we will be mostly using the more simplified form \(\braket{\psi }{A\phi } \) due to the fact that we almost always consider \(A\) operating on \(\ket{\phi } \) instead of \(\bra{\psi } \).

\subsection{Outer Product}

The outer product of two kets \(\ket{\alpha } \text { and } \ket{\beta }  \) is a linear operator itself, just as how the outer product of two vector gives a matrix. Its action on an arbitrary ket \(\ket{\psi } \) is, by associativity

\begin{equation}
  (\ket{\alpha }\bra{\beta }  ) \ket{\psi } =  \ket{\alpha }\bra{\beta }\ket{\psi } = \braket{\beta  }{\psi  } \ket{\alpha  }.     
\end{equation}

Similarly, its action on a bra \(\bra{\psi} \) is

\begin{equation}
  \bra{\psi }(\ket{\alpha }\bra{\beta }  ) = \braket{\psi }{\alpha } \bra{\beta }.  
\end{equation}

For example, the operator \(\hat{P} \equiv \ket{\alpha }\bra{\alpha }  \) is a projection operator that picks out the portion of any other vector that lies along \(\ket{\alpha } \)

\begin{equation}
  \hat{P} \ket{\beta } = \ket{\alpha }\bra{\alpha }\ket{\beta } = \left( \braket{\alpha }{\beta }  \right) \ket{\alpha }.     
\end{equation}

If \(\{\ket{e_{n} }\} \) is a orthonormal basis, \textit{i.e.,} \(\braket{e_{m} }{e_{n} } = 1\), or 

\begin{equation}
  \sum_{n}^{} \ket{e_{n} }\bra{e_{n} } = 1,   
\end{equation}

called the resolution of identity and can be easily verified by acting on this operator an arbitrary vector \(\ket{\alpha } \)

\begin{equation}
  \left( \sum_{n}^{} \ket{e_{n} }\bra{e_{n} } \right) \ket{\alpha } = \sum_{n}^{} (\braket{e_{n} }{\alpha } )\ket{e_{n} } = \ket{\alpha }.   
\end{equation}

Here \(1 \sim  \mathbb{I}\) is the infinite analog of the identity matrix in the finite case. In continuous case we repalce the sum with an integral.





\subsection{Hermitian Operators}

\subsubsection{Definition of Hermitian Operators}

The hermitian conjugate of an operator is defined by 

\begin{equation}
  A^{\dagger} \ket{\psi } = (\bra{\psi }A )^{\dagger}, ~\text { or }~ \braket{\psi }{A^{\dagger} \phi } = \braket{A \psi }{\phi }. \label{herm2} 
\end{equation}

An operator is hermitian if it is equal to its own hermitian conjugate, \textit{i.e.,} \(A^{\dagger} = A\), analogous to the definition of a hermitian matrix. 

From \(\braket{\psi }{A\phi } = \braket{A\psi }{\phi } = \braket{\phi }{A\psi }^*   \) we also find that \(\bra{\psi }A\ket{\psi }  \) is necessarily real if \(A\) is hermitian. Futhermore we say the hermitian operator \(A\) is positive definite if it satisifies \(\bra{\psi }\ket{A\psi } >0  \) which only has positive eigenvalues and conversely nonnegative definite if \(\bra{\psi }\ket{A\psi } \le 0  \)., which only has nonnegative eigenvalues.     

For example, the momentum operator is hermitian since

\begin{equation}
  \langle f \vert \hat{p} g \rangle = \int_{-\infty}^\infty f^* \left( -i\hbar \frac{dg}{dx} \right) dx = -i\hbar f^* g \bigg|_{-\infty}^\infty + \int_{-\infty}^\infty \left( -i\hbar \frac{df}{dx} \right)^* g  dx = \langle \hat{p} f \vert g \rangle,
\end{equation}

where we threw away the boundary term because if \(f(x) \text { and } g(x)\) are square integrable, they must go to zero at \(\pm \infty\).

\subsubsection{Eigenfunctions and Eigenvalues}

The eigenket \(\ket{u} \), eigenbra \(\bra{v} \), and the left and right eigenvalues \(a \text { and } b\) of the operator \(A\) satisfy 

\begin{equation}
  A \ket{u} = a\ket{u} \text { and } \bra{v}A = b \bra{v}.
\end{equation}

In finite dimensions every right eigenvalue is also a left eigenvalue but this need not be true in infinite dimensions. Also note that an eigenvector for a specific eigenvalue is not unique, even if the eigenvalue is non-degenerate and normalized, since we can add an arbitrary phase factor without changing its norm.

The spectrum of an operator is the set of its eigenvalues, which can be discrete (countable infinity) or continuous (incountable infinity) (or a mix of both).\footnote{There will be infinite eigenvalues since Hilbert space has infinite dimensions, just as how a \(n \times n\) matrix has \(n\) eigenvalues. } 

Carrying from our understanding of hermitian matrices in finite-dimensional vector space, we can prove three important facts about the hermitian operators,\footnote{These nice properties are shared by a larger class of normal operators, but we will be mostly dealing with hermitian operator we might as well use hermitian as a synonym for normal.} namely

\begin{enumerate}
  \item The eigenvalues are real,
  \item the eigenvectors of distinct eigenvalues are orthogonal if its spectrum is discrete, and
  \item the left and right eigenvalues are equal.
\end{enumerate}

To prove the first property we have 

\begin{equation}
  \bra{u} \ket{Au} = a \braket{u}{u} = \braket{Au}{u} = a^*\braket{u}{u} \implies a = a^*.
\end{equation}

To prove the second property we have 

\begin{equation}
\bra{u'}\ket{Au} = a \braket{u'}{u} ~\text { and }~ \bra{u}\ket{Au'} ^* = {a'}^* \braket{u}{u'}^* = a' \bra{u'}\ket{u} \implies a = a' ~\text{ or } \braket{u}{u'} = 0.     
\end{equation}

To prove the third property we have

\begin{equation}
  (A\ket{u}){}^{\dagger}  = (a\ket{u})^{\dagger} = \bra{u} A = a^*\bra{u} = a\bra{u}. 
\end{equation}

In fact a common pratice is to label an eigenvector \(\ket{nr} \), where \(n\) dentoes the eigenspace index and \(r\) denotes the linearly indepndent eigevectors of our choice within a particular eigenspace \(n\). 

\section{Eigenstates of Hilbert Space}

In quantum mechanics, all the information about the system is in the abstract state vector \(\ket{\mathcal{S}(t)} \),\footnote{To discourage the idealogy that the position wavefunction \(\psi (x)\) is more fundamental than the momentum wavefunction \(\phi (p)\) and \(\{c_{n}\} \), we will represent the state vector by \(\ket{\mathcal{S}(t)} \) in this section, instead of the customary \(\ket{\psi } \).} residing somewhere in the Hilbert space. In fact, every normalized vector in the Hilbert space corresponds to a physically realizable state. 

By normalized vector we means that that the norm (-squared) of the vector has to be unity, \textit{i.e.,} \(\braket{\mathcal{S}(t)}{\mathcal{S}(t)} = 1 \). As we will see this normalization ensures the correct interpretation of its component in different basis. Non-normalized vectors represent the same state as the normalized vector after it has been normalized, \textit{i.e.,} multiplied by a factor \(k\) where \(\braket{k \mathcal{S}(t)}{k \mathcal{S}(t)} =1\). Therfore we see that the state vector is defined only up to a (complex) constant, which is also the reason why normalizing the time-dependent wavefunction \(\Psi (x,t)\) is equivalent to normalizing the time-independent wavefunction \(\psi (x)\), since they only differed by the wiggle factor \(\varphi (t) = e^{iE_{n}t/\hbar  } \), which is a constant complex number. This is analogous to how we almost always refer to the normalized eigenvector as ``the'' eigenvector of a matrix.

There are three important basis in Hilbert sapce, namely the position, momentum and energy eigenbasis.\footnote{Some authors like to say that there are three fundamental Hilbert space, \textit{i.e.,} position space, momentum space and energy space, which is just another way of saying that we can expand the state vector \(\ket{\mathcal{S}(t)} \) in different eigenbasis, but they treat the same vector space with different eigenbasis as separate vector spaces. This view also make sense since in a standard linear algebra course, we are used to the basis standing for the same quantity, say, space coordinates, even after a linear transformation, say, a rotation, which only change the direction of the axes. In quantum mechanics, however, the change in eigenbasis stands for the change in how we describe the state. So whether you view position, momentum and energy space as three separate vector space is largely just a matter of taste. In these notes, we adopt the interpretation that we are working in a single Hilbert space, the visualization of view the switching of eigenbasis from one to another as the action of a rotation matrix can still be useful.} Eigenstates are the eigenvectors of their corresponding operators, namely the position operator \(\hat{x} \), momentum operator \(\hat{p} \) and the Hamiltonian (energy operator) \(\hat{H} \). They are in fact even more often called the eigenstates, since every vector in Hilbert space corresponds to a physical state. Note that the eigenstates form a basis since the operators are hermitian, so their eigenstates are (or can be made to be) orthonormal and complete (spans the whole Hilbert space).\footnote{The completeness of eigenvectors is trivial in finite dimension once the orthonormality of the eigenvectors is proved, sicne we know there would be \(n\) eigenvectors for a \(n \times n\) matrix from the fundamental theorem of calculus when solving the charateristic equation. In infinite dimensions, however, the completeness should not be taken for granted, but we shall assume the completness of eigenstates for the standard hermitian operators due to the difficulty in proving it.} 

The basis that we choose determines what quantity are we describing the system in. The state vector \(\ket{\mathcal{S}(t)} \) is most likely to be in a superposition of different eigenstates and the component of the state vector \(\ket{\mathcal{S}(t)} \) on a particular eigenstate is the probability amplitude\footnote{The true probability is the probability amplitude squared.} that upon measurement it would ``collapses'' to this eigenstate. 

Now we when operate on the state vector \(\ket{\mathcal{S}(t)} \), the operator would scale each eigenstate by its eigenvalue, which could be position \(x\), momentum \(p\), or energy \(E_{n} \). This operator is useful in the sense that if we sum up, for all the eigenstate, the probability that the system would ``collapses'' to this particular eigenstate \(P(\ket{\cdot } )\) times its eigenvalue, which can be position, momentum, or energy, then we would obtain the weighted avergae, which is the expected value of that observable quantity.\footnote{In the case of continuous spectra the collapse is to a narrow range about the measured value, depending on the precision of the measuring device.} 

\subsection{Position Operator \(\hat{x} \) }

The position operator \(\hat{x} \) has position eigenstates \(\ket{x} \) defined by the eigenequation 

\begin{equation}
  \hat{x} \ket{x} = x \ket{x},  
\end{equation}

where the eigevalues \(x\) represents the definite position of the particle.

Any quantum state can be expanded in the position eigenbasis as

\begin{equation}
  \ket{\mathcal{S}(t)} = \int dx \psi (x)\ket{x}.\footnote{Mathemtically this comes from acting the resolution of identity \(1 = \int dx \ket{x} \bra{x}  \) to the state vector \(\ket{\mathcal{S}(t)} \).} 
\end{equation}

Here \(\psi (x)\) is the position time-independent wavefunction, which is the probability amplitude that the state vector \(\mathcal{S}(t)\) would ``collapses'' to the eigenstate \(\ket{x} \). In other words, \(\psi (x)\) is the component (or the projection) of the state vector \(\ket{\mathcal{S}(t)} \) onto the eigenstate \(\ket{x} \), \textit{i.e.,} 

\begin{equation}
  \psi (x) = \braket{x}{\mathcal{S}(t)}. 
\end{equation}

The position wavefunction \(\psi (x)\) is also called the eigenfunction of the position operator \(\hat{x} \), which is the representation of the position eigenstate \(\ket{x} \) in position space.\footnote{The words eigenfunction and eigenstate are in most cases used interchangeably, but rigourously, eigenstate is a vector in the Hilbert space, while the eigenfunction is a scalar representation of the eigenstate dependent on the basis chosen.}

\subsection{Momentum Operator \(\hat{p} \) }

The momentum operator \(\hat{p} \) has momentum eigenstates \(\ket{p} \) defined by the eigenequation 

\begin{equation}
  \hat{p} \ket{p} = p \ket{p},  
\end{equation}

where the eigevalues \(p\) represents the definite momentum of the particle.

Any quantum state can be expanded in the position eigenbasis as

\begin{equation}
  \ket{\mathcal{S}(t)} = \int dp \phi  (p)\ket{p}.  \footnote{Mathemtically this comes from acting the resolution of identity \(1 = \int dp \ket{p} \bra{p}  \) to the state vector \(\ket{\mathcal{S}(t)} \).} 
\end{equation}

Here \(\phi (p)\) is the momentum time-independent wavefunction, which is the probability amplitude that the state vector \(\mathcal{S}(t)\) would ``collapses'' to the eigenstate \(\ket{p} \). In other words, \(\phi (p)\) is the component (or the projection) of the state vector \(\ket{\mathcal{S}(t)} \) onto the eigenstate \(\ket{p} \), \textit{i.e.,} 

\begin{equation}
  \phi (p) = \braket{p}{\mathcal{S}(t)}. 
\end{equation}

\subsection{Hamitonian \(\hat{H} \) }

The Hamiltonian (energy operator) \(\hat{H} \) has energy eigenstates \(\ket{E_{n} } \), also called the stationary states, defined by the eigenequation

\begin{equation}
  \hat{H}  \ket{E_{n} } = E_{n}\ket{E_{n} },
\end{equation}

where the eigenvalues \(E_{n} \) represents the definite energy of the quantum system. 

Any quantum state can be expanded in the energy eigenbasis as 

\begin{equation}
  \ket{\mathcal{S}(t)} = \sum_{n}^{} c_{n} \ket{E_{n} }.    \footnote{Mathemtically this comes from acting the resolution of identity \(1 = \sum_{n}^{} \ket{E_{n} }\bra{E_{n} }    \) to the state vector \(\ket{\mathcal{S}(t)} \).} 
\end{equation}

Here \(c_{n} \) is the energy time-independent wavefunction, which is the probability amplitude that the state vector \(\mathcal{S}(t)\) would ``collapses'' to the eigenstate \(\ket{E_{n} } \). In other words, \(c_{n} \) is the component (or the projection) of the state vector \(\ket{\mathcal{S}(t)} \) onto the eigenstate \(\ket{E_{n} } \), \textit{i.e.,} 

\begin{equation}
  c_{n}  = \braket{E_{n} }{\mathcal{S}(t)}. 
\end{equation}

\subsection{Position Eigenstates} \label{poseigen} 

Just as how the basis can be changed by a matrix in a standard linear algebra course, the position, momentum and energy eigenbasis are interchangeable.\footnote{If we view the position, momentum and energy space as three separte vector space, this is to say that the three vector spaces are isomorphic to each other, \textit{i.e.,} there exist a linear, bijective map between any of the two vector spaces.} 

\paragraph{Position Space}

In position space, \textit{i.e.,} using the position eigenstates \(\ket{x'} \) as the basis, the position eigenstate \(\ket{x } \) is represented by the eigenfunction

\begin{equation}
  \braket{x'}{x} = \delta (x'-x),
\end{equation}

and the position eigenstate \(\ket{x} \) can be expanded in terms of the position eigenstates as 

\begin{equation}
  \ket{x} = \int dx' \braket{x'}{x} \ket{x'} = \int dx' \delta (x'-x) \ket{x'} = \ket{x}.  
\end{equation}

\paragraph{Momentum Space}

In momentum space, \textit{i.e.,} using momentum eigenstates \(\ket{p} \) as the basis, the position eigenstate \(\ket{x} \) is represented by the eigenfunction

\begin{equation}
  \braket{p}{x} = \frac{1}{\sqrt{2\pi \hbar } } e^{-ipx /\hbar },
\end{equation}

and the position eigenstate \(\ket{x} \) can be expanded in terms of the momentum eigenstates as

\begin{equation}
  \ket{x} = \int dp \braket{p}{x} \ket{p} = \frac{1}{\sqrt{2\pi \hbar } } \int dp e^{-ipx /\hbar } \ket{p} .    
\end{equation}

Taking the complex conjugate and applying it to the state vector \(\mathcal{S}(t)\) gives 

\begin{equation}
  \braket{x}{\mathcal{S}(t)} = \psi (x) = \frac{1}{\sqrt{2\pi \hbar } } \int dp e^{ipx /\hbar } \braket{p}{\mathcal{S}(t)} = \frac{1}{\sqrt{2\pi \hbar } }  \int dp e^{ipx /\hbar } \phi (p).   \label{posmom} 
\end{equation}

\paragraph{Energy space}

In energy space, \textit{i.e.,} using energy eigenstates \(\ket{E_{n} } \) as the basis, the position eigenstate \(\ket{x} \) is represented by the eigenfunction 

\begin{equation}
  \braket{E_{n} }{x} = \psi _{n}^*(x),
\end{equation}

and the position eigenstate \(\ket{x} \) can be expanded in terms of the energy eigenstates as 

\begin{equation}
  \ket{x} = \sum_{n}^{} \braket{E_{n} }{x} \ket{E_{n} } = \sum_{n}^{} \psi _{n}^*(x) \ket{E_{n} }.       
\end{equation}

Taking the complex conjugate and applying it to the state vector \(\mathcal{S}(t)\) gives 

\begin{equation}
  \braket{x}{\mathcal{S}(t)} = \psi (x) = \sum_{n}^{} \psi _{n}(x) \braket{E_{n} }{\mathcal{S}(t)} = \sum_{n}^{} \psi _{n}(x) c_{n}       
\end{equation}

\subsection{Momentum Eigenstates} \label{momeigen} 

\paragraph{Position Space}

In position space, \textit{i.e.,} using the position eigenstates \(\ket{x} \) as the basis, the momentum eigenstate \(\ket{p } \) is represented by the eigenfunction

\begin{equation}
  \braket{x}{p} = \frac{1}{\sqrt{2\pi \hbar } } e^{ipx /\hbar },
\end{equation}

and the momentum eigenstate \(\ket{p} \) can be expanded in terms of the position eigenstates as 

\begin{equation}
  \ket{p} = \int dx \braket{x}{p} \ket{x} = \frac{1}{\sqrt{2\pi \hbar } } \int dp e^{ipx /\hbar } \ket{x} .      
\end{equation}

Taking the complex conjugate and applying it to the state vector \(\mathcal{S}(t)\) gives 

\begin{equation}
  \braket{p}{\mathcal{S}(t)} = \phi (p) = \frac{1}{\sqrt{2\pi \hbar } } \int dx e^{-ipx /\hbar } \braket{x}{\mathcal{S}(t)} = \frac{1}{\sqrt{2\pi \hbar } }  \int dx e^{-ipx /\hbar } \psi (x).   
\end{equation}

\paragraph{Momentum Space}

In momentum space, \textit{i.e.,} using momentum eigenstates \(\ket{p} \) as the basis, the momentum eigenstate \(\ket{p} \) is represented by the eigenfunction

\begin{equation}
  \braket{p'}{p} = \delta (p'-p),
\end{equation}

and the momentum eigenstate \(\ket{p} \) can be expanded in terms of the momentum eigenstates as

\begin{equation}
  \ket{p} = \int dp' \braket{p'}{p} \ket{p'} = \int dp' \delta (p'-p) \ket{p'} = \ket{p}.  
\end{equation}

\paragraph{Energy space}

In energy space, \textit{i.e.,} using energy eigenstates \(\ket{E_{n} } \) as the basis, the momentum eigenstate \(\ket{p} \) is represented by the eigenfunction 

\begin{equation}
  \braket{E_{n} }{p} = \phi _{n}^*(p) ,
\end{equation}

and the momentum eigenstate \(\ket{p} \) can be expanded in terms of the energy eigenstates as 

\begin{equation}
  \ket{p} = \sum_{n}^{} \braket{E_{n} }{p} \ket{E_{n} } = \sum_{n}^{} \phi _{n}^*(p) \ket{E_{n} }.       
\end{equation}

Taking the complex conjugate and applying it to the state vector \(\mathcal{S}(t)\) gives 

\begin{equation}
  \braket{p}{\mathcal{S}(t)} = \phi (x) = \sum_{n}^{} \phi _{n}(x) \braket{E_{n} }{\mathcal{S}(t)} = \sum_{n}^{} \phi _{n}(x) c_{n}       
\end{equation}

\subsection{Energy Eigenstates}

\paragraph{Position Space}

In position space, \textit{i.e.,} using the position eigenstates \(\ket{x} \) as the basis, the energy eigenstate \(\ket{E_{n} } \) is represented by the eigenfunction

\begin{equation}
  \braket{x}{E_{n} } = \psi _{n}(x) ,
\end{equation}

and the energy eigenstate \(\ket{E_{n} } \) can be expanded in terms of the position eigenstates as 

\begin{equation}
  \ket{E_{n} } = \int dx \braket{x}{E_{n} } \ket{x} = \int dx \psi _{n}(x) \ket{x}.      
\end{equation}

Taking the complex conjugate and applying it to the state vector \(\mathcal{S}(t)\) gives 

\begin{equation}
  \braket{E_{n} }{\mathcal{S}(t)} = c_{n} = \int dx \psi _{n}^*(x) \braket{x}{\mathcal{S}(t)} = \int dx \psi _{n}^*(x)\psi (x).    
\end{equation}



\paragraph{Momentum Space}

In momentum space, \textit{i.e.,} using momentum eigenstates \(\ket{p} \) as the basis, the energy eigenstate \(\ket{E_{n} } \) is represented by the eigenfunction

\begin{equation}
  \braket{p}{E_{n} } = \phi _{n}(x),
\end{equation}

and the energy eigenstate \(\ket{E_{n} } \) can be expanded in terms of the momentum eigenstates as

\begin{equation}
  \ket{E_{n} } = \int dp \braket{p}{E_{n} } \ket{p} = \int dp \phi  _{n}(x) \ket{x}.      
\end{equation}

Taking the complex conjugate and applying it to the state vector \(\mathcal{S}(t)\) gives 

\begin{equation}
  \braket{E_{n} }{\mathcal{S}(t)} = c_{n} = \int dp \phi _{n}^*(p) \braket{p}{\mathcal{S}(t)} = \int dp \phi _{n}^*(p)\psi (p).    
\end{equation}

\paragraph{Energy space}

In energy space, \textit{i.e.,} using energy eigenstates \(\ket{E_{n} '} \) as the basis, the energy eigenstate \(\ket{E_{n} } \) is represented by the eigenfunction 

\begin{equation}
  \braket{E_{n} '}{E_{n} } = \delta (E_{n}' - E_{n}  ),
\end{equation}

and the energy eigenstate \(\ket{E_{n} } \) can be expanded in terms of the energy eigenstates as 

\begin{equation}
  \ket{E_{n} } = \int dE_{n} ' \braket{E_{n} '}{E_{n} } \ket{E_{n} '} = \int dE_{n} ' \delta (E_{n} '-E_{n} ) \ket{E_{n} '} = \ket{E_{n} }.  
\end{equation}

Therefore, none of these spaces can be taken as more fundamental than the other; any calculation that can be carried out in one space can be carried out in another.\footnote{Psychologically there is a tendency to think of the position wavefunctions \(\psi (x)\) are more fundamental, possibly due to the fact that we live in physical space, but not momentum space or energy space.} 

\subsection{Position, Momentum and Fourier Transform}

In this subsection we will try and explain why the position and momentum wave function are Fourier transfomrm of each other.

The eigenequation for the momentum operator \(\hat{p} \) reads

\begin{equation}
  \hat{p}  \ket{p} = p \ket{p}.  
\end{equation}

To express this abstract vector equation in position space, we act on both sides the dual of the position eigenstate \(\ket{x} \), \textit{i.e.,} \(\bra{x} \), and substitute the position representation of the momentum operator \(\hat{p} = -i \hbar \partial /\partial x\) to get 

\begin{equation}
  -i \hbar \frac{\partial }{\partial x} \braket{x}{p} = p \braket{x}{p} \implies \phi (p) = \braket{x}{p} = Ae^{-ipx /\hbar } \equiv \frac{1}{\sqrt{2\pi \hbar } } e^{-ipx /\hbar },   
\end{equation}

where the normalization constant \(A\) is chosen to be \(1/\sqrt{2\pi \hbar }  \) for symmetry consideration.  

An equivalent way would be to ``take the complex conjugate'' of the whole equation and apply it to the state vector \(\ket{\mathcal{S}(t)} \) as we have done, which would yield  

\begin{equation}
  \hat{p} \braket{p}{\mathcal{S}(t)} = \hat{p} \phi (p) = p \braket{p}{\mathcal{S}(t)} = p \phi (p) \implies \phi (p) = \frac{1}{2\pi \hbar } e^{-ipx /\hbar },    
\end{equation}

since \(\hat{p} \) is hermitian, so it does not change under hermitian conjugate.

A wrong approach would be to take the hermitian conjugate ``as usual'' as

\begin{equation}
 i \hbar \frac{\partial }{\partial x} \braket{p}{\mathcal{S}(t)} = i \hbar \frac{\partial }{\partial x} \phi (p) = p \braket{p}{\mathcal{S}(t)} = p \phi (p) \implies \phi (p) = Ae^{ipx /\hbar } \equiv \frac{1}{\sqrt{2\pi \hbar } }e^{ipx /\hbar },
\end{equation}

which differs by a sign, since the rule for a genearl operator \((iA){}^{\dagger} = - iA^{\dagger} \) does not holds (\(A = d/dx\) in this case), because \(d/dx\) itself changes under conjugation. What really mattres is that the momentum operator is hermitian (which we will prove explicitly later) and thus \(\hat{p} {}^{\dagger} = \hat{p} \). 

From here we follows the procedure from \cref{momeigen} to obtain the expression of the momentum wavefunction in terms of the position wavefunction

\begin{equation}
  \phi (p) = \frac{1}{\sqrt{2\pi \hbar } } \int dx e^{-ipx /\hbar }\psi (x).  
\end{equation}

The prove its converse

\begin{equation}
  \psi (x) = \frac{1}{\sqrt{2\pi \hbar } } \int dp e^{ipx/\hbar } \phi (p),  
\end{equation}

we start with the position operator in the positon space, \textit{i.e.,} \(\hat{x} = x\). Operating both sides on the position wavefunction \(\psi (x)\) and taking the Fourier transform of both sides we have 

\begin{equation}
  \begin{aligned} 
  \int dxe^{-ipx /\hbar }\hat{x} \psi (x) &= \int dxe^{-ipx /\hbar }x \psi (x)\\
  \hat{x} \phi (p) = \int dx \left( i \hbar \frac{d}{dp} e^{-ipx /\hbar }  \right) \psi (x) &= i \hbar \frac{d}{dp} \int dx e^{-ipx /\hbar } \psi (x) = i \hbar \frac{d}{dp} \phi (p),
  \end{aligned} 
\end{equation}

where \(\hat{x} \) can be pulled out from the integral due to the associativity of linear operators.

Alternatively, we can express the positon operator \(\hat{x} \) in momentum space by taking the inner product between the momentum eigenstates \(\ket{p} \) and the operated state vector \(\hat{x} \ket{\mathcal{S}(t)} \)

\begin{equation}
  \begin{aligned} 
  \bra{p}{\hat{x} }\ket{\mathcal{S}(t)} &= \left \langle p\left| \hat{x}   \left(\int dx \ket{x} \bra{x} \right) \right| \mathcal{S}(t) \right \rangle = \int dx \bra{p}{x}\ket{x} \braket{x}{\mathcal{S}(t)}  \\
  &= \int dx x \braket{p}{x} \psi (x) = \frac{1}{\sqrt{2\pi \hbar } }  \int dx x \psi (x) e^{-ipx /\hbar } \\
  &= i \hbar \frac{\partial }{\partial p} \frac{1}{\sqrt{2\pi \hbar } } \int dx e^{-ipx /\hbar }\psi (x) = i \hbar \frac{\partial }{\partial p} \phi (p), 
  \end{aligned} 
\end{equation}

where we have inserted the resolution of indentity at the first equality

Therefore we have \(\hat{x} = i \hbar d /dp \) in momentum space. Following the same procedure above but in momentum space we prove the Fourier transform relation between position wavefunction \(\psi (x)\) and momentum wavefunction \(\phi (p)\) once again.  

\subsection{Dirac Orthonomrality}

Note that the Dirac delta function is not a function in the ususal sense but a distribution, so it would be inappropriate to say that \(\delta (0) = \infty\). Instead, the Dirac delta function is born to be used under an integral sign, and satisfies \(\int_{-\infty}^{+\infty} \delta (x-x')dx = 1 \).

The position eigenstates, or other continuous eigenstates, are not orthonomral in the usual sense, \textit{i.e.,} \(\braket{x_{m} }{x_{n} } = \delta (x_{m} - x_{n}  ) \neq  \delta _{mn}  \), but it still have the orthonormal property of \(\braket{x'}{x} = 0 \) for \(x' \neq x\), just that we cannot assign a value for \(\braket{x}{x} \).

Although the eigenfunctions themselves are not normalizable, they do not represent possible wavefunctions, but linear combinations of them would be normalizable. For example, although the momentum eigenfunction in position space is non normalizable

\begin{equation}
  \int_{-\infty}^{+\infty} dx \braket{x}{p} ^2  = \int_{-\infty}^{+\infty} \left( \frac{1}{\sqrt{2\pi \hbar } } e^{ipx /\hbar }   \right) dx = \int_{-\infty}^{+\infty} \frac{dx}{2\pi \hbar } = \infty,  
\end{equation}

a linear combination of momentum eigenfunctions, with the weight function \(\phi (p)\) is normalizable 

\begin{equation}
  \int_{-\infty}^{+\infty} dx \abs{\psi (x)}^2 = \frac{1}{2\pi \hbar } \int dp \abs{\phi (p)}^2 < \infty  
\end{equation}

from \cref{posmom}. 

This is to say that a single momentum eigenstate is not localized and extends uniformly over all space, leading to an infinite norm, a manifestication of the Heisenberg uncertainty principle. On the other hand, a linear combination of momentum eigenstates, weighted appropriately can interfere to produce a localized wave packet that is square-integrable.

As they are non-nomralizable, they do not, in fact, live in the standard Hilbert sapce and does not represent a physically realizable state, \textit{i.e.,} there is no particle with a definite momentum or position. In fact, they live in a more general \href{https:////en.wikipedia.org//wiki//Rigged_Hilbert_space}{rigged Hilbert space}. Informally, though, we still refer the eigenstates to live in the Hilbert space. 

\subsection{Observables}
A complete hermitian operator corresponds to an observable, \textit{i.e.,} some quantity that we can observe in the system, and the eigenstate of the operator corresponds to the state where the observable has a definite value, \textit{i.e.,} we get the same result every time we measure this observable. 

The expectation value of an observable \(Q(x,p)\)\footnote{If \(Q\) involves, say, the product \(xp\), we need other consideration to determine whether we should write \(\hat{x} \hat{p} \text { or } \hat{p} \hat{x}  \).} can be obtained by acting the corresponding hermitian operator \(\hat{Q} \) on \(\Psi \) as can be found by the weighted average

\begin{equation}
  \begin{aligned} 
  \left \langle {Q} \right \rangle &= \sum_{n}^{} Q_{n} \braket{Q_{n} }{\mathcal{S}(t)}^2 = \sum_{n}^{} Q_{n} \braket{Q_{n} }{\mathcal{S}(t)} \braket{\mathcal{S}(t)}{Q_{n} }\\
  &= \sum_{n}^{} \braket{\mathcal{S}(t)}{Q_{n} } \bra{Q_{n} }{\hat{Q} }\ket{\mathcal{S}(t)} = \left \langle \mathcal{S}(t) \left| \sum_{n}^{} \ket{Q_{n} } \bra{Q_{n} } \hat{Q} \right| \mathcal{S}(t) \right \rangle \\
   &= \bra{\mathcal{S}(t)}{}\ket{\hat{Q} \mathcal{S}(t)} = \braket{\hat{Q} \mathcal{S}(t)}{\mathcal{S}(t)}, 
  \end{aligned}       
\end{equation}

where we did not need to take the hermitian conjugate when switching the order of the scalar product since observables must be real. 

\subsection{Heisenberg's Uncertainty Principle}

The uncertainty for any observable \(Q\) is 

\begin{equation}
  \sigma _{Q}^2 =  \left< (Q-\avg{Q} )^2 \right> = \left< \mathcal{S}(t) \mid (\hat{Q} - \avg{Q} )^2 \mathcal{S}(t) \right> = \left< (\hat{Q} - \avg{Q} )\mathcal{S}(t) \mid (\hat{Q} - \avg{Q} )\mathcal{S}(t) \right>,
\end{equation}

which equals to zero if the state vector \(\ket{\mathcal{S}(t)} \) lies on the eigenstate of \(\hat{Q} \) due to the eigenequation \(\hat{Q} \ket{\mathcal{S}(t)} = \left \langle {Q} \right \rangle \ket{\mathcal{S}(t)} \). 

Now for any complex number \(z\) we have 

\begin{equation}
  \abs{z}^2 = \left( \mathfrak{Re} (z)  \right)^2 + \left( \mathfrak{Im} (z)  \right)^2 \ge \left( \mathfrak{Im} (z)  \right)^2 = \left( \frac{1}{2i} (z - z^*)  \right)^2, \label{complex} 
\end{equation}

Together with the Schwarz inequality we have

\begin{equation}
  \begin{aligned} 
  \sigma _{A}^2 \sigma _{B}^2 &=   \braket{(\hat{A} - \avg{A} )\mathcal{S}(t)}{(\hat{A} - \avg{A} )\mathcal{S}(t)} ^2  \braket{(\hat{B} - \avg{B} )\mathcal{S}(t)}{(\hat{B} - \avg{B} )\mathcal{S}(t)} ^2 \\
  &\ge \braket{(\hat{A} - \avg{A} )\mathcal{S}(t)}{(\hat{B} - \avg{B} )\mathcal{S}(t)} ^2 \\
  &\ge \left( \frac{1}{2i} \left( \braket{(\hat{A} - \avg{A} )\mathcal{S}(t)}{(\hat{B} - \avg{B} )\mathcal{S}(t)}  - \braket{(\hat{A} - \avg{A} )\mathcal{S}(t)}{(\hat{B} - \avg{B} )\mathcal{S}(t)}^* \right)  \right)^2.
  \end{aligned} 
\end{equation}

The braket can be simplified as

\begin{equation}
  \begin{aligned} 
  &~~~~\braket{(\hat{A} - \avg{A} )\mathcal{S}(t)}{(\hat{B} - \avg{B} )\mathcal{S}(t)} = \braket{\mathcal{S}(t)}{\left( \hat{A} - \left \langle {A} \right \rangle  \right) \left( \hat{B} - \left \langle {B} \right \rangle  \right) \mathcal{S}(t)} \\
  &= \braket{\mathcal{S}(t)}{\left( \hat{A} \hat{B} - \hat{A} \left \langle {B} \right \rangle - \hat{B} \left \langle {A} \right \rangle + \left \langle {A} \right \rangle \left \langle {B} \right \rangle  \right) \mathcal{S}(t)} \\
  &= \braket{\mathcal{S}(t)}{\hat{A} \hat{B} \mathcal{S}(t)} - \left \langle {B} \right \rangle \braket{\mathcal{S}(t)}{\hat{A} \mathcal{S}(t)} - \hat{A} \braket{\mathcal{S}(t)}{\hat{B} \mathcal{S}(t)} + \left \langle {A} \right \rangle \left \langle {B} \right \rangle \braket{\mathcal{S}(t)}{\mathcal{S}(t)} \\
  &= \left \langle {\hat{A} \hat{B} } \right \rangle - \left \langle {B} \right \rangle \left \langle {A} \right \rangle - \left \langle {A} \right \rangle \left \langle {B} \right \rangle + \left \langle {A} \right \rangle \left \langle {B} \right \rangle = \left \langle {\hat{A} \hat{B} } \right \rangle - \left \langle {A} \right \rangle \left \langle {B} \right \rangle.
  \end{aligned} 
\end{equation}

Upon substitution gives

\begin{equation}
  \begin{aligned} 
  \sigma _{A}^2\sigma _{B}^2 &\ge \left( \frac{1}{2i} \left( \left \langle {\hat{A} \hat{B} } \right \rangle  - \left \langle {A} \right \rangle \left \langle {B} \right \rangle  \right) - \left( \left \langle {\hat{A} \hat{B} } \right \rangle - \left \langle {A} \right \rangle \left \langle {B} \right \rangle   \right)^*  \right)^2 \\
  &= \left( \frac{1}{2i}  \left( \left \langle {\hat{A} \hat{B} } \right \rangle  - \left \langle {A} \right \rangle \left \langle {B} \right \rangle  \right) - \left( \left \langle {\hat{B} \hat{A} } \right \rangle - \left \langle {A} \right \rangle \left \langle {B} \right \rangle  \right)  \right)^2 \\
  &= \left( \frac{1}{2i} \left \langle {\hat{A} \hat{B} } \right \rangle - \left \langle {\hat{B} \hat{A} } \right \rangle   \right)^2 \equiv \left( \frac{1}{2i} \left \langle {\left[ \hat{A} ,\hat{B}  \right]} \right \rangle \right)^2,
  \end{aligned} 
\end{equation}

where \(\left[ \hat{A} , \hat{B}  \right] \equiv \hat{A} \hat{B} - \hat{B} \hat{A} \) is called the commutator of the two operators \(\hat{A} \text { and } \hat{B} \), which measures how badly they fail to commute.  

For the pair of operators \(x \text { and } \hat{p} \), we have

\begin{equation}
  (x \hat{p} - \hat{p} x )f(x) = x(-i \hbar )\frac{df}{dx} -(i \hbar )\frac{d}{dx}(xf) = i \hbar f(x) \implies \left[ x, \hat{p}  \right] = i \hbar ,
\end{equation}

which is known as the canonical commutation relation. 

The Heisenberg's uncertainty principle therefore states that 

\begin{equation}
  \sigma _{x}^2\sigma _{p}^2 \ge \left( \frac{\hbar }{2}  \right)^2 \implies \sigma _{x}\sigma _{p} \ge \frac{\hbar }{2}.   
\end{equation}

The inequality in Heisenberg's uncertainty principle becomes equality if the Schwarz inequality becomes equality and the real part that we thrown away in \cref{complex} is zero, that is

\begin{equation}
  \begin{aligned} 
  \hat{A} - \left \langle {A} \right \rangle &= ia \left( \hat{B} - \left \langle {B} \right \rangle  \right), ~\text { or }~ \\
  \left( -i \hbar \frac{d}{dx} - \left \langle {p} \right \rangle   \right) \ket{\mathcal{S}(t)} &= ia (x - x) \ket{\mathcal{S}(t)}.
  \end{aligned}  
\end{equation}

Solving gives a gaussian wave packet 

\begin{equation}
  \psi (x) = Ae^{-a (x - \ket{x} )^2 / 2 \hbar } e^{i \left \langle {p} \right \rangle x /\hbar }.  
\end{equation}













\chapter{The Wavefunction}
	
\section{The Schrödinger Equation}
	
In classical mechanics, the total energy \(E\) of a particle can be written as 

\begin{equation}
  E=\frac{1}{2} mv^2 + V(x) = \frac{p^2}{2m} + V(x). \label{classenergy}
\end{equation}

Since we know that all particles are actually waves of frequency \(\omega\) and wavenumber \(\vb{k}\), so \cref{classenergy} becomes

\begin{equation} 
  \hbar \omega = \frac{\hbar^2k^2}{2m} + V(x). \label{quanenergy}
\end{equation}

We now introduce the wavefunction of a particle \(\Psi \) as

\begin{equation}
  \Psi (\vb{r} ,t) = Ae^{i(\vb{k} \dot{\vb{r} } - \omega t )}. \label{3dwavefuc} 
\end{equation}

In one-dimensional case, \cref{3dwavefuc} reduces to

\begin{equation}
  \Psi (x,t) = Ae^{i(kx - \omega t)}. \label{1dwavefuc}  
\end{equation}

where \(\abs{\Psi (x,t)}^2 dx\) is the probability of finding the particle between \(x\) and \(x + dx\) at time t (so \(\Psi\) is actually a probability density function) and \(A\) is chosen such that \(\Psi\) is normalized, \textit{i.e.,} 

\begin{equation}
  \int_{-\infty}^{\infty} \abs{\Psi (x,t)}^2 dx = 1.
\end{equation}

Noting that \( \partial \Psi /\partial t = -i \omega\Psi \) and \( \partial ^2\Psi /\partial x^2 = -k^2\Psi \), \(\Psi\) times \cref{quanenergy} becomes

\begin{equation}
  \Psi \hbar\omega = \Psi \left(\frac{\hbar ^2 k^2 }{2m} + V(x)\right) = -\frac{\hbar }{i} \frac{\partial\Psi}{\partial t} = \frac{-\hbar ^2 }{2m} \frac{\partial^2\Psi }{\partial x^2} + V(x)\Psi \label{fma} 
\end{equation}

Rearranging, we obtain the Schrödinger equation\footnote{Some call this the time-dependent Schrödinger equation, in contrast with the time-independent Schrödinger equation that we will encounter later (in which case the term on the LHS is replace by \(E\psi \)), but in most cases we will refer both simply by Schrödinger equation, as the distinction is clear.} 

\begin{equation}
  i \hbar \frac{\partial \Psi}{\partial t}=-\frac{\hbar^2}{2 m} \frac{\partial^2 \Psi}{\partial x^2}+V \Psi .\label{scr}
\end{equation}

The Schrödinger equation in quantum mechanics plays a similar role to Newton's second law in classical mechanics. Given suitable initial conditions (typically, $\Psi(x, 0)$), the Schrödinger equation determines $\Psi(x, t)$ for all future time, just as Newton's second law determines $x(t)$ for all future time.

\example{Wavefunction Remains Normalized.}
{Show that once the wavefunction is normalized at t = 0, it remains normalized for any later time.}
{Consider

\begin{equation}
  \frac{\partial }{\partial t} \abs{\Psi }^2 = \frac{\partial }{\partial t} (\Psi^*\Psi ) = \Psi ^* \frac{\partial \Psi }{\partial t} + \Psi \frac{\partial \Psi ^*}{\partial t}, 
\end{equation}

since \(\partial \Psi / \partial t \) is given in the Schrödinger equation (\cref{scr}), while \(\partial \Psi ^* /\partial t\) can be found by taking the complex conjugate of the Schrödinger equation (by changing the sign of the exponential in \cref{3dwavefuc}), we have
		
\begin{equation}
  -i \hbar \frac{\partial \Psi^*}{\partial t}=-\frac{\hbar^2}{2 m} \frac{\partial^2 \Psi^*}{\partial x^2}+V\Psi^*.
\end{equation}
		
Therefore
		
\begin{equation}
  \begin{aligned}
    \frac{d}{dt}  \int_{\infty}^{\infty}   \abs{\Psi(x,t)}^2 dx  &= \int_{\infty}^{\infty}   \pdv{t} \abs{\Psi(x,t)}^2 dx \\ &= \int_{\infty}^{\infty}   \left(\Psi^*\left(\frac{i\hbar}{2m}\pdv[2]{\Psi}{x} - \frac{i}{\hbar}V\Psi^*\right) + \Psi\left(-\frac{i\hbar}{2m}\pdv[2]{\Psi^*}{x} + \frac{i}{\hbar}V\Psi^*\right)\right)dx \\ &= \int_{\infty}^{\infty}   \frac{i\hbar}{2m}\left(\Psi^*\pdv[2]{\Psi}{x} - \Psi\pdv[2]{\Psi^*}{x}\right)dx \\ &= \frac{i\hbar}{2m}\int_{\infty}^{\infty}  \pdv{x}\left(\Psi^*\pdv{\Psi}{x} - \Psi\pdv{\Psi^*}{x}\right)dx \\ &= \frac{i\hbar}{2m} \eval{\left(\Psi^*\pdv{\Psi}{x} - \Psi\pdv{\Psi^*}{x}\right)}_{-\infty}^{+\infty} = 0. \label{ddtpsi2}
  \end{aligned}
\end{equation}

where in the last equality we invoked the fact that \(\Psi\) and \(\Psi^*\) must goes to zero as \(x\) goes to \(\infty\) otherwise the wavefunction will not be normalizable.
		
Therefore, since \(\frac{d}{dt}  \int_{-\infty}^{\infty} \abs{\Psi (x,t)}^2 dx = 0\), it implies that \( \int_{-\infty}^{\infty}   \abs{\Psi(x,t)}^2 dx\) is a constant. But we know that \( \int_{-\infty}^{\infty}   \abs{\Psi(x,t)}^2 dx\) at \(t = 0\) is 1. Therefore the wavefunction remains normalized all the time.}		\todo{1.5}
		
\example{Effect to the Wavefunction by adding a Constant Potential.}
{Show that the effect of adding a constant potential \(V_0\) introduce an extra phase \(V_0 t /h\) to the wavefunction.}
{By substituting \( \Psi_0 = \Psi e^{-i V_0 \hbar /t}\) into the \screq with potential \(V + V_0\), where \(\Psi\) satisfies the normal \screq with potential \(V\), we can verfify that \(\Psi_0\) indeed satisfies the modified \screq: 
			
\begin{equation}
	\begin{aligned}
		i \hbar \frac{\partial \Psi_0}{\partial t} & =i \hbar \frac{\partial \Psi}{\partial t} e^{-i V_0 t / \hbar}+i \hbar \Psi\left(-\frac{i V_0}{\hbar}\right) e^{-i V_0 t / \hbar} \\ &=\left[-\frac{\hbar^2}{2 m} \frac{\partial^2 \Psi}{\partial x^2}+V \Psi\right] e^{-i V_0 t / \hbar}+V_0 \Psi e^{-i V_0 t / \hbar} =-\frac{\hbar^2}{2 m} \frac{\partial^2 \Psi_0}{\partial x^2}+\left(V+V_0\right) \Psi_0 .
	\end{aligned}
\end{equation}
		
This, however has no effect on the average value of other dynamical variables such as momentum as the extra phase is independent of \(x\), so it vanishes after the absolute value of the wavefunction is taken.}
		
\example{Potential for a Wavefunction.}
{Consider the wavefunction \(\Psi = Ae^{-a(mx^2 / \hbar ) + it}\). Find \(V(x)\) such that this is a solution to \screq. Then confirm the uncertainty principle by calculating \(\sigma_x \text { and }  \sigma_p\).}
{From the wavefunction given, we obtain
			
\begin{equation}
  \frac{\partial \Psi }{\partial t} = -ia\Psi , \quad  \frac{\partial \Psi }{\partial t} = -\frac{2amx}{\hbar }\Psi    
\end{equation}

and
		
\begin{equation}
  \frac{\partial^2 \Psi }{\partial x^2} = -\frac{2am}{\hbar }\left(\Psi + x\frac{\partial \Psi }{\partial x} \right) = -\frac{2am}{\hbar }\left(1-\frac{2amx^2 }{\hbar } \right)\Psi .  
\end{equation}
		
From the \screq, we have 
		
\begin{equation}
  V\Psi = i\hbar\pdv{\Psi}{t} + \frac{\hbar^2}{2m}\pdv[2]{\Psi}{x} = i\hbar(-ia\Psi) + \frac{\hbar^2}{2m}\left(-\frac{2am}{\hbar}\right)\left(1-\frac{2amx^2}{\hbar}\Psi\right) = 2a^2mx^2\Psi.
\end{equation}
		
		
So \(V(x) = 2ma^2x^2\).
		
To obtain \(\sigma_x\) and \(\sigma_p\), we have to first normalize the function by requiring

\begin{equation}
  \int_{-\infty}^{\infty} \abs{\Psi (x,t)}^2 dx = \abs{A} ^2  \int_{-\infty}^{\infty} e^{-\frac{2amx^2 }{\hbar } } dx = \abs{A} ^2 \sqrt{\frac{\pi \hbar }{2am} }     
\end{equation}

since the absolute value of \(Aee^{i \theta }\) is simply \(A\). So \( A = (2am /\pi \hbar )^{\frac{1}{4} }\).
		
Now \(\avg{x}, \avg{x^2}, \avg{p}\) and \(\avg{p^2}\) can be straightforwardly calculated from integrations to get \(\avg{x} = \avg{p} = 0\) as expected, \(\avg{x^2} = \hbar / 4am\) and \(\avg{p^2} = am\hbar\).
		
Therefore 

\begin{equation}
  \sigma_x = \sqrt{\avg{x^2} - \avg{x}^2} = \sqrt{\frac{\hbar}{4am}}, \quad \sigma _{p} = \sqrt{\avg{p^2}-\avg{p}^2  } = \sqrt{am \hbar } \implies \sigma _{x}\sigma _{p} = \frac{\hbar }{2},       
\end{equation}

which is just consistent with the uncertainty principle.}

\section{The Copenhagen interpretation}
	
In this set of notes, we adopt the Copenhagen interpretation of quantum mechanics, as it is the most widely recognized view in today's physics's landscape. 

According to this view, as long as nothing tries to interact with the particle, it is on every possible position allowed by its wavefunction each with the probability \(\abs{\Psi(x,t)}^2 dx\) for position located between \(x\) and \(x + dx\). Upon measurement, however, the wavefunction collapses.

Here, we have to be very careful with the term ``measurement'' and ``collapses''. A ``measurement'' is broadly defined as any interaction with the wavefunction that eliminate some possibilities of its possible location. ``Collapses'' thus implies some possible positions of electrons are eliminated.

In ideal case, the wavefunction is localized at a point in space and becomes a dirac delta function. Soon, however, it spreads out according to the Schrödinger equation. In other cases, however, the wavefunction \href{https://arxiv.org/pdf/2106.00466}{partially collapses} and we are only certain that the particle is located at a certain range of positions bit and also not located at a certain range of positions.

This idea is best illustrated by the double slit experiment: \onefig{double_slit}{width=\textwidth}

Consider one electron\footnote{Here electron is just a replacement of photon just to illustrates the fact that any particle is a wave.} that is emitted by the source. When its wavefunction reaches the slits, the wavefunction evolves as shown in \cref{double_slit}. If we probe the intermediate screen (where the slits are located), the wavefunction will collapses to either state: 

\begin{enumerate}
  \item a state where the particle hits the intermediate screen and we see a spot on the intermediate screen, or
  \item a state where the electron passes through the slits.
\end{enumerate}

In the latter state, however, we still have no idea which slit the electron has passed through, therefore the electron is still simultaneously passing through both slits. Then, from the Huygen's principle we can regard the wavefunction as two secondary waves with origin located at the slits. These two waves superpose each other and thus at the screen, the wavefunction looks like an diffraction plus an interference pattern (\(\Psi\) in this case is analogous to \(E\) in optic's interference). If the electron random picks a position according to this probability distribution function, then as the number of electrons emitted becomes sufficiently large, an interference pattern will be shown on the screen.

However, by measuring which slit the electron goes through, the wavefunction of the electron becomes only one secondary wave with origin located at one of the slit. And the resulting wavefunction at the screen for the electron will be reminiscent of the diffraction pattern in ordinary optics without interference. As the number of electrons becomes sufficiently large, then an overlapping pattern (superposition) of diffraction from the two slits will be shown on screen.

From a mathematical standpoint, the dispcrepancy arise from the fact that \(\abs{\Psi_1 + \Psi_2}^2 \neq \abs{\Psi_1}^2 + \abs{\Psi_2}^2\). In optics, this is analogous to the fact that the last term in \(I_{12} = I_1 + I_2 + 2\sqrt{I_1I_2} \cos(\phi_2 - \phi_1)\) doesn't exist when there is no interference. 

From a philosophical standpoint, this result has profound impact on how observation correlates to reality. This quantum effect begs to answer the famous philosophical question ``If a tree falls in a forest and no one is around to hear it, does it make a sound?''. And the answer seems to be that as long as we are not certain that something happen (upon measurement), every possibilities remain possible. During the flight of the electron, it must have collided with some air particles in its way that forces it to localize at a point. However, as long as we don't probe the air particles, we don't know whether that have been collided with the electron and thus the electron remains in all possible paths.

\section{Momentum and Hamiltonian Operators}
	
The expected value of momentum \(\avg{p} \) can be defined identically as in classical mechanics as \(\avg{p} =m\avg{v} =md \avg{x} /dt\), where \(d \avg{x} /dt \) can be computed straightforwardly as 
	
\begin{equation}
  \begin{aligned}
    \frac{ d\avg{x} }{ dt} &= \int_{-\infty}^{\infty} \frac{\partial }{\partial t} x \abs{\Psi }^2 dx = \frac{i\hbar }{2m} \int_{-\infty}^{\infty} x \frac{\partial }{\partial x} \left(\Psi ^* \frac{d\Psi}{dx} \right)dx \\ &= -\frac{i\hbar }{2m} \int_{-\infty}^{\infty} \left(\Psi ^* \frac{ d\Psi }{ dx} - \Psi \frac{ d\Psi ^*}{ dx} \right) dx = -\frac{i\hbar }{m} \int_{-\infty}^{\infty} \Psi ^* \frac{\partial \Psi }{\partial x} dx,          
  \end{aligned}
\end{equation}
	
where we used the result in \cref{ddtpsi2} in the second equality and have performed integration by part twice at the end.
	
Therefore,

\begin{equation}
  \avg{p} = \int_{-\infty}^{\infty} \Psi ^* \left[-i\hbar \frac{\partial }{\partial x} \right] \Psi dx.
\end{equation}

and \(-i\hbar \partial / \partial x \) is called the momentum operator. 

Together with the position operator (which is simply \(x\)) that calculates the expected position of the particle, for any quantity \(Q(x,p)\) that is a function of the position and the momentum, such as angular momentum and kinetic energy, the expected value or the average value can be simply calculated by 
	
\begin{equation}
  \avg{Q(x,p)} = \int_{-\infty}^{\infty} \Psi ^* \left[\hat{Q} \left(x, -i\hbar \frac{\partial }{\partial x} \right)\right] \Psi dx, \label{expectedvalues} 
\end{equation}

where \(\hat{Q}\) is the corresponding operator, which is just \(Q\) but with momentum \(p\) replaced by the momentum operator \( -i \hbar \partial /\partial x \).   

For example, the total energy (or the Hamiltonian) of a particle with momentum \(p\) at position \(x\) is given by \( H(x,p) = p^2 /2m + V(x) \), so the corresponding Hamiltonian operator is \( \hat{H} = - (\hbar ^2 /2m )\partial ^2 / \partial x^2 +V(x)\) and the expected value of the total energy is 

\begin{equation}
  \avg{H(x,p)} = \int \psi ^* \left[ - \frac{\hbar ^2}{2m}\frac{\partial^2 }{\partial x^2} +V(x) \right]\psi dx. \label{Hamil} 
\end{equation}


\example{Ehrenfest's Theorem.}
{Calculate \(\partial \avg{p} /\partial t  \).}
{Since 
		
\begin{equation}
	\begin{aligned}
		\frac{\partial}{\partial t}\left(\Psi^* \frac{\partial \Psi}{\partial x}\right) & =\frac{\partial \Psi^*}{\partial t} \frac{\partial \Psi}{\partial x}+\Psi^* \frac{\partial}{\partial x}\left(\frac{\partial \Psi}{\partial t}\right) \\
		& =\left[-\frac{i \hbar}{2 m} \frac{\partial^2 \Psi^*}{\partial x^2}+\frac{i}{\hbar} V \Psi^*\right] \frac{\partial \Psi}{\partial x}+\Psi^* \frac{\partial}{\partial x}\left[\frac{i \hbar}{2 m} \frac{\partial^2 \Psi}{\partial x^2}-\frac{i}{\hbar} V \Psi\right] \\
		& =\frac{i \hbar}{2 m}\left[\Psi^* \frac{\partial^3 \Psi}{\partial x^3}-\frac{\partial^2 \Psi^*}{\partial x^2} \frac{\partial \Psi}{\partial x}\right]+\frac{i}{\hbar}\left[V \Psi^* \frac{\partial \Psi}{\partial x}-\Psi^* \frac{\partial}{\partial x}(V \Psi)\right],
	\end{aligned}
\end{equation}
		
Therefore

\begin{equation}
  \begin{aligned}
      \frac{\partial \avg{p}}{\partial t} &= -i\hbar \int_{-\infty}^{\infty} \frac{\partial}{\partial t} \left(\Psi^* \frac{\partial \Psi}{\partial x} \right) dx \\ 
      &= -i\hbar \int_{-\infty}^{\infty} \left( \frac{i\hbar}{2m} \left[ \Psi^* \frac{\partial^3 \Psi}{\partial x^3} - \frac{\partial^2 \Psi^*}{\partial x^2} \frac{\partial \Psi}{\partial x} \right] 
      + \frac{i}{\hbar} \left[ V \Psi^* \frac{\partial \Psi}{\partial x} - \Psi^* \frac{\partial}{\partial x}(V \Psi) \right] \right) dx \\ 
      &= (-i\hbar) \left( \frac{i\hbar}{2m} \right) 
      \left( \eval{\Psi^* \frac{\partial^2 \Psi}{\partial x^2}}_{-\infty}^{+\infty} 
      - \left( \eval{\frac{\partial \Psi^*}{\partial x} \frac{\partial \Psi}{\partial x}}_{-\infty}^{+\infty} 
      - \int_{-\infty}^{\infty} \frac{\partial^2 \Psi^*}{\partial x^2} \frac{\partial \Psi}{\partial x} dx \right) \right. \\ 
      & \quad \left. - \int_{-\infty}^{\infty} \frac{\partial^2 \Psi^*}{\partial x^2} \frac{\partial \Psi}{\partial x} dx \right) 
      + (-i\hbar) \left( \frac{i}{\hbar} \right) 
      \int_{-\infty}^{\infty} \left( V \Psi^* \frac{\partial \Psi}{\partial x} + \Psi \frac{\partial V}{\partial x} \right) dx \\ 
      &= 0 + \int_{-\infty}^{\infty} -\Psi \Psi^* \frac{\partial V}{\partial x} dx = \left \langle {-\frac{\partial V}{\partial x} } \right \rangle. 
  \end{aligned}
  \end{equation}
	
which is almost identical to the classical result that predicts 

\begin{equation}
  \frac{\partial \avg{p} }{\partial x} = -\frac{\partial }{\partial x} V(\avg{x} ) 
\end{equation}

according to Ehrenfest's theorem.}
	
\example{Classical Formalism of Quantum Mechanics.}
{In this question, we try to model the behaviour of wavefunction with classical formalism. Consider a classical particle with energy \(E\) in a potential well \(V(x)\) of the case of simple harmonic oscillator where \(V(x) = \frac12 kx^2\) and find \(\rho(x),\rho(p), \avg{x^2}, \avg{p^2}, \sigma_x\) and \(\sigma_p\), where \(\rho(x)dx\) and \(\rho(p)dp\) are the probability of the particle located at \(x\) and have the a momentum \(p\) if we choose a random instant.}
{The speed of the particle is
	
\begin{equation}
  V(x) = \sqrt{\frac{2}{m} (E - V(x))} = \sqrt{\frac{2}{m} (E - \frac{1}{2} kx^2 )}.  
\end{equation}
		
The period of the particle is  \(T = 2\pi \sqrt{m /k}\).
		
So the probability density function \(\rho(x)\) can be found by
		
\begin{equation}
  \rho (x) dx = \frac{dt}{\frac{T}{2} } = \frac{2dx}{v(x)T}  
\end{equation}
		
If we let \(-a\) and \(a\) to be the end points of the particle, then \(E =  ka^2 /2\) and
		
\begin{equation}
  \rho (x) = \frac{2}{T} \frac{1}{\sqrt{\frac{2}{m} \left(E - \frac{1}{2} kx^2 \right)} } = \frac{1}{\pi \sqrt{b^2 -x^2 } }.  
\end{equation}

So 
		
\begin{equation}
  \avg{x^2 } = 2\int_{0}^{a} \frac{x^2 dx}{\pi \sqrt{b^2 -x^2 } } =  \frac{E}{k}    
\end{equation}

and 

\begin{equation}
  \sigma _{x} = \sqrt{\avg{x^2 } - \avg{x} ^2  } = \sqrt{\avg{x^2 } } = \sqrt{\frac{E}{k} }.   
\end{equation}

For the probability density function of with respect to momentum \(\rho(p)\), 

\begin{equation}
  \rho (p)dp = \frac{dt}{T}  = \frac{dx}{v(x)T}.
\end{equation}}

\todo{Quantum entaglement is not ``affect'', since it is based on conservation law, if one up the other must be down, but state of anyone of them not known beforehand.
} 



\chapter{Separation of Variables}

\section{The General Approach}

To solve for the wavefunction of a particle, we look for the solution in the form of 

\begin{equation}
  \Psi (x,t) = \psi (x)\varphi (t).
\end{equation}

Substituting into the Schrödinger equation and divide through \(\Psi = \psi \varphi\), we have

\begin{equation}
  i \hbar \frac{1}{\varphi } \frac{d\varphi }{dt} = -\frac{\hbar ^2}{2m} \frac{1}{\psi } \frac{d^2\psi }{dx^2} + V.    
\end{equation}

Since the LHS and RHS of the above equation is a function of \(t \text { and } x\) alone, respectively, they must a constant of \(t \text { and } x\), which we call it \(E\) (for it is actually the energy of the particle). We thus have, for \(t\) dependence

\begin{equation}
  i \hbar \frac{1}{\varphi } \frac{d\varphi }{dt} = E \implies \varphi (t) = e^{-iEt /\hbar  },
\end{equation}

which we will refer it to the wiggle factor. For the \(x\) dependence we have to solve for \(\psi (x)\) in the time independent Schrödinger equation

\begin{equation}
  - \frac{\hbar ^2}{2m} \frac{d^2\psi }{dx^2} + V\psi = \hat{H}\psi = E\psi, \label{psix} 
\end{equation}

where \(\hat{H}\) is the Hamiltonian operator defined in \cref{Hamil}.

There are a few properties of of separable solutions that make them special. Firstly, the probability density of the position 

\begin{equation}
  \abs{\Psi (x,t)}^2 = \Psi ^*\Psi = \psi ^* e^{+iEt /\hbar  }\psi e^{-iEt /\hbar  } = \abs{\psi (x)}^2
\end{equation}

is independent of time, and so does any expected values which are functions of position and momentum from \cref{expectedvalues}.

Secondly, the total energy is definite. With \cref{psix} in hand, the expected value of the total energy is 

\begin{equation}
  \avg{H} = \int \psi ^* \hat{H} \psi dx = E \int \abs{\psi }^2 dx = E \int \abs{\Psi }^2 dx = E.  
\end{equation}

By computing the expected value of \(H^2\), which is \(\avg{H^2} = E^2 \), one can conclude that the variance of \(H\)

\begin{equation}
  \sigma _{H}^2 = \avg{H^2} - \avg{H}^2 = E^2- E^2 = 0,
\end{equation}

which means that every measurement of the total energy is certain to return the value \(E\).

Lastly, the general solution of \(\Psi (x,t)\) is a linear combination of the separable solutions, each with its own allowed energy \(E_{n} \) 

\begin{equation}
  \Psi (x,t) = \sum_{n=1}^{\infty} c_{n}\psi _{n}(x) e^{-iE_{n}t /\hbar   }, \label{Psix} 
\end{equation}

where the linearity coefficients \(c_{n} \) can be found by expanding the initial condition \(\Psi (x,0)\) in the \(\psi _{n}(x) \) basis and comparing the coefficients, also known as the Fourier's trick, as

\begin{equation}
  c_{n} = \int \Psi _{n}(x,0)^* \Psi (x,0) dx,  
\end{equation}

since the functions \(\Psi _{n}(x,0) \) are orthogonal (so all expansion terms integrate to zero except \(n\)) and complete (so that \(\Psi (x,0)\) can be expressed in terms of \(\psi _{n}(x) \)).

Futhremore, we have

\begin{equation}
  \begin{aligned}
    1 &= \int \abs{\Psi (x,0)}^2dx = \int \left( \sum_{m=1}^{\infty}c_{m}\psi _{m}(x)\right)^*\left( \sum_{n=1}^{\infty}c_{n}\psi _{n}(x)\right) dx \\ &= \sum_{m=1}^{\infty}\sum_{n=1}^{\infty}c_{m}^*c_{n}\int \psi _{m}(x)^*\psi _{n}(x)dx \\ &= \sum_{n=1}^{\infty}\sum_{m=1}^{\infty}c_{m}^*c_{n}\delta _{mn}= \sum_{n=1}^{\infty}\abs{c_{n} }^2,       
  \end{aligned}
\end{equation}

and  

\begin{equation}
  \begin{aligned} 
    \avg{H} &= \int \Psi ^* \hat{H} \Psi dx = \int \left( \sum_{m=1}^{\infty}c_{m}\psi _{m}   \right) ^*  \hat{H} \left( \sum_{n=1}^{\infty}c_{n}\psi _{n}    \right) dx \\ &= \sum_{n=1}^{\infty}\sum_{m=1}^{\infty}c_{m}^*c_{n}E_{n}\int \psi _{m}^*\psi _{n}dx = \sum_{n=1}^{\infty}\abs{c_{n} }^2E_{n}.          
  \end{aligned} 
\end{equation}

Thus \(\abs{c_{n} }^2 \) is the probability that a measurement of the energy would return the value \(E_{n} \).\footnote{It is incorrect to say that \(\abs{c_{n} }^2\) is the probability that the particle is in the \(n^{\text{th}} \) stationary state, since the particle is in state \(\Psi \), but not \(\Psi _{n} \), so you never find the particle to be in a particular state, you only measure some observable quantities such as the energy of the particle, a number, but not a wavefunction.} 

\example{Neutrino Oscillation.}
{Consider a system with only two linearly independent states 

\begin{equation}
  \ket{x_1} = \begin{pmatrix}
     1 \\
     0 \\
  \end{pmatrix} ~\text { and }~ \ket{x_2} = \begin{pmatrix}
     0 \\
     1 \\
  \end{pmatrix}, 
\end{equation}

where \(\ket{1} \) represents the electron neutrino and \(\ket{2} \) the muon neutrino. 

\(\ket{x_1} \text { and } \ket{x_2 }  \) are called the computational basis, and is simply an arbitrary orthonormal basis. It is only simply for simplicity, without the loss of generality that we assign \(\ket{x_1} \text { and } \ket{x_2 }  \) their physical meaning 

The Hamiltonian can be expressed as a hermitian matrix 

\begin{equation}
  H = \begin{pmatrix}
    h &  g \\
    g &  h \\
  \end{pmatrix},
\end{equation}

since we are dealing with finite-dimesional space. 

If the system starts out in state \(\ket{1} \), \textit{i.e.,} \(\ket{\mathcal{S}(0)} = \ket{x_1}  \). Find \(\ket{\mathcal{S}(t)} \).  
}
{We begin by finding the energy eigenstates from the eigenequation

\begin{equation}
  \hat{H} \ket{E_{n} } = E_{n} \ket{E_{n} }.  
\end{equation}

The eigenvalues of the Hamiltonian matrix are \(h \pm g\), so the normalized eigenvectors are 

\begin{equation}
  \ket{E_{1} } = \frac{1}{\sqrt{2} } \begin{pmatrix}
     1 \\
     1 \\
  \end{pmatrix} ~\text { and }~ \ket{E_2 } = \frac{1}{\sqrt{2} } \begin{pmatrix}
     1 \\
     -1 \\
  \end{pmatrix}.  
\end{equation}

Exapnding the intial state as a linear combination of the energy eigenstates, we have 

\begin{equation}
  \ket{\mathcal{S}(0)} = \frac{1}{\sqrt{2} } \left( \ket{E_1 } + \ket{E_2 }   \right).  
\end{equation}

Finally we just tack on the wiggle factors to obtain 

\begin{equation}
  \ket{\mathcal{S}(t) } = \frac{1}{\sqrt{2}} \left( e^{-i(h+g)t /\hbar } \begin{pmatrix}
     1 \\
     1 \\
  \end{pmatrix} + e^{-i(h-g)t /\hbar } \begin{pmatrix}
     1 \\
     1 \\
  \end{pmatrix}   \right) = e^{i h t/\hbar } \begin{pmatrix}
     \cos (gt /\hbar ) \\
     -i \sin (gt /\hbar ) \\
  \end{pmatrix}  .
\end{equation}~
} 

\section{Infinite Square Well}

Suppose we have the potential 

\begin{equation}
  V(x) =
  \begin{cases} 
  0, & 0 \leq x \leq a, \\
  \infty, & \text{otherwise}.
  \end{cases}
\end{equation}

Outside the well, \(\psi (x) = 0\). Inside the well, \cref{psix} reads 

\begin{equation}
  \frac{d^2\psi }{dx^2} = -k^2\psi , \quad  k \equiv \frac{\sqrt{2mE} }{\hbar }, \label{free} 
\end{equation}

where we have subtly assumed that \(E \ge 0\).  

Together with the boundary conditions \(\psi (0) = \psi (a) = 0\), the solution is  

\begin{equation}
  \psi _{n} (x) = A\sin (k_{n} x), \quad k_{n} = \frac{n\pi }{a}, \quad n = 1,2,3,\ldots 
\end{equation}

Curiously, the boundary condition at \(x = a\) does not determine the constant \(A\), but rather the constant \(k\), and hence the possible values of \( E_{n} = n^2\pi ^2\hbar ^2 /2ma^2\).

To find \(A\), we normalize \(\Psi \) (or \(\psi \) since the wiggle factor contribute nothing) 

\begin{equation}
  \int_{0}^{a} \abs{A}^2 \sin ^2(kx) dx = \frac{a}{2} \abs{A}^2  = 1 \implies A = \sqrt{\frac{2}{a} }.      
\end{equation}

The complete solution is therefore

\begin{equation}
  \Psi (x,t) = \sum_{n=1}^{\infty} c_{n} \sqrt{\frac{2}{a} } \sin \left( \frac{n\pi }{a}x  \right) e^{-i n^2\pi ^2\hbar t /2ma^2}, \quad c_{n} = \sqrt{\frac{2}{a} } \int_{0}^{a} \sin \left( \frac{n\pi }{a}x  \right)\Psi (x,0)dx.    
\end{equation}



\section{Harmonic Oscillator}

Suppose the potential is now 

\begin{equation}
  V(x) = \frac{1}{2}m \omega ^2x^2. 
\end{equation}

From \cref{psix} we now have

\begin{equation}
  - \frac{\hbar ^2}{2m}\frac{d^2\psi }{dx^2} + \frac{1}{2}m \omega ^2x^2\psi = E\psi . \label{harmonic} 
\end{equation}

There are two ways which we can solve this Schrödinger equation, namely the algebraic method and the analytic method.

\subsection{Algebraic Method}

To solve the Schrödinger equation, we first rewrite \cref{harmonic} as 

\begin{equation}
  \frac{1}{2m}\left( \hat{p}^2 + (m \omega x)^2\right)\psi = \hat{H} \psi = E\psi . 
\end{equation}

The idea now is to factorize the Hamiltonian, by introducing the ladder operators

\begin{equation}
  \hat{a} _{\pm } \equiv \frac{1}{\sqrt{2 \hbar m \omega } } (\pm i \hat{p} +m \omega x),\footnote{The motivation is that \(u^2+v^2 = (iu+v)(-iu-v)\) can be easily factorized, but now we extend this to operators.} 
\end{equation}

whose product is 

\begin{equation}
  \hat{a} _{\pm }\hat{a} _{\mp} = \frac{1}{2 \hbar m \omega }( \hat{p} ^2 + (m \omega x)^2) \pm  \frac{i}{2 \hbar }[x, \hat{p} ] = \frac{1}{\hbar \omega }\hat{H} \mp \frac{1}{2}.    
\end{equation}

So the Schrödinger equation becomes 

\begin{equation}
  \hbar \omega \left( \hat{a} _{\pm }\hat{a} _{\mp} \pm \frac{1}{2}    \right) \psi = E\psi . \label{Agen1} 
\end{equation}

Writing the Schrödinger equation in this form, we can see that if \(\psi \) satisifies the Schrödinger equation with energy \(E\), then \(\hat{a} _{\pm }\psi  \) satisfies the Schrödinger equation with energy \(E \pm \hbar \omega \), since

\begin{equation}
  \begin{aligned} 
    \hat{H} (\hat{a} _{\pm } \psi ) &= \hbar \omega \left( \hat{a} _{\pm }\hat{a} _{\mp} +\frac{1}{2}    \right) (\hat{a} _{\pm }\psi ) = \hbar \omega \left( \hat{a} _{\pm }\hat{a} _{\mp}\hat{a} _{\pm } + \frac{1}{2} \hat{a} _{\pm } \right) \psi \\ &= \hbar \omega \hat{a} _{\pm }\left( \hat{a} _{\mp}\hat{a} _{\pm } + \frac{1}{2}    \right) \psi = \hat{a} _{\pm } \left( \hbar \omega \left( \hat{a} _{\pm }\hat{a} _{\mp} + 1 + \frac{1}{2}    \right) \psi \right) \\ &= \hat{a} _{\pm } (\hat{H} + \hbar \omega )\psi = \hat{a} _{\pm }(E+\hbar \omega )\psi = (E+\hbar \omega )(\hat{a} _{\pm }\psi  ),
  \end{aligned} 
\end{equation}

where in the last equality of the second line we used that fact that \(\hat{a} _{\mp} \hat{a} _{\pm } = \hat{a} _{\pm } \hat{a} _{\mp} + 1\), since \([\hat{a} _{-}, \hat{a} _{+}  ] = 1\).  

This means that as long as we find one solution, we can find all the solutions using the ladder operators \(\hat{a} _{\pm } \). Of course, we will not be able to apply the lowering operator \(\hat{a} _{-} \) repeatedly to reach a state with energy less than zero. There occurs a lowest energy state (called the ground state) \(\psi _{0} \) such that 

\begin{equation}
  \hat{a} _{-}\psi _{0} = 0 \implies \psi _{0} = Ae^{-m \omega x^2/2\hbar  } = \left( \frac{m \omega }{\pi \hbar }  \right)^{\frac{1}{4} } e^{-m \omega x^2/2 \hbar },
\end{equation}

which corresponds the state with energy \( E_{0} = \hbar \omega /2  \), and we would only get \(\psi =0\)  no matter how many times we apply the lowering operator \(\hat{a} _{-} \) to \(\psi _{0} \).

With our foot now planted on the ground state, the solution of the Schrödinger equation is now clear as

\begin{equation}
  \psi _{n}(x) = A_{n} (\hat{a} _{+} )^{n} \psi _{0}(x), \quad E_{n} = \left( n+\frac{1}{2}  \right)\hbar \omega . \label{Agen2} 
\end{equation}

To find \(A_{n} \), we first note that \(\hat{a} _{\pm } \) are hermitian conjugate of each other, this is because

\begin{equation}
  \hat{a} _{+}{}^{\dagger}  = \frac{1}{\sqrt{2 \hbar m \omega } } (i \hat{p} + m \omega x){}^{\dagger}  = \frac{1}{\sqrt{2\hbar m \omega } } (-i \hat{p} + m \omega x) = \hat{a}  _{-},  
\end{equation}

where \(\hat{p} {}^{\dagger} = \hat{p} \text { and } x^{\dagger} = x\), since \(x \text { and } p\) are observable so their operators are hermitian.  

From \cref{herm1} and \cref{herm2}, we have 

\begin{equation}
  \hat{a} _{+} \hat{a} _{-} \psi _{n} = n \psi _{n} ~\text { and }~ \hat{a} _{-}\hat{a} _{+ }\psi _{n} = (n+1)\psi _{n},        
\end{equation}

so 

\begin{equation}
  \begin{aligned} 
  \braket{\hat{a} _{+}\psi _{n}  }{\hat{a} _{+}\psi _{n}  } &= \abs{A_{n+1} }^2 \braket{\psi _{n+1} }{\psi _{n+1} } = \abs{A_{n+1} }^2  = \braket{\hat{a} _{-}\hat{a} _{+}\psi _{n}   }{\psi _{n} } = (n+1) \braket{\psi _{n} }{\psi _{n} } = n+1, ~\text { and }~ \\
  \braket{\hat{a} _{-}\psi _{n}  }{\hat{a} _{-}\psi _{n}  } &= \abs{A_{n-1} }^2 \braket{\psi _{n-1} }{\psi _{n-1} } = \abs{A_{n-1} }^2  = \braket{\hat{a} _{+}\hat{a} _{-}\psi _{n}   }{\psi _{n} } = n \braket{\psi _{n} }{\psi _{n} } = n.
  \end{aligned} 
\end{equation}

Clearly we have \(A_{n} = \sqrt{n!}  \) and the genearl solution is therefore

\begin{equation}
  \begin{aligned} 
  \Psi (x,t) &= \sum_{n=1}^{\infty} c_{n}\frac{1}{\sqrt{n!} } (\hat{a} _{+} )^{n} \left( \frac{m \omega }{\pi \hbar }  \right)^{\frac{1}{4} } e^{- m \omega x^2/2 \hbar }   e^{-i(n+1/2)\omega t}, \\
  c_{n} &= \frac{1}{\sqrt{n!} } \left( \frac{m \omega }{\pi \hbar }  \right)^{\frac{1}{4} } \int_{-\infty}^{+\infty} (\hat{a} _{+} )^{n} e^{- m \omega x^2/2 \hbar } \Psi (x,0)dx.
  \end{aligned}         
\end{equation}

For the sake of completeness we show that the stationary states of the harmonic oscillator are indeed orthogonal, although it is already proved more generally in the previous chapter for all stationary states

\begin{equation}
  \braket{\psi _{m} }{\hat{a} _{+}\hat{a} _{-} \psi _{n}   } = n \braket{\psi _{m} }{\psi _{n} } = \braket{\hat{a} _{+} \psi _{m}  }{\hat{a} _{-} \psi _{n}  } = \braket{\hat{a} _{-} \hat{a} _{+} \psi _{m}  }{\psi _{n} } = m \braket{\psi _{m} }{\psi _{n} },     
\end{equation}

so unless \(m = n\), then \(\braket{\psi _{m} }{\psi _{n} } = 0 \).

\example{Average Potential Energy of the Harmonic Oscillator.}
{Find the expectation value of the potential energy in the \(n^{\text{th}} \) stationary state of the harmonic oscillator. }
{The averge optential energy is 

\begin{equation}
  \left \langle {V} \right \rangle = \left \langle {\frac{1}{2}m \omega ^2x^2 } \right \rangle = \frac{1}{2}m \omega ^2 \int_{-\infty}^{+\infty} \psi _{n}^* x^2 \psi _{n} dx.    
\end{equation}

To evaluate integrals involving powers of \(x \text { or } \hat{p}  \), we can use 

\begin{equation}
  x = \sqrt{\frac{\hbar }{2m \omega } } (\hat{a} _{+} + \hat{a} _{-}  ) ~\text { and }~ \hat{p} = i \sqrt{\frac{\hbar m \omega }{2} } (\hat{a} _{+} - \hat{a} _{-}  ). 
\end{equation}

So the integral becomes 

\begin{equation}
  \left \langle {V} \right \rangle = \frac{\hbar \omega }{4} \int_{-\infty}^{+\infty} \psi _{n}^* \left( \left( \hat{a} _{+}  \right)^2 + (\hat{a} _{+}\hat{a} _{-}  ) + (\hat{a} _{-}\hat{a} _{+}  ) + (\hat{a} _{-} )^2 \right) \psi _{n}dx.
\end{equation}

But \((\hat{a} _{+}^2 )\psi _{n} \text { and }  (\hat{a} _{-} )^2 \) are orthogonal to \(\psi _{n} \), so the remaining terms integrate to 

\begin{equation}
  \left \langle {V} \right \rangle = \frac{\hbar \omega }{4} (n + n + 1) = \frac{1}{2} \hbar \omega \left( n + \frac{1}{2}  \right) .
\end{equation}

} 

\subsection{Analytic Method}

First we introudce the dimensionless variable \(\xi \text { and } K\) to rewrite the Schrödinger equation as

\begin{equation}
  \frac{d^2\psi }{d\xi ^2} = \left( \xi ^2 - K \right) \psi , \quad \xi \equiv  \sqrt{\frac{m \omega }{\hbar } } x ~\text { and }~  K \equiv \frac{2E}{\hbar \omega }.   
\end{equation}

To solve this equation we first note that for \(\xi ^2 \gg K\) we have \(d^2 \psi / d \xi ^2 \approx \xi ^2\psi \), so we have \(\psi (\xi ) \to (\cdot )e^{-\xi ^2/2} \) at large \(\xi\) (the positive exponential term is neglected since it can't be normalized). Thus we propose 

\begin{equation}
  \psi (\xi ) = h(\xi ) e^{- \xi ^2 /2}, \quad h(\xi ) = a_0  + a_1 \xi + a_2 \xi ^2 + \cdots = \sum_{j=0}^{\infty} a_{j}\xi ^{j}.   
\end{equation}

Upon substitution we find

\begin{equation}
  \frac{d^2h}{d\xi ^2} - 2\xi \frac{dh}{d\xi } + (K-1) h = 0 = \sum_{j=0}^{\infty} \left( (j+1)(j+2)a_{j+2} - 2a_{j} + (K-1)a_{j}    \right) \xi ^{j}.  
\end{equation}

From the uniqueless of power series expansion,\footnote{In other words, since \(\xi ^{j} \) forms a basis in the polynomial space, if the vector is equals to zero each individual component must be equals to zero.} the coefficient of each power of \(\xi \) must vanish, hence

\begin{equation}
  a_{j+2} = \frac{(2j + 1 - K)}{(j+1)(j+2)}a_{j}.
\end{equation}

Thus we can determine \(h(\xi )\) from just tow arbitrary constants \(a_0 \text { and } a_1 \) as all other coefficients can be found using the above recursion formula.  

For \(\psi (\xi )\) to be normalizeable, however, the power series must terminate at some \(j = n\), which means that either \(a_1 \text { or } a_0 \) = 0, and

\begin{equation}
  2j+1 = K ~\text { or }~ E_{n} = \left( n + \frac{1}{2}  \right) \hbar \omega .
\end{equation}

It seems at first rather surprising that the quantization of energy should emerge from a technical detail in the power series solution to the Schrödinger equation. In fact, for any value of \(E\), it has two linearly independent solutions but almost all of these solutions blow up exponentially at large \(x\), and hence are not normlizable. Only when \(E_{n}\) satisfies the above equation does they converge at large \(x\).   

\section{The Free Particle}

Now we consider the case where \(V(x) = 0\) everywhere. The Schrödinger equation is the same as \cref{free}

\begin{equation}
  \frac{d^2\psi }{dx^2} = -k^2 \psi , \quad k \equiv \frac{\sqrt{2mE} }{\hbar } \implies \psi _{k} (x) = Ae^{ikx} + Be^{-ikx}, \label{freee} 
\end{equation}

Tackling on the wiggle factors, 

\begin{equation}
  \Psi _{k} (x,t) = Ae^{ik (x - \hbar kt/2m)} + Be^{-ik (x+ \hbar kt /2m)},
\end{equation}

which is a linaer combination of two waves travelling in opposite directions.

Note that now there are no boundary conditions to fix the values of \(A \text { or } B\), this problem also makes the wavefunction non-normalizable, since it contains an exponentially increasing term. In fact, this means that there is no such thing as a free particle with a definite energy.  

Although unlike the discrete index \(n\) in previous examples, the continuous variable \(k\) now can take on any values, but the complete solution is still the linear combination of the ``stationary solutions''. To do this we replace the discrete sum by a integral so the general solution is 

\begin{equation}
  \Psi (x,t) = \frac{1}{\sqrt{2\pi } } \int_{-\infty}^{+\infty} \phi (k) e^{i(kx - \hbar k^2 t/2m)}dk,   
\end{equation}

where we merged the two terms in the ``stationary solution'' by allowing \(k\) to goes from \(-\infty\) to \(+\infty\). 

The \(1 / \sqrt{2\pi }  \) factor is pulled out for convenience. What plays the role of the coefficient \(c_{n} \) in previous examples is now the combination \((1/\sqrt{2\pi } )\phi (k)dk\). 

To fit the initial wavefunction \(\Psi (x,0)\) we use the continuous version of the Fourier's series, \textit{i.e.,} Fourier's transform, where any function can be expressed, according to the Plancherel's theorem, as

\begin{equation}
  \Psi (x,0) = \frac{1}{\sqrt{2\pi } } \int_{-\infty}^{+\infty} \phi (k) e^{ikx}dk, \quad \psi  (k) = \frac{1}{\sqrt{2\pi } } \int_{-\infty}^{+\infty} \Psi (x,0) e^{- ikx}dx.     
\end{equation}

In fact, the difference in the discrete and continuous cases in the above examples correspond physically to bound state and scattering state, which means that the particle can or cannot never escape the potential well.

\section{The Delta-Function Well}

We now consider a Delta-function potential

\begin{equation}
  V(x) = -\alpha \delta (x) = \begin{cases}
    0,& x \neq 0,\\
    -\infty,& x=0.
  \end{cases}, \quad \text{ with } \int_{-\infty}^{+\infty} - \alpha \delta (x)dx = -\alpha .  
\end{equation}

The Schrödinger equation reads

\begin{equation}
  -\frac{\hbar ^2}{2m} \frac{d^2\psi }{dx^2} - \alpha \delta (x)\psi  = E\psi . 
\end{equation}

We first consider the bound state solution, \textit{i.e.,} \(E<0\). For \(x<0\), \(V=0\), so we have a simlar Schrödinger equation as the free particle case (\cref{freee}), except that \(E<0\) so we have to modify it as 

\begin{equation}
  \frac{d^2\psi }{dx^2} = \kappa ^2\psi , \quad \kappa = \frac{\sqrt{-2mE} }{\hbar } \implies \psi _{\kappa }(x) = Ae^{\kappa x},
\end{equation}

where we have omitted the negative exponential term since it blows up as \(x \to -\infty\). Similarly, for \(x > 0\) we have \(\psi _{\kappa }(x) = Be^{-\kappa x}  \).   

The boundary conditions are \(\psi \) continuous and \(d \psi /dx\) continuous except when \(V \to \pm \infty\). This is because if we integrate the Schrödinger equation from \(- \epsilon \) to \(+ \epsilon \), and take the limite as \(\epsilon \to 0\), we have

\begin{equation}
  \begin{aligned} 
  -\frac{\hbar ^2}{2m} \int_{-\epsilon }^{+\epsilon } \frac{d^2\psi }{dx^2} dx + \int_{-\epsilon }^{+\epsilon } V(x)\psi (x) dx &= E \int_{-\epsilon }^{+\epsilon } \psi (x)dx = 0 \\
  \Delta \left( \frac{d\psi }{dx}  \right) \equiv  \lim_{\epsilon  \to 0} \left( \eval{\frac{\partial \psi }{\partial x} }_{+\epsilon }^{} - \eval{\frac{\partial \psi }{\partial x} }_{-\epsilon }^{}   \right) &= \frac{2m}{\hbar ^2} \lim_{\epsilon  \to 0}  \int_{-\epsilon }^{+\epsilon } V(x)\psi (x)dx.  
  \end{aligned} 
\end{equation}

Ordinary the lmiit on the right is zero since \(V(x)\) is finite. However this argument fails when \(V(x)\) is infinite so \(d\psi /dx\) is discontinuous when \(V(x) \to \pm \infty\).    

In particular, for \(V(x) = - \alpha \delta (x)\) the integral gives 

\begin{equation}
  \Delta \left( \frac{d\psi }{dx}  \right) = -\frac{2m\alpha  }{\hbar ^2} \psi (0)  = -\frac{2m\alpha A}{\hbar ^2} \implies \kappa = \frac{m\alpha }{\hbar ^2} \implies E = -\frac{m\alpha ^2}{2\hbar ^2}.   
\end{equation}

\chapter{Three Dimensions}

In three dimensions, the time-dependent Schrödinger equation reads

\begin{equation}
  i \hbar \frac{\partial \Psi }{\partial t} = -\frac{\hbar ^2}{2m} \laplacian \Psi +V\Psi ,
\end{equation}

while the time-independent Schrödinger equation reads

\begin{equation}
  -\frac{\hbar ^2}{2m} \laplacian \psi  + V\psi = E\psi .
\end{equation}

The general solution now reads

\begin{equation}
  \Psi (\vb{r} ,t) = \sum_{n}^{} c_{n}\psi _{n}(\vb{r} ) e^{-i E_{n}t/\hbar  }.   
\end{equation}

\section{Central Potential}

To solve the time-independnent Schrödinger equation for central potentials, for which \(V\) is a function only of the distance from the origin, \textit{i.e.,} \(V(\vb{r} ) = V(r)\), we adopt spherical coordintates and guess 

\begin{equation}
  \psi (r,\theta ,\phi ) = R(r) Y (\theta ,\phi ).
\end{equation}

Upon substitution we get

\begin{equation}
  \frac{1}{R}\frac{d}{dr}\left( r^2 \frac{dR}{dr}  \right) - \frac{2mr^2}{\hbar ^2}- \frac{2mr^2}{\hbar ^2}(V(r) - E) + \frac{1}{Y}\left(   \frac{1}{\sin \theta }\frac{\partial }{\partial \theta }\left( \sin \theta  \frac{\partial Y}{\partial \theta } \right) + \frac{1}{\sin ^2\theta }\frac{\partial^2 Y}{\partial \phi ^2} \right) = 0.
\end{equation}

The first term only depends on \(r\) and the second term only depends on \(\theta \text { and } \phi \), so they must both be a constant. We write this constant as \(\pm \ell (\ell +1)\), for reasons that would become obvious later.

THe normalization condition is 

\begin{equation}
  \int \abs{\Psi }^2 d^3 \vb{r} = \int  \abs{\psi }^2r^2\sin \theta dr d\theta d\phi = \left( \int_{0}^{R}  \abs{R}^2r^2dr  \right)\left( \int_{0}^{\pi } \abs{Y}^2\sin \theta d \theta d\phi     \right) = 1.
\end{equation}

Since the two integrals are independent of each other, both of them must be equal to 1.


\subsection{Radial Equation}

The radial equation reads 

\begin{equation}
  \frac{d}{dr} \left( r^2 \frac{dR}{dr}  \right) - \frac{2mr^2}{\hbar ^2}(V(r)-E)R = \ell (\ell +1)R.
\end{equation}

Introduce the change in variable \(u(r)\equiv rR(r)\), we have 

\begin{equation}
  -\frac{\hbar ^2}{2m} \frac{d^2u}{dr^2} + \left( V+ \frac{\hbar ^2}{2m} \frac{\ell (\ell +1)}{r^2}   \right)u = Eu. 
\end{equation}

It is identical in form to the one-dimensional Schrödinger equation, except that the potential \(V\) is repalced by the effective potential 

\begin{equation}
  V_{\text{eff} } = V + \frac{\hbar ^2}{2m} \frac{\ell (\ell +1)}{r^2}.   
\end{equation}

\subsection{Angular Equation}

The angular equation reads

\begin{equation}
  \sin \theta \frac{\partial }{\partial \theta } \left( \sin \theta \frac{\partial Y}{\partial \theta }  \right) + \frac{\partial^2 Y}{\partial \phi ^2} = -\ell (\ell +1)\sin ^2\theta Y. 
\end{equation}

We separate the variables again by susbstituting \(Y(\theta ,\phi ) = \Theta (\theta )\Phi (\phi )\), which gives 

\begin{equation}
  \left( \frac{1}{\Theta }\left( \sin \theta \frac{d}{d\theta }\left( \sin \theta \frac{d\Theta }{d\theta }  \right)  \right) + \ell (\ell +1)\sin ^2\theta   \right) + \frac{1}{\Phi } \frac{d^2\Phi }{d\phi ^2} = 0.  
\end{equation}

The first term only depends on \(\theta \) and the second term only depends on \(\phi \), so they must both be a constant. We write this constant as \(\pm m^2\), for reasons that would become obvious later.

\subsubsection{Polar Equation}

The \(\phi \) equation is easy 

\begin{equation}
  \frac{d^2\Phi }{d\phi ^2} = - m^2\Phi \implies \Phi (\phi ) = e^{im \phi },
\end{equation}

where \(m\) is allowed to go negative to cover all cases.

Now when \(\phi \) advances by \(2\pi \), we return to the same point in space, so we require that 

\begin{equation}
  \Phi (\phi +2\pi ) = \Phi (\phi ) \implies e^{2\pi im} = 1 \implies m = 0,\pm 1,\pm 2,\ldots . 
\end{equation}

\subsubsection{Azimuthual Equation}

For the \(\theta \) equation

\begin{equation}
  \sin \theta \frac{d}{d\theta } \left( \sin \theta \frac{d\Theta }{d \theta }  \right) + \left( \ell (\ell +1)\sin ^2\theta -m^2 \right) \Theta =0,
\end{equation}

the solution is 

\begin{equation}
  \Theta (\theta ) = A P_{\ell }^{m}(\cos \theta ),
\end{equation}

where \(P_{\ell }^{m}  \) is the associated Legendre function 

\begin{equation}
  P_{\ell }^{m}(x)\equiv (-1)^{m}(1-x^2)^{m /2} \left( \frac{d}{dx}  \right)^{m}P_{\ell }(x),
\end{equation}

and \(P_{\ell }(x) \) is the \(\ell^{\text{th}} \) Legendre polynomial, defined by the Rodrigues formula

\begin{equation}
  \quad P_{\ell } \equiv \frac{1}{2^{\ell }\ell ! } \left( \frac{d}{dx}  \right)^{\ell } \left( x^2-1 \right) ^{\ell }.
\end{equation}

The normalized angular wavefunctions are called the spherical harmonics

\begin{equation}
  Y_{\ell }^{m}(\theta ,\phi ) = \sqrt{\frac{2\ell +1}{4\pi } \frac{(\ell -m)!}{(\ell +m)!} } e^{i m \phi }P_{\ell }^{m}(\cos \theta ).      
\end{equation}

\Cref{legendre} shows some associated functional form and graphs of \(r = \abs{P_{\ell }^{m}  (\cos \theta )}\). Note that in the plots \(r\) tells you the magnitude of the function in the direction \(\theta \); each figure should be rotated about the \(z\)-axis.  

\Cref{sphericalharmonics} shows the first few spherical harmonics \(Y_{\ell }^{m}(\theta ,\phi )  \). 

\onefig{legendre}{scale=0.3} 

\onefig{sphericalharmonics}{scale=0.3} 

\example{Infinite Spherical Well.}
{Consider the infinite spherical well

\begin{equation}
  V(r) = \begin{cases}
    0,& r \le a\\
    \infty,& r > a.
  \end{cases}
\end{equation}

Find the wavefunctions and the allowed energies.
}
{Inside the well the radial equation reads 

\begin{equation}
  \frac{d^2u}{dr^2} = \left( \frac{\ell (\ell +1)}{r^2} - k^2 \right)u, \quad k \equiv \frac{\sqrt{2mE} }{\hbar }, 
\end{equation}

subject to the boundary condition \(u(a)=0\).

For \(\ell =0\) we have 

\begin{equation}
  \frac{d^2u}{dr^2} = -k^2u \implies u(r) = A\sin (kr), \quad A = \sqrt{\frac{2}{a} }, 
\end{equation}

where we omitted the \(u(r) = B\cos (kr)\) solution since the actual wavefucntion \(R(r)=u(r) /r\)  blows up as \(r\text { to } \infty\) and found \(A\) through normalization.

The boundary condition then requires 

\begin{equation}
  \sin (ka) = 0 \implies ka = N\pi \implies E_{N0} = \frac{N^2\pi ^2\hbar ^2}{2ma^2}, \quad N = 1,2,3,\ldots .  
\end{equation}

The general solution for arbitrary integer \(\ell \) is 

\begin{equation}
  u(r) = Ar j_{\ell }(kr) + Br n_{\ell }(kr),  
\end{equation}

where \(j\ell (x) \text { and } n_{\ell }(x) \) are the spherical Bessel function of order \(\ell \) and the spherical Neumann function of order \(\ell \), defined by 

\begin{equation}
  j_{\ell }(x) \equiv (-x)^{\ell } \left( \frac{1}{x} \frac{d}{dx}   \right)^{\ell } \frac{\sin x}{x}, \quad n_{\ell }(x) \equiv - (-x)^{\ell } \left( \frac{1}{x} \frac{d}{dx}   \right)^{\ell } \frac{\cos x}{x}.  
\end{equation}

Since Neumann functions blow up at the origin we have \(B_{\ell } = 0\).

The boundary condition then requires 

\begin{equation}
  j_{\ell }(ka) = 0 \implies k = \frac{\beta _{N \ell } }{a},  
\end{equation}

where \(\beta _{N \ell } \) is the \(N^{\text{th}} \) zero of the \(\ell^{\text{th}} \) spherical Bessel function. The allowed energies are then give by 

\begin{equation}
  E_{N \ell } = \frac{\hbar ^2 \beta _{N \ell }^2 }{2ma^2}.  
\end{equation}

It is customary to introduce the principal quantum number \(n\), which orders the allowed energies, starting with 1 for the ground state.

The wavefunctions are 

\begin{equation}
  \psi _{n\ell m}(r,\theta ,\phi ) = A_{n \ell }j_{\ell } \left( \beta _{N \ell }\frac{r}{a}   \right)  Y_{\ell }^{m}(\theta ,\phi ),  
\end{equation}

with the constant \(A_{n\ell } \)  to be determined by normalization. 

The energy levels of the infinite spherical well is illustrated in \cref{infinite}. \(N-1\) is the number of radial nodes, where \(n\) is the order of the energy.  
}

\onefig{infinite}{scale=0.3} 

\section{Hydrogen Atom}

From Coulomb's law, we have the radial equation

\begin{equation}
  -\frac{\hbar ^2}{2m} \frac{d^2u}{dr^2} + \left( - \frac{e^2}{4\pi \epsilon_0 r} + \frac{\hbar ^2}{2m_{e} } \frac{\ell (\ell +1)}{r^2}   \right)u = Eu. 
\end{equation}

Introducing the variables \(\kappa \equiv \sqrt{-2m_{e} E} /\hbar \) (here we consider the bound state so \(E <0\)), \(\rho \equiv \kappa r\) and \(\rho _{0}\equiv m_{e}e^2 /2\pi \epsilon_0 \hbar ^2 \kappa  \), we have

\begin{equation}
  \frac{d^2u}{d\rho ^2} = \left( 1- \frac{\rho _{0} }{\rho } + \frac{\ell (\ell +1)}{\rho ^2}   \right) u.
\end{equation}

As \(\rho \to \infty\), we have 

\begin{equation}
  \frac{d^2u}{d\rho ^2} = u \implies u(\rho ) = Ae^{-\rho },   
\end{equation}

where we have neglected the \(Be^{\rho } \) solution since it blows up as \(\rho \to \infty\). 

On the other hand, as \(\rho \to 0\), we have 

\begin{equation}
  \frac{d^2u}{d\rho ^2} = \frac{\ell (\ell +1)}{\rho ^2} u \implies u(\rho ) = C \rho ^{\ell +1},  
\end{equation}

where we have neglected the \(D\rho ^{-\ell } \) solution since it blows up as \(\rho \to 0\).  

Peeling of the asymptotic behaviour, we propose

\begin{equation}
  u(\rho ) = \rho ^{\ell +1}e^{-\rho }v(\rho ), \quad v(\rho ) = \sum_{j=0}^{\infty} c_{j}\rho ^{j}.   
\end{equation}

Substitution gives 

\begin{equation}
  \rho \frac{d^2v}{d\rho ^2} + 2(\ell +1-\rho ) \frac{dv}{d\rho } + (\rho _{0} - 2(\ell +1) )v = 0,
\end{equation}

or 

\begin{equation}
  \sum_{j=0}^{\infty} j(j+1)c_{j+1}\rho ^{j} + 2(\ell +1)\sum_{j=0}^{\infty} j(j+1)c_{j+1}\rho ^{j} - 2\sum_{j=0}^{\infty} j c_{j}\rho ^{j} + (\rho _{0} - 2(\ell +1) ) \sum_{j=0}^{\infty}c_{j}\rho ^{j} = 0.
\end{equation}

Equating the coefficients of like powers yields 

\begin{equation}
  c_{j+1} = \left( \frac{2(j+\ell +1)-\rho _{0} }{(j+1)(j+2\ell +2)}  \right) c_{j}. 
\end{equation}

For \(u(\rho )\) to be normalizable, however, the power series must terminate at some \(j=N\), where 

\begin{equation}
  2(N+1) - \rho _{0} = 0 \implies \rho _{0} = 2n, \quad n \equiv N+\ell.
\end{equation}

The allowed energies are then 

\begin{equation}
  E_{n} = -\left( \frac{m_{e} }{2\hbar ^2} \left( \frac{e^2}{4\pi \epsilon_0 }  \right)^2  \right) \frac{1}{n^2} = \frac{E_1 }{n^2}, \quad n = 1,2,3, \ldots .  
\end{equation}

The wavefunction is then labeled by three quantum numbers \(n, \ell \text { and } m\) as 

\begin{equation}
  \psi _{n \ell m}(r,\theta ,\phi ) = R_{n \ell }(r)Y_{\ell }^{m} (\theta ,\phi ), \quad R_{n \ell }(r) = \frac{1}{r}\rho ^{\ell +1} e^{-\rho } v(\rho )        
\end{equation}


\chapter{Identical Particles}

\section{Two-Particle Systems}

For a two-particle system, the time-dependent Schrödinger Equation reads

\begin{equation}
  i \hbar \frac{\partial \Psi }{\partial t} = -\frac{\hbar ^2}{2m_1 } \laplacian _{1}\Psi - \frac{\hbar ^2}{2m_2 } \laplacian _{2} \Psi + V \Psi,
\end{equation}

while the time-independent Schrödinger Equation reads

\begin{equation}
  -\frac{\hbar ^2}{2m_1 }\laplacian _{1}\psi - \frac{\hbar ^2}{2m_2 }\laplacian _{2}\psi  + V\psi = E\psi .   
\end{equation}

For non-interacting particles, the potential energy has the form

\begin{equation}
  V(\vb{r} _{1},\vb{r} _{2}  ) = V_1 (\vb{r} _{1} ) + V_2 (\vb{r} _{2} ),
\end{equation}

and the time-independent Schrödinger Equation can be solved by separation of variables 

\begin{equation}
  \psi (\vb{r} _{1},\vb{r} _{2}  ) = \psi _{a}(\vb{r} _{1} )\psi _{b}(\vb{r} _{2} ).  
\end{equation}

Carrying out the standard procedure of separation of variables we find that \(\psi _{a}(\vb{r} _{1} ) \text { and } \psi _{b}(\vb{r} _{2} )  \) each satisfy the one-particle Schrödinger Equation, so the two-particle wavefunction is a simple product of one-particle wavefunctions

\begin{equation}
  \Psi (\vb{r} _{1},\vb{r} _{2},t  ) = \psi _{a}(\vb{r} _{1} )\psi _{b}(\vb{r} _{2} ) e^{-i (E_{a}+E_{b}  )t /\hbar } = \Psi _{a}(\vb{r} _{1},t )\Psi _{b}(\vb{r} _{2},t ).    
\end{equation}

In fact, any linear combination of such solution, such as 

\begin{equation}
  \Psi (\vb{r} _{1},\vb{r} _{2},t  ) = \frac{3}{5} \Psi _{a}(\vb{r} _{1} ,t) \Psi _{b}(\vb{r} _{2},t ) + \frac{4}{5} \Psi _{c}(\vb{r} _{1},t ) \Psi _{d}(\vb{r} _{2},t ),    
\end{equation}

also satisfies the time-dependent Schrödinger Equation, in which case the state of particle 1 depends on the state of particle 2, in the sense that if you measure the energy of particle 1, you might get \(E_{a} \) (with probability 9/25), in which case the energy of particle 2 is definitely \(E_{b} \). THe two particles are said to be entangled, which is one that cannot be written as a product of single-particle states.  

If the particles interact only with one another, via a potential that depends on their separation 

\begin{equation}
  V(\vb{r} _{1}, \vb{r} _{2}  ) = V(\abs{\vb{r} _{1}-\vb{r} _{2}  } ), 
\end{equation}

then the two-body problem reduces to an equivalent one-body problem via the introduction of the reduced mass.

















































































\end{document}








